{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"hw7_bert.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"36d9c916125043aeb24f5859c1fd7e18":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a5a8999953e34c22854013b066fbc456","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_60cf6676db01470883f78e98cb721e2a","IPY_MODEL_46ffe683adc84e7fb1a7af030efd2f89"]}},"a5a8999953e34c22854013b066fbc456":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"60cf6676db01470883f78e98cb721e2a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3ac514dd82404b9ba14e5c079dc899bc","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":6734,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":6734,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_77dadad1bce94bb8a493d0326724feef"}},"46ffe683adc84e7fb1a7af030efd2f89":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4b1000744ef840c580a6163ce03e414b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 6734/6734 [23:31&lt;00:00,  4.77it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c15be8f7aba84088b78d9e67b9a76b8c"}},"3ac514dd82404b9ba14e5c079dc899bc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"77dadad1bce94bb8a493d0326724feef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4b1000744ef840c580a6163ce03e414b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c15be8f7aba84088b78d9e67b9a76b8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"af0a9749dcfb4a8c944f5aad9c3be4f5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4e321d5a48bf4d299a0229706de070ad","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_27cffcf551f6407986c401545e4725fc","IPY_MODEL_6735ddc0397e435da6e2b5da9996c4fc"]}},"4e321d5a48bf4d299a0229706de070ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"27cffcf551f6407986c401545e4725fc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_022228ab222f493690983722d16ca8fe","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":3524,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3524,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a4f58c7f41794880a7362a2e7e48f301"}},"6735ddc0397e435da6e2b5da9996c4fc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9a747c2eb4864b88946de537f4e659d1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3524/3524 [10:00&lt;00:00,  5.87it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3c39c0aee6474fffa535e53f8293b2a8"}},"022228ab222f493690983722d16ca8fe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a4f58c7f41794880a7362a2e7e48f301":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9a747c2eb4864b88946de537f4e659d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3c39c0aee6474fffa535e53f8293b2a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e8ecbf9e2f07472d9e6f7d1deb07d0ce":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_39fcb2227ba7423486973071a693be69","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9b4c407b50f8478097937c39913f2f61","IPY_MODEL_4655aae0c65b45858f550f29abcf20fa"]}},"39fcb2227ba7423486973071a693be69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9b4c407b50f8478097937c39913f2f61":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_124ab250e53f4601ade249da818e9576","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":6734,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":6734,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_244f85d87004439ca01de48c9d59bffc"}},"4655aae0c65b45858f550f29abcf20fa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4be9bc27305e426a9afe1922d3d0a2fc","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 6734/6734 [23:31&lt;00:00,  4.77it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d467130bc39742e98d9513bf3fab8414"}},"124ab250e53f4601ade249da818e9576":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"244f85d87004439ca01de48c9d59bffc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4be9bc27305e426a9afe1922d3d0a2fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d467130bc39742e98d9513bf3fab8414":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8eb24d40e4d740538ffa2434830c2af4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c683b86696774df89dd34090667743b6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_835bbf05a2744956999863c9d8504add","IPY_MODEL_037c560575434bc29716bad34d366a90"]}},"c683b86696774df89dd34090667743b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"835bbf05a2744956999863c9d8504add":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_78b8557635784f3e89d33ec7e83e487f","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":3524,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3524,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bb7c262fb28344ba983a3381e0595689"}},"037c560575434bc29716bad34d366a90":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7a01aaeff8584bddb8eb2cb1fcbb2e8a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3524/3524 [09:54&lt;00:00,  5.93it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0a06dfb3f6ec45e39ad83a4fdd6c8884"}},"78b8557635784f3e89d33ec7e83e487f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bb7c262fb28344ba983a3381e0595689":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7a01aaeff8584bddb8eb2cb1fcbb2e8a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0a06dfb3f6ec45e39ad83a4fdd6c8884":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6083b09400e64876b920d63126faea4a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d3feed738b0e441fab2ca614370620d2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bdc9758f090e486287994b5445895b68","IPY_MODEL_cdf8e8a149f54a4d9b40548a842b7546"]}},"d3feed738b0e441fab2ca614370620d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bdc9758f090e486287994b5445895b68":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_adb1d6adefc14768a417170f2fc6cf1b","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":3493,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3493,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_acc7b11a20ee4c6088ae0c1d30489581"}},"cdf8e8a149f54a4d9b40548a842b7546":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_30013ce76c4d40768ca778e4d1b38cf5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3493/3493 [30:56&lt;00:00,  1.88it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a268672c1800432ba6b0e095bacf8b59"}},"adb1d6adefc14768a417170f2fc6cf1b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"acc7b11a20ee4c6088ae0c1d30489581":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"30013ce76c4d40768ca778e4d1b38cf5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a268672c1800432ba6b0e095bacf8b59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"xvSGDbExff_I"},"source":["# **Homework 7 - Bert (Question Answering)**\n","\n","If you have any questions, feel free to email us at ntu-ml-2021spring-ta@googlegroups.com\n","\n","\n","\n","Slide:    [Link](https://docs.google.com/presentation/d/1aQoWogAQo_xVJvMQMrGaYiWzuyfO0QyLLAhiMwFyS2w)　Kaggle: [Link](https://www.kaggle.com/c/ml2021-spring-hw7)　Data: [Link](https://drive.google.com/uc?id=1znKmX08v9Fygp-dgwo7BKiLIf2qL1FH1)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"WGOr_eS3wJJf"},"source":["## Task description\n","- Chinese Extractive Question Answering\n","  - Input: Paragraph + Question\n","  - Output: Answer\n","\n","- Objective: Learn how to fine tune a pretrained model on downstream task using transformers\n","\n","- Todo\n","    - Fine tune a pretrained chinese BERT model\n","    - Change hyperparameters (e.g. doc_stride)\n","    - Apply linear learning rate decay\n","    - Try other pretrained models\n","    - Improve preprocessing\n","    - Improve postprocessing\n","- Training tips\n","    - Automatic mixed precision\n","    - Gradient accumulation\n","    - Ensemble\n","\n","- Estimated training time (tesla t4 with automatic mixed precision enabled)\n","    - Simple: 8mins\n","    - Medium: 8mins\n","    - Strong: 25mins\n","    - Boss: 2hrs\n","  "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"MLoHaRJ3u55-","executionInfo":{"status":"ok","timestamp":1621132217511,"user_tz":-480,"elapsed":3235,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"10b3bd4b-0776-4b95-e3d5-e49f1156799e"},"source":["import torch\n","\n","torch.cuda.get_device_name()"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Tesla V100-SXM2-16GB'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-P7G3gORCkew","executionInfo":{"status":"ok","timestamp":1621132239042,"user_tz":-480,"elapsed":19549,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"4cbf995a-53c4-40a9-d6fa-f5c1771196be"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TJ1fSAJE2oaC"},"source":["## Download Dataset"]},{"cell_type":"code","metadata":{"id":"YPrc4Eie9Yo5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621132245230,"user_tz":-480,"elapsed":2803,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"e9e26607-3fca-4d72-ee82-56171012a1a9"},"source":["# Download link 1\n","!gdown --id '1znKmX08v9Fygp-dgwo7BKiLIf2qL1FH1' --output hw7_data.zip\n","\n","# Download Link 2 (if the above link fails) \n","# !gdown --id '1pOu3FdPdvzielUZyggeD7KDnVy9iW1uC' --output hw7_data.zip\n","\n","!unzip -o hw7_data.zip\n","\n","# For this HW, K80 < P4 < T4 < P100 <= T4(fp16) < V100\n","#!nvidia-smi"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1znKmX08v9Fygp-dgwo7BKiLIf2qL1FH1\n","To: /content/hw7_data.zip\n","7.71MB [00:00, 21.2MB/s]\n","Archive:  hw7_data.zip\n","  inflating: hw7_dev.json            \n","  inflating: hw7_test.json           \n","  inflating: hw7_train.json          \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E9w8uocK86_0","executionInfo":{"status":"ok","timestamp":1621154551276,"user_tz":-480,"elapsed":773,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"92d19157-a271-432f-bace-d074bd149156"},"source":["!nvidia-smi"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Sun May 16 08:42:30 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   42C    P0    54W / 300W |  16143MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pQVe0fAjflkC","executionInfo":{"status":"ok","timestamp":1621162492321,"user_tz":-480,"elapsed":1016,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"77bef25c-07b1-48e9-daf2-4270cc61e1b6"},"source":["!ps -aux|grep python"],"execution_count":17,"outputs":[{"output_type":"stream","text":["root          93  0.0  0.0 128668 16556 ?        Sl   02:30   0:04 /usr/bin/python3 /usr/local/lib/python3.7/dist-packages/debugpy/adapter --for-server 46587 --host 127.0.0.1 --port 15157 --server-access-token ee8a1401e7fabfc136084b2ad7cfd3fc66580c38f05518c5b62c64481f7107a7\n","root         256  0.0  0.0  18384  3096 ?        S    02:30   0:00 bash -c tail -n +0 -F \"/root/.config/Google/DriveFS/Logs/drive_fs.txt\" | python3 /opt/google/drive/drive-filter.py > \"/root/.config/Google/DriveFS/Logs/timeouts.txt\" \n","root         258  0.0  0.0  31744  9552 ?        S    02:30   0:00 python3 /opt/google/drive/drive-filter.py\n","root        1156  0.0  0.0      0     0 ?        Z    03:42   0:01 [python3] <defunct>\n","root        1315  0.0  0.0      0     0 ?        Z    03:49   0:02 [python3] <defunct>\n","root        1479  0.0  0.0      0     0 ?        Zs   04:01   0:01 [python3] <defunct>\n","root        1499  0.0  0.0      0     0 ?        Z    04:01   0:00 [python3] <defunct>\n","root        1525  1.1  0.2 197508 62680 ?        Sl   04:01   4:41 /usr/bin/python2 /usr/local/bin/jupyter-notebook --ip=\"172.28.0.2\" --port=9000 --FileContentsManager.root_dir=\"/\" --LargeFileManager.delete_to_trash=False --MappingKernelManager.root_dir=\"/content\"\n","root        1554  0.0  0.0      0     0 ?        Z    04:01   0:07 [python3] <defunct>\n","root        2182  0.0  0.0      0     0 ?        Z    04:42   0:04 [python3] <defunct>\n","root        2474  0.0  0.0      0     0 ?        Z    05:05   0:07 [python3] <defunct>\n","root        2966  0.0  0.0      0     0 ?        Z    05:45   0:06 [python3] <defunct>\n","root        3356  0.0  0.0      0     0 ?        Z    06:21   0:16 [python3] <defunct>\n","root        4136  0.0  0.0      0     0 ?        Z    07:41   0:11 [python3] <defunct>\n","root        4529  0.0  0.0      0     0 ?        Z    08:37   0:00 [python3] <defunct>\n","root        4654  0.2  0.0      0     0 ?        Z    08:42   0:16 [python3] <defunct>\n","root        5069 64.0 24.6 29376076 6583928 ?    Ssl  10:04  32:07 /usr/bin/python3 -m ipykernel_launcher -f /root/.local/share/jupyter/runtime/kernel-19fa00e5-94ca-4c46-adf2-abc5bc39b839.json\n","root        5089  0.3  0.0 129180 16508 ?        Sl   10:04   0:09 /usr/bin/python3 /usr/local/lib/python3.7/dist-packages/debugpy/adapter --for-server 36475 --host 127.0.0.1 --port 18298 --server-access-token 44b72055789dcb5bd3b41897c3b47458b40bd0d27531164cd0a67fa69045db7e\n","root        5288  0.0  0.0  39200  6388 ?        S    10:54   0:00 /bin/bash -c ps -aux|grep python\n","root        5290  0.0  0.0  38576  5552 ?        S    10:54   0:00 grep python\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JfaSQLv0fnux"},"source":["!kill -9 5069"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TevOvhC03m0h"},"source":["## Install transformers\n","\n","Documentation for the toolkit:　https://huggingface.co/transformers/"]},{"cell_type":"code","metadata":{"id":"tbxWFX_jpDom","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621137700463,"user_tz":-480,"elapsed":3186,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"dc9b4e0b-6728-41dc-baeb-7124159ebcbc"},"source":["# You are allowed to change version of transformers or use other toolkits\n","!pip install transformers==4.5.0"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers==4.5.0 in /usr/local/lib/python3.7/dist-packages (4.5.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (4.41.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (4.0.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (1.19.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (3.0.12)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (20.9)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (0.0.45)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (0.10.2)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0) (1.24.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.5.0) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.5.0) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.5.0) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.0) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.0) (8.0.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.0) (1.0.1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8dKM4yCh4LI_"},"source":["## Import Packages"]},{"cell_type":"code","metadata":{"id":"WOTHHtWJoahe","executionInfo":{"status":"ok","timestamp":1621162511715,"user_tz":-480,"elapsed":3553,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}}},"source":["import json\n","import numpy as np\n","import random\n","import torch\n","from torch.utils.data import DataLoader, Dataset \n","from transformers import AdamW, BertForQuestionAnswering, BertTokenizerFast\n","\n","from tqdm.auto import tqdm\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# Fix random seed for reproducibility\n","def same_seeds(seed):\n","\t  torch.manual_seed(seed)\n","\t  if torch.cuda.is_available():\n","\t\t    torch.cuda.manual_seed(seed)\n","\t\t    torch.cuda.manual_seed_all(seed)\n","\t  np.random.seed(seed)\n","\t  random.seed(seed)\n","\t  torch.backends.cudnn.benchmark = False\n","\t  torch.backends.cudnn.deterministic = True\n","same_seeds(0)"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"7pBtSZP1SKQO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621162514203,"user_tz":-480,"elapsed":6029,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"f36876a4-eb33-4b36-f4a1-ed0daeda389e"},"source":["# Change \"fp16_training\" to True to support automatic mixed precision training (fp16)\t\n","fp16_training = True\n","\n","if fp16_training:\n","    !pip install accelerate==0.2.0\n","    from accelerate import Accelerator\n","    accelerator = Accelerator(fp16=True)\n","    device = accelerator.device\n","\n","# Documentation for the toolkit:  https://huggingface.co/docs/accelerate/"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: accelerate==0.2.0 in /usr/local/lib/python3.7/dist-packages (0.2.0)\n","Requirement already satisfied: pyaml>=20.4.0 in /usr/local/lib/python3.7/dist-packages (from accelerate==0.2.0) (20.4.0)\n","Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from accelerate==0.2.0) (1.8.1+cu101)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=20.4.0->accelerate==0.2.0) (3.13)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->accelerate==0.2.0) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->accelerate==0.2.0) (3.7.4.3)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2YgXHuVLp_6j"},"source":["## Load Model and Tokenizer\n","\n","\n","\n","\n"," "]},{"cell_type":"code","metadata":{"id":"xyBCYGjAp3ym","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621162531581,"user_tz":-480,"elapsed":21916,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"283a00e3-6029-48b5-a87d-32e2298dc7f9"},"source":["\n","from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoModelForPreTraining\n","\n","# model = BertForQuestionAnswering.from_pretrained(\"bert-base-chinese\").to(device)\n","# tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-chinese\")\n","\n","\n","tokenizer = BertTokenizerFast.from_pretrained(\"hfl/chinese-roberta-wwm-ext-large\")\n","model = BertForQuestionAnswering.from_pretrained(\"hfl/chinese-roberta-wwm-ext-large\").to(device)\n","\n","#model = BertForQuestionAnswering.from_pretrained(\"hfl/chinese-macbert-large\").to(device)\n","#tokenizer = BertTokenizerFast.from_pretrained(\"hfl/chinese-macbert-large\")\n","\n","# You can safely ignore the warning message (it pops up because new prediction heads for QA are initialized randomly)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at hfl/chinese-roberta-wwm-ext-large were not used when initializing BertForQuestionAnswering: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at hfl/chinese-roberta-wwm-ext-large and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"3Td-GTmk5OW4"},"source":["## Read Data\n","\n","- Training set: 26935 QA pairs\n","- Dev set: 3523  QA pairs\n","- Test set: 3492  QA pairs\n","\n","- {train/dev/test}_questions:\t\n","  - List of dicts with the following keys:\n","   - id (int)\n","   - paragraph_id (int)\n","   - question_text (string)\n","   - answer_text (string)\n","   - answer_start (int)\n","   - answer_end (int)\n","- {train/dev/test}_paragraphs: \n","  - List of strings\n","  - paragraph_ids in questions correspond to indexs in paragraphs\n","  - A paragraph may be used by several questions "]},{"cell_type":"code","metadata":{"id":"NvX7hlepogvu","executionInfo":{"status":"ok","timestamp":1621162531584,"user_tz":-480,"elapsed":20139,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}}},"source":["def read_data(file):\n","    with open(file, 'r', encoding=\"utf-8\") as reader:\n","        data = json.load(reader)\n","    return data[\"questions\"], data[\"paragraphs\"]\n","\n","train_questions, train_paragraphs = read_data(\"hw7_train.json\")\n","dev_questions, dev_paragraphs = read_data(\"hw7_dev.json\")\n","test_questions, test_paragraphs = read_data(\"hw7_test.json\")"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fm0rpTHq0e4N"},"source":["## Tokenize Data"]},{"cell_type":"code","metadata":{"id":"rTZ6B70Hoxie","executionInfo":{"status":"ok","timestamp":1621162542268,"user_tz":-480,"elapsed":29614,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}}},"source":["# Tokenize questions and paragraphs separately\n","# 「add_special_tokens」 is set to False since special tokens will be added when tokenized questions and paragraphs are combined in datset __getitem__ \n","\n","train_questions_tokenized = tokenizer([train_question[\"question_text\"] for train_question in train_questions], add_special_tokens=False)\n","dev_questions_tokenized = tokenizer([dev_question[\"question_text\"] for dev_question in dev_questions], add_special_tokens=False)\n","test_questions_tokenized = tokenizer([test_question[\"question_text\"] for test_question in test_questions], add_special_tokens=False) \n","\n","train_paragraphs_tokenized = tokenizer(train_paragraphs, add_special_tokens=False)\n","dev_paragraphs_tokenized = tokenizer(dev_paragraphs, add_special_tokens=False)\n","test_paragraphs_tokenized = tokenizer(test_paragraphs, add_special_tokens=False)\n","\n","# You can safely ignore the warning message as tokenized sequences will be futher processed in datset __getitem__ before passing to model"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0MIRYrSGCQUj","executionInfo":{"status":"ok","timestamp":1621162542269,"user_tz":-480,"elapsed":28833,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"655632e4-fc02-42bc-ba45-c19d5131fe54"},"source":["# 句號的encode\n","\n","dotend = tokenizer.encode('。', add_special_tokens=False)[0]\n","dotend"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["511"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DomyF0brWDgJ","executionInfo":{"status":"ok","timestamp":1621162542270,"user_tz":-480,"elapsed":28647,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"54e02c2e-edc5-43d2-f7d0-8460ec2223c2"},"source":["comma = tokenizer.encode('，', add_special_tokens=False)[0]\n","comma"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8024"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"Ws8c8_4d5UCI"},"source":["## Dataset and Dataloader"]},{"cell_type":"code","metadata":{"id":"UDss8sXUUyS4","executionInfo":{"status":"ok","timestamp":1621143270920,"user_tz":-480,"elapsed":766,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}}},"source":["test_list = tokenizer(train_paragraphs[5870], add_special_tokens=False).input_ids\n","train_paragraphs[5870]"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JTrsk5IqZNR4","executionInfo":{"status":"ok","timestamp":1621143306685,"user_tz":-480,"elapsed":896,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"a80ba19c-edab-485a-bfdc-af12372643b7"},"source":["for i in train_questions:\n","  if i['paragraph_id'] == 5870:\n","    print(i)"],"execution_count":35,"outputs":[{"output_type":"stream","text":["{'id': 2566, 'paragraph_id': 5870, 'question_text': 'PlayStation發售後3年內穩居遊戲市場第一的位置是因為哪一款遊戲?', 'answer_text': 'Final Fantasy系列', 'answer_start': 476, 'answer_end': 490}\n","{'id': 7755, 'paragraph_id': 5870, 'question_text': '「索尼互動娛樂」商標上的方形是甚麼顏色?', 'answer_text': '黃色', 'answer_start': 747, 'answer_end': 748}\n","{'id': 9783, 'paragraph_id': 5870, 'question_text': '索尼互動娛樂在哪一年成立?', 'answer_text': '1993年', 'answer_start': 41, 'answer_end': 45}\n","{'id': 25385, 'paragraph_id': 5870, 'question_text': '任天堂與索尼的合作在哪一年正式決裂?', 'answer_text': '1992年', 'answer_start': 164, 'answer_end': 168}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zslg-FMjdyD6","executionInfo":{"status":"ok","timestamp":1621143510131,"user_tz":-480,"elapsed":742,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"bed453a1-82f5-4f49-cc5f-fb422b503940"},"source":["len(train_paragraphs[5870])"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["755"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gei9QsbvN47o","executionInfo":{"status":"ok","timestamp":1621143801203,"user_tz":-480,"elapsed":905,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"c965d4e8-4aaa-4eb9-f259-d96cdd3880b2"},"source":["size = len(test_list)\n","idx_list = [idx + 1 for idx, val in\n","            enumerate(test_list) if val == dotend] \n","print(idx_list)\n","res = [test_list[i: j] for i, j in\n","        zip([0] + idx_list, idx_list + \n","        ([size] if idx_list[-1] != size else []))]\n","  \n","# print result\n","\n","total_window = len(res)\n","counter = 50\n","\n","for i, window in enumerate(res):\n","  \n","\n","  counter += len(window)\n","  print('w', counter)\n","  if train_questions[2566]['answer_start'] < counter:\n","    print(len(window))\n","    print('a',train_questions[2566]['answer_start'])\n","    start = max(0, counter - len(window) - 50)\n","    end = (counter)\n","    print(test_list[start:end])\n","    break\n","  else:\n","    start = counter - 100\n","    end = counter + 100\n","    \n","\n","print('c',end)\n","    "],"execution_count":45,"outputs":[{"output_type":"stream","text":["[81, 103, 148, 195, 222, 247, 350, 445, 462, 495, 524, 543, 602]\n","w 131\n","w 153\n","w 198\n","w 245\n","w 272\n","w 297\n","w 400\n","w 495\n","95\n","a 476\n","[8447, 2399, 8024, 11515, 8154, 809, 4534, 3229, 3297, 1044, 4999, 4638, 8219, 2512, 1008, 2825, 6123, 4158, 3636, 1690, 4638, 7442, 6213, 6879, 3556, 1690, 519, 11026, 520, 1217, 1057, 4801, 7768, 2356, 1842, 8024, 5645, 9342, 8676, 4638, 9342, 8676, 8536, 12760, 1469, 818, 1921, 1828, 4638, 10560, 8511, 11652, 8167, 8308, 2245, 7274, 749, 4080, 4164, 4638, 2356, 1842, 5000, 4261, 8039, 738, 1728, 4158, 10591, 12436, 5143, 1154, 4638, 2512, 7513, 8024, 11026, 4634, 1545, 2527, 124, 2399, 1058, 4952, 2233, 6879, 2783, 2356, 1842, 5018, 671, 4638, 855, 5390, 511, 8258, 2399, 8024, 11515, 8154, 4634, 1545, 3108, 2380, 6879, 2783, 712, 3582, 11026, 11311, 9609, 511, 8213, 2399, 8111, 3299, 8024, 11515, 8154, 4634, 1545, 11026, 124, 8024, 1728, 4158, 4634, 6121, 6733, 2714, 510, 5965, 1045, 1045, 4817, 1019, 3419, 3203, 6523, 5445, 671, 2428, 3760, 5862, 511]\n","c 495\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Xjooag-Swnuh","executionInfo":{"status":"ok","timestamp":1621162687604,"user_tz":-480,"elapsed":982,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}}},"source":["class QA_Dataset(Dataset):\n","    def __init__(self, split, questions, tokenized_questions, tokenized_paragraphs):\n","        self.split = split\n","        self.questions = questions\n","        self.tokenized_questions = tokenized_questions\n","        self.tokenized_paragraphs = tokenized_paragraphs\n","        self.max_question_len = 40\n","        #self.max_paragraph_len = 150\n","        #self.max_paragraph_len = 450 #0.8\n","        self.max_paragraph_len = 300 #0.82 0.807\n","\n","        ##### TODO: Change value of doc_stride #####\n","        #self.doc_stride = 150\n","        #self.doc_stride = 10 #0.8\n","        self.doc_stride = 25 #0.82 0.807\n","        #self.doc_stride = 300\n","\n","\n","        # Input sequence length = [CLS] + question + [SEP] + paragraph + [SEP]\n","        self.max_seq_len = 1 + self.max_question_len + 1 + self.max_paragraph_len + 1\n","\n","    def __len__(self):\n","        return len(self.questions)\n","\n","    def __getitem__(self, idx):\n","        question = self.questions[idx] # 一次取一個問題\n","        tokenized_question = self.tokenized_questions[idx] #一次取一個問題的token\n","        tokenized_paragraph = self.tokenized_paragraphs[question[\"paragraph_id\"]] # 找出對印的文章[文章id]\n","\n","        ##### TODO: Preprocessing #####\n","        # Hint: How to prevent model from learning something it should not learn\n","\n","        if self.split == \"train\":\n","            # Convert answer's start/end positions in paragraph_text to start/end positions in tokenized_paragraph  \n","            answer_start_token = tokenized_paragraph.char_to_token(question[\"answer_start\"]) # 看答案的開頭在段落的哪個位置\n","            answer_end_token = tokenized_paragraph.char_to_token(question[\"answer_end\"]) # 看答案的結尾在段落的哪個位置\n","\n","            # A single window is obtained by slicing the portion of paragraph containing the answer\n","            #print(tokenized_paragraph.ids)\n","\n","            #mid = (answer_start_token + answer_end_token) // 2\n","            #paragraph_start = max(0, min(mid - self.max_paragraph_len // 2, len(tokenized_paragraph) - self.max_paragraph_len))\n","\n","\n","           \n","            # rand = np.random.choice([100, 160, 190, 200, 210 ,220, 250, 300], 1)[0]\n","\n","            # paragraph_start = max(0,answer_start_token - rand)\n","            # paragraph_end = paragraph_start + self.max_paragraph_len\n","            try:\n","              size = len(tokenized_paragraph.ids)\n","              idx_list = [idx + 1 for idx, val in enumerate(tokenized_paragraph.ids) if val == dotend] \n","\n","              res = [tokenized_paragraph.ids[i: j] for i, j in zip([0] + idx_list, idx_list + ([size] if idx_list[-1] != size else []))]\n","\n","              # print result\n","              counter = 50\n","\n","              for i, window in enumerate(res):\n","                counter += len(window)\n","                if question[\"answer_start\"] < counter:\n","                  paragraph_start = max(0, counter - len(window) - 50)\n","                  paragraph_end = counter\n","                  if (paragraph_end - paragraph_start) > 300:\n","                    rand = np.random.choice([100, 160, 190, 200, 210 ,220, 250, 300], 1)[0]\n","                    paragraph_start = max(0,answer_start_token - rand)\n","                    paragraph_end = paragraph_start + self.max_paragraph_len \n","                  break\n","                else:\n","                  paragraph_start = counter - 120\n","                  paragraph_end = counter + 120\n","              \n","\n","            except:\n","              size = len(tokenized_paragraph.ids)\n","              idx_list = [idx + 1 for idx, val in enumerate(tokenized_paragraph.ids) if val == comma] \n","\n","              res = [tokenized_paragraph.ids[i: j] for i, j in zip([0] + idx_list, idx_list + ([size] if idx_list[-1] != size else []))]\n","\n","              # print result\n","              total_window = len(res)\n","              counter = 100\n","\n","              for i, window in enumerate(res):\n","                counter += len(window)\n","                if question[\"answer_start\"] < counter:\n","\n","                  paragraph_start = max(0, counter - len(window) - 100)\n","                  paragraph_end = counter\n","                  if (paragraph_end - paragraph_start) > 400:\n","                    rand = np.random.choice([100, 160, 190, 200, 210 ,220, 250, 300], 1)[0]\n","                    paragraph_start = max(0,answer_start_token - rand)\n","                    paragraph_end = paragraph_start + self.max_paragraph_len \n","                  break\n","                else:\n","                  paragraph_start = counter - 150\n","                  paragraph_end = counter + 150\n","            \n","\n","\n","            # Slice question/paragraph and add special tokens (101: CLS, 102: SEP)\n","            input_ids_question = [101] + tokenized_question.ids[:self.max_question_len] + [102] \n","\n","\n","            input_ids_paragraph = tokenized_paragraph.ids[paragraph_start : paragraph_end] + [102]\t\t\n","            \n","            # Convert answer's start/end positions in tokenized_paragraph to start/end positions in the window  \n","            answer_start_token += len(input_ids_question) - paragraph_start\n","            answer_end_token += len(input_ids_question) - paragraph_start\n","            \n","            # Pad sequence and obtain inputs to model \n","            input_ids, token_type_ids, attention_mask = self.padding(input_ids_question, input_ids_paragraph)\n","            return torch.tensor(input_ids), torch.tensor(token_type_ids), torch.tensor(attention_mask), answer_start_token, answer_end_token\n","\n","        # Validation/Testing\n","        else:\n","            input_ids_list, token_type_ids_list, attention_mask_list = [], [], []\n","            \n","            # Paragraph is split into several windows, each with start positions separated by step \"doc_stride\"\n","            for i in range(0, len(tokenized_paragraph), self.doc_stride): # 文章總長度\n"," \n","                # Slice question/paragraph and add special tokens (101: CLS, 102: SEP)\n","                input_ids_question = [101] + tokenized_question.ids[:self.max_question_len] + [102] # ids取出問題\n","                input_ids_paragraph = tokenized_paragraph.ids[i : i + self.max_paragraph_len] + [102] # ids取出文章\n","                \n","                # Pad sequence and obtain inputs to model\n","                input_ids, token_type_ids, attention_mask = self.padding(input_ids_question, input_ids_paragraph)\n","                \n","                input_ids_list.append(input_ids)\n","                token_type_ids_list.append(token_type_ids)\n","                attention_mask_list.append(attention_mask)\n","            \n","            return torch.tensor(input_ids_list), torch.tensor(token_type_ids_list), torch.tensor(attention_mask_list)\n","\n","    def padding(self, input_ids_question, input_ids_paragraph):\n","        # Pad zeros if sequence length is shorter than max_seq_len\n","        padding_len = self.max_seq_len - len(input_ids_question) - len(input_ids_paragraph)\n","        # Indices of input sequence tokens in the vocabulary\n","        input_ids = input_ids_question + input_ids_paragraph + [0] * padding_len\n","        # Segment token indices to indicate first and second portions of the inputs. Indices are selected in [0, 1]\n","        token_type_ids = [0] * len(input_ids_question) + [1] * len(input_ids_paragraph) + [0] * padding_len\n","        # Mask to avoid performing attention on padding token indices. Mask values selected in [0, 1]\n","        attention_mask = [1] * (len(input_ids_question) + len(input_ids_paragraph)) + [0] * padding_len\n","        \n","        return input_ids, token_type_ids, attention_mask\n","\n","train_set = QA_Dataset(\"train\", train_questions, train_questions_tokenized, train_paragraphs_tokenized)\n","dev_set = QA_Dataset(\"dev\", dev_questions, dev_questions_tokenized, dev_paragraphs_tokenized)\n","test_set = QA_Dataset(\"test\", test_questions, test_questions_tokenized, test_paragraphs_tokenized)\n","\n","train_batch_size = 4\n","\n","# Note: Do NOT change batch size of dev_loader / test_loader !\n","# Although batch size=1, it is actually a batch consisting of several windows from the same QA pair\n","train_loader = DataLoader(train_set, batch_size=train_batch_size, shuffle=True, pin_memory=True)\n","dev_loader = DataLoader(dev_set, batch_size=1, shuffle=False, pin_memory=True)\n","test_loader = DataLoader(test_set, batch_size=1, shuffle=False, pin_memory=True)"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5_H1kqhR8CdM"},"source":["## Function for Evaluation"]},{"cell_type":"code","metadata":{"id":"SqeA3PLPxOHu","executionInfo":{"status":"ok","timestamp":1621162576282,"user_tz":-480,"elapsed":763,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}}},"source":["def evaluate(data, output):\n","    ##### TODO: Postprocessing #####\n","    # There is a bug and room for improvement in postprocessing \n","    # Hint: Open your prediction file to see what is wrong \n","    \n","    answer = ''\n","    max_prob = float('-inf')\n","    num_of_windows = data[0].shape[1]\n","\n","\n","    for k in range(num_of_windows):\n","        # Obtain answer by choosing the most probable start position / end position\n","        start_prob, start_index = torch.max(output.start_logits[k], dim=0)\n","        end_prob, end_index = torch.max(output.end_logits[k], dim=0)\n","\n","        # Probability of answer is calculated as sum of start_prob and end_prob\n","        prob = start_prob + end_prob\n","        \n","        # # Replace answer if calculated probability is larger than previous windows\n","        if prob > max_prob:\n","            max_prob = prob\n","            if start_index < end_index:\n","              \n","            # Convert tokens to chars (e.g. [1920, 7032] --> \"大 金\")\n","              answer = tokenizer.decode(data[0][0][k][start_index : end_index + 1])\n","            else:\n","              answer = ''\n","\n","    # Remove spaces in answer (e.g. \"大 金\" --> \"大金\")\n","\n","    return answer.replace(' ','')\n"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rzHQit6eMnKG"},"source":["## Training"]},{"cell_type":"code","metadata":{"id":"JvAhaTpi1QRt","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["36d9c916125043aeb24f5859c1fd7e18","a5a8999953e34c22854013b066fbc456","60cf6676db01470883f78e98cb721e2a","46ffe683adc84e7fb1a7af030efd2f89","3ac514dd82404b9ba14e5c079dc899bc","77dadad1bce94bb8a493d0326724feef","4b1000744ef840c580a6163ce03e414b","c15be8f7aba84088b78d9e67b9a76b8c","af0a9749dcfb4a8c944f5aad9c3be4f5","4e321d5a48bf4d299a0229706de070ad","27cffcf551f6407986c401545e4725fc","6735ddc0397e435da6e2b5da9996c4fc","022228ab222f493690983722d16ca8fe","a4f58c7f41794880a7362a2e7e48f301","9a747c2eb4864b88946de537f4e659d1","3c39c0aee6474fffa535e53f8293b2a8","e8ecbf9e2f07472d9e6f7d1deb07d0ce","39fcb2227ba7423486973071a693be69","9b4c407b50f8478097937c39913f2f61","4655aae0c65b45858f550f29abcf20fa","124ab250e53f4601ade249da818e9576","244f85d87004439ca01de48c9d59bffc","4be9bc27305e426a9afe1922d3d0a2fc","d467130bc39742e98d9513bf3fab8414","8eb24d40e4d740538ffa2434830c2af4","c683b86696774df89dd34090667743b6","835bbf05a2744956999863c9d8504add","037c560575434bc29716bad34d366a90","78b8557635784f3e89d33ec7e83e487f","bb7c262fb28344ba983a3381e0595689","7a01aaeff8584bddb8eb2cb1fcbb2e8a","0a06dfb3f6ec45e39ad83a4fdd6c8884"]},"executionInfo":{"status":"ok","timestamp":1621166680404,"user_tz":-480,"elapsed":3990630,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"075f76e4-f52f-4049-b9cc-5ef0d0aefeb9"},"source":["num_epoch = 2\n","validation = True\n","logging_step = 500\n","learning_rate = 2e-5\n","optimizer = AdamW(model.parameters(), lr=learning_rate)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 3000, gamma=0.6, last_epoch=-1)\n","if fp16_training:\n","    model, optimizer, train_loader = accelerator.prepare(model, optimizer, train_loader) \n","#accumulation_steps = 4\n","model.train()\n","\n","print(\"Start Training ...\")\n","\n","for epoch in range(num_epoch):\n","    step = 1\n","    learning_rate = 2e-5\n","    train_loss = train_acc = 0\n","    \n","    for data in tqdm(train_loader):\t\n","\n","        # Load all data into GPU\n","        data = [i.to(device) for i in data]\n","\n","        # Model inputs: input_ids, token_type_ids, attention_mask, start_positions, end_positions (Note: only \"input_ids\" is mandatory)\n","        # Model outputs: start_logits, end_logits, loss (return when start_positions/end_positions are provided)  \n","\n","        output = model(input_ids=data[0], token_type_ids=data[1], attention_mask=data[2], start_positions=data[3], end_positions=data[4])\n","\n","        # Choose the most probable start position / end position\n","        start_index = torch.argmax(output.start_logits, dim=1)\n","        end_index = torch.argmax(output.end_logits, dim=1)\n","        \n","        # Prediction is correct only if both start_index and end_index are correct\n","        train_acc += ((start_index == data[3]) & (end_index == data[4])).float().mean()\n","        train_loss += output.loss.item()\n","        #train_loss = output.loss.item() / accumulation_steps\n","        if fp16_training:\n","            accelerator.backward(output.loss)\n","\n","        else:\n","            output.loss.backward()\n","\n","        optimizer.step()\n","        optimizer.zero_grad()\n","        step += 1\n","\n","        ##### TODO: Apply linear learning rate decay #####\n","        scheduler.step()\n","        \n","        # Print training loss and accuracy over past logging step\n","        if step % logging_step == 0:\n","            print('Learning Rate :', optimizer.param_groups[0]['lr'])\n","            print(f\"Epoch {epoch + 1} | Step {step} | loss = {train_loss / logging_step:.3f}, acc = {train_acc / logging_step:.3f}\")\n","            train_loss = train_acc = 0\n","\n","    if validation:\n","        print(\"Evaluating Dev Set ...\")\n","        model.eval()\n","        with torch.no_grad():\n","            dev_acc = 0\n","            for i, data in enumerate(tqdm(dev_loader)):\n","                output = model(input_ids=data[0].squeeze(dim=0).to(device), token_type_ids=data[1].squeeze(dim=0).to(device),\n","                       attention_mask=data[2].squeeze(dim=0).to(device))\n","                # prediction is correct only if answer text exactly matches\n","                dev_acc += evaluate(data, output) == dev_questions[i][\"answer_text\"]\n","            print(f\"Validation | Epoch {epoch + 1} | acc = {dev_acc / len(dev_loader):.3f}\")\n","        model.train()\n","\n","# Save a model and its configuration file to the directory 「saved_model」 \n","# i.e. there are two files under the direcory 「saved_model」: 「pytorch_model.bin」 and 「config.json」\n","# Saved model can be re-loaded using 「model = BertForQuestionAnswering.from_pretrained(\"saved_model\")」\n","print(\"Saving Model ...\")\n","model_save_dir = \"/content/drive/MyDrive/bert/saved_model6\" \n","model.save_pretrained(model_save_dir)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Start Training ...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"36d9c916125043aeb24f5859c1fd7e18","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=6734.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Learning Rate : 2e-05\n","Epoch 1 | Step 500 | loss = 1.164, acc = 0.583\n","Learning Rate : 2e-05\n","Epoch 1 | Step 1000 | loss = 0.726, acc = 0.722\n","Learning Rate : 2e-05\n","Epoch 1 | Step 1500 | loss = 0.629, acc = 0.746\n","Learning Rate : 2e-05\n","Epoch 1 | Step 2000 | loss = 0.582, acc = 0.745\n","Learning Rate : 2e-05\n","Epoch 1 | Step 2500 | loss = 0.581, acc = 0.772\n","Learning Rate : 2e-05\n","Epoch 1 | Step 3000 | loss = 0.594, acc = 0.765\n","Learning Rate : 1.2e-05\n","Epoch 1 | Step 3500 | loss = 0.496, acc = 0.795\n","Learning Rate : 1.2e-05\n","Epoch 1 | Step 4000 | loss = 0.488, acc = 0.779\n","Learning Rate : 1.2e-05\n","Epoch 1 | Step 4500 | loss = 0.531, acc = 0.779\n","Learning Rate : 1.2e-05\n","Epoch 1 | Step 5000 | loss = 0.469, acc = 0.792\n","Learning Rate : 1.2e-05\n","Epoch 1 | Step 5500 | loss = 0.504, acc = 0.792\n","Learning Rate : 1.2e-05\n","Epoch 1 | Step 6000 | loss = 0.511, acc = 0.788\n","Learning Rate : 7.2e-06\n","Epoch 1 | Step 6500 | loss = 0.500, acc = 0.781\n","\n","Evaluating Dev Set ...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"af0a9749dcfb4a8c944f5aad9c3be4f5","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=3524.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Validation | Epoch 1 | acc = 0.799\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e8ecbf9e2f07472d9e6f7d1deb07d0ce","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=6734.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Learning Rate : 7.2e-06\n","Epoch 2 | Step 500 | loss = 0.217, acc = 0.886\n","Learning Rate : 7.2e-06\n","Epoch 2 | Step 1000 | loss = 0.232, acc = 0.880\n","Learning Rate : 7.2e-06\n","Epoch 2 | Step 1500 | loss = 0.178, acc = 0.903\n","Learning Rate : 7.2e-06\n","Epoch 2 | Step 2000 | loss = 0.214, acc = 0.880\n","Learning Rate : 4.319999999999999e-06\n","Epoch 2 | Step 2500 | loss = 0.200, acc = 0.888\n","Learning Rate : 4.319999999999999e-06\n","Epoch 2 | Step 3000 | loss = 0.193, acc = 0.897\n","Learning Rate : 4.319999999999999e-06\n","Epoch 2 | Step 3500 | loss = 0.201, acc = 0.895\n","Learning Rate : 4.319999999999999e-06\n","Epoch 2 | Step 4000 | loss = 0.193, acc = 0.892\n","Learning Rate : 4.319999999999999e-06\n","Epoch 2 | Step 4500 | loss = 0.212, acc = 0.890\n","Learning Rate : 4.319999999999999e-06\n","Epoch 2 | Step 5000 | loss = 0.225, acc = 0.884\n","Learning Rate : 2.5919999999999995e-06\n","Epoch 2 | Step 5500 | loss = 0.196, acc = 0.905\n","Learning Rate : 2.5919999999999995e-06\n","Epoch 2 | Step 6000 | loss = 0.208, acc = 0.891\n","Learning Rate : 2.5919999999999995e-06\n","Epoch 2 | Step 6500 | loss = 0.176, acc = 0.901\n","\n","Evaluating Dev Set ...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8eb24d40e4d740538ffa2434830c2af4","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=3524.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Validation | Epoch 2 | acc = 0.812\n","Saving Model ...\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kMmdLOKBMsdE"},"source":["## Testing"]},{"cell_type":"code","metadata":{"id":"cgDPXetkfYFl","executionInfo":{"status":"ok","timestamp":1621159633982,"user_tz":-480,"elapsed":106219,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}}},"source":["model = torch.load('/content/drive/MyDrive/bert/saved_model3/pytorch_model.bin')\n","model1 = torch.load('/content/drive/MyDrive/bert/saved_model2/pytorch_model.bin')\n","model2 = torch.load('/content/drive/MyDrive/bert/saved_model1/pytorch_model.bin')\n","model3 = torch.load('/content/drive/MyDrive/bert/saved_model4/pytorch_model.bin')\n","model4 = torch.load('/content/drive/MyDrive/bert/saved_model6/pytorch_model.bin')\n","model5 = torch.load('/content/drive/MyDrive/bert/saved_model7/pytorch_model.bin')"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"-wzWLygAVxxg","executionInfo":{"status":"ok","timestamp":1621159636168,"user_tz":-480,"elapsed":502,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}}},"source":["import collections\n","model_en = collections.OrderedDict()\n","for key, value in model.items(): \n","    if key in model1: \n","     model_en[key] = (model[key] + model1[key] + model2[key] + model3[key])/4"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xO2IfErSV1Ui","executionInfo":{"status":"ok","timestamp":1621159650115,"user_tz":-480,"elapsed":12672,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"2de42d0f-e8a8-4dee-9a03-a268dae966f7"},"source":["# loading model\n","model = BertForQuestionAnswering.from_pretrained(\"hfl/chinese-roberta-wwm-ext-large\").to(device)\n","\n","model.load_state_dict(model_en)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at hfl/chinese-roberta-wwm-ext-large were not used when initializing BertForQuestionAnswering: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at hfl/chinese-roberta-wwm-ext-large and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"U5scNKC9xz0C","colab":{"base_uri":"https://localhost:8080/","height":100,"referenced_widgets":["6083b09400e64876b920d63126faea4a","d3feed738b0e441fab2ca614370620d2","bdc9758f090e486287994b5445895b68","cdf8e8a149f54a4d9b40548a842b7546","adb1d6adefc14768a417170f2fc6cf1b","acc7b11a20ee4c6088ae0c1d30489581","30013ce76c4d40768ca778e4d1b38cf5","a268672c1800432ba6b0e095bacf8b59"]},"executionInfo":{"status":"ok","timestamp":1621161515375,"user_tz":-480,"elapsed":1857245,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"ee7ed70e-33e3-44fc-f019-87d3b052860d"},"source":["print(\"Evaluating Test Set ...\")\n","\n","result = []\n","out = []\n","model.eval()\n","with torch.no_grad():\n","    for data in tqdm(test_loader):\n","        output = model(input_ids=data[0].squeeze(dim=0).to(device), token_type_ids=data[1].squeeze(dim=0).to(device),\n","                       attention_mask=data[2].squeeze(dim=0).to(device))\n","        result.append(evaluate(data, output))\n","\n","result_file = \"/content/result.csv\"\n","#result_file = \"/content/drive/MyDrive/result.csv\"\n","with open(result_file, 'w') as f:\t\n","\t  f.write(\"ID,Answer\\n\")\n","\t  for i, test_question in enumerate(test_questions):\n","        # Replace commas in answers with empty strings (since csv is separated by comma)\n","        # Answers in kaggle are processed in the same way\n","\t\t    f.write(f\"{test_question['id']},{result[i].replace(',','')}\\n\")\n","\n","print(f\"Completed! Result is in {result_file}\")"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Evaluating Test Set ...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6083b09400e64876b920d63126faea4a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=3493.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Completed! Result is in /content/result.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MavupMZAPskZ","executionInfo":{"status":"ok","timestamp":1621161767364,"user_tz":-480,"elapsed":842,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}}},"source":["import pandas as pd\n","pd.set_option('display.max_rows', None)\n","#result = pd.read_csv('/content/drive/MyDrive/result_en.csv')\n","result = pd.read_csv(\"/content/result.csv\")\n","unk = result[result['Answer'].str.contains('UNK') == True]\n","id = unk['ID'].to_list()\n","sub = unk['ID'].astype(str).tolist()\n","result['Answer'] = result['Answer'].apply(lambda x: str(x).replace('[UNK]', '.'))"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H9S_-45IdXoQ","executionInfo":{"status":"ok","timestamp":1621161768532,"user_tz":-480,"elapsed":1038,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"9333d689-9350-4ed4-a5bf-df112b016031"},"source":["import re\n","for i in sub:\n","    try:\n","        content = test_paragraphs[test_questions[int(i)]['paragraph_id']]\n","        pred = result.iloc[int(i)][1]\n","        print(pred)\n","\n","        res = re.search(pred, content)\n","        a = res.span()\n","        start = a[0]\n","        end = a[-1]\n","        result.iloc[int(i),1] = test_paragraphs[test_questions[int(i)]['paragraph_id']][start:end]\n","    except:\n","      pass"],"execution_count":14,"outputs":[{"output_type":"stream","text":["溥.\n","目前沒有觀察到任何語言純.以力道來區分不同輔音\n",".人國\n","馬.\n","東晉常.\n",".稻\n","白.紀滅絕事件\n","抗佝.病\n","杭州.橋機場\n","蔡.\n","丁.\n","隋.帝\n","胡季.\n","英文縮寫首字母為「.·ㄎㄟ·ㄨㄞ」\n","梁.\n",".靼海峽\n","白.紀末滅絕事件\n","侏.紀\n","克里米亞.靼人\n","白.紀中期\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"JT1RT9JZlnI_","executionInfo":{"status":"ok","timestamp":1621161768991,"user_tz":-480,"elapsed":522,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"6bfbf3b9-55b7-46f6-d81e-9265cc14095f"},"source":["result.iloc[int(250),1]"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'溥儁'"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"yrSt1MA7SIA6","executionInfo":{"status":"ok","timestamp":1621161769911,"user_tz":-480,"elapsed":948,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}}},"source":["\n","result.to_csv('/content/result_postprocess.csv', index=False)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"TT1Z4Ivy9DSN"},"source":["# Ensemble\n","\n","\n"],"execution_count":null,"outputs":[]}]}