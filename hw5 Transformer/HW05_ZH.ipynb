{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"HW05_ZH.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"16e38fbca53c40b087d971257ffe1fe0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d72dfe4b8ece46e8a2e19ac205168ab2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_681d2de321b744fd995ed3f45e99ae7c","IPY_MODEL_48552e6b8232422ca6b6b5da3943e671"]}},"d72dfe4b8ece46e8a2e19ac205168ab2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"681d2de321b744fd995ed3f45e99ae7c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_45dd7828ca2844cbbbe2179e257cfa2a","_dom_classes":[],"description":"train epoch 31:  87%","_model_name":"FloatProgressModel","bar_style":"","max":818,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":710,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bf7028e3ee9d424ba356f28c5ffac623"}},"48552e6b8232422ca6b6b5da3943e671":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8ebc436bfe5f427483bf0e5848519ee3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 710/818 [04:22&lt;00:41,  2.61it/s, loss=1.97]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5b158534a86648b38790714a472e12bc"}},"45dd7828ca2844cbbbe2179e257cfa2a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bf7028e3ee9d424ba356f28c5ffac623":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8ebc436bfe5f427483bf0e5848519ee3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5b158534a86648b38790714a472e12bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"318f75d9d8334baaa62385f48af8af0a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d2c18e76d5154b27bf1d3a06f6d2db87","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_dd9f8f637e344ba6a931b04be6ad59e6","IPY_MODEL_c002b5effdc3435487b06ed68444454d"]}},"d2c18e76d5154b27bf1d3a06f6d2db87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dd9f8f637e344ba6a931b04be6ad59e6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5dd4b6a9e2f44c80aa8d996b069a6d60","_dom_classes":[],"description":"train epoch 32:  58%","_model_name":"FloatProgressModel","bar_style":"","max":818,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":476,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_50ec20aae90440089630aeac6384d302"}},"c002b5effdc3435487b06ed68444454d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_92319027210c4c739da8f9aa28814551","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 476/818 [02:56&lt;01:55,  2.97it/s, loss=1.97]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_752b998c63e6466f921582cc4484601d"}},"5dd4b6a9e2f44c80aa8d996b069a6d60":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"50ec20aae90440089630aeac6384d302":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"92319027210c4c739da8f9aa28814551":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"752b998c63e6466f921582cc4484601d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2124bb656544416cb7fc351b30700aa5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e310a1656bb4400f93d62b5d451ccac2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_23595079044e41a8a98d5205553c98df","IPY_MODEL_3b3fa8478ba245fa861820c8f1e7f319"]}},"e310a1656bb4400f93d62b5d451ccac2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"23595079044e41a8a98d5205553c98df":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8852c9deedb64b0cb9a98d150565e423","_dom_classes":[],"description":"validation: 100%","_model_name":"FloatProgressModel","bar_style":"","max":27,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":27,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_83b22f2ac3c24064b09d8cde92e85603"}},"3b3fa8478ba245fa861820c8f1e7f319":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ebb1081450154be296ef5b882a828488","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 27/27 [00:30&lt;00:00,  1.56s/it, valid_loss=3.2]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_95301ff06e1a4fe6b7c9b679b8ea881f"}},"8852c9deedb64b0cb9a98d150565e423":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"83b22f2ac3c24064b09d8cde92e85603":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ebb1081450154be296ef5b882a828488":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"95301ff06e1a4fe6b7c9b679b8ea881f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d1467beaff7b451aa78c77c74b183be9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2085ac863b5342cc90c7470a6ff27cbc","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d58e2481570c4bdf8d79d4712d0894fa","IPY_MODEL_f3b6d15fccb6486ba9ba8e87b59182e2"]}},"2085ac863b5342cc90c7470a6ff27cbc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d58e2481570c4bdf8d79d4712d0894fa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e30c14d5e2b14b608bae0129911aa7a3","_dom_classes":[],"description":"train epoch 34:   4%","_model_name":"FloatProgressModel","bar_style":"","max":818,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":29,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5439b29fe68e4b1486202d867de29b8e"}},"f3b6d15fccb6486ba9ba8e87b59182e2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c0c5ac146c4244c59ddb641c2258310c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 29/818 [00:10&lt;04:57,  2.65it/s, loss=1.83]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4c0ced99f38342fb9fbef91d8c3a9b99"}},"e30c14d5e2b14b608bae0129911aa7a3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5439b29fe68e4b1486202d867de29b8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c0c5ac146c4244c59ddb641c2258310c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4c0ced99f38342fb9fbef91d8c3a9b99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ac8fd36b760b4a37944694797c4ccad8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2faf265c8e024192b7937c34e997c913","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_64b2cdb2ef664851889009307c483362","IPY_MODEL_3c92e4eeb8c2407f9342ac2468fd9f01"]}},"2faf265c8e024192b7937c34e997c913":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"64b2cdb2ef664851889009307c483362":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_35de21041d7b40538208fd3992cf41cb","_dom_classes":[],"description":"validation: 100%","_model_name":"FloatProgressModel","bar_style":"","max":27,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":27,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c69c1d8ddd5449208ee0560e9a4268f1"}},"3c92e4eeb8c2407f9342ac2468fd9f01":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e4a2bd19bfed420aa219b255af295ae8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 27/27 [00:30&lt;00:00,  1.55s/it, valid_loss=2.96]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2eb49c9661ea4264880b5c23b0ab41d0"}},"35de21041d7b40538208fd3992cf41cb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c69c1d8ddd5449208ee0560e9a4268f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e4a2bd19bfed420aa219b255af295ae8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2eb49c9661ea4264880b5c23b0ab41d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"76c81bffc5564940be82b1a85da5170a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7086b2d44d3e408bbb3527d51447721a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_836ff4bd26ca4fafac79dc0f25b2fdb5","IPY_MODEL_9a12c310d6a5497bb36e490df94492c6"]}},"7086b2d44d3e408bbb3527d51447721a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"836ff4bd26ca4fafac79dc0f25b2fdb5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_50410a2540ed4c889b16d5367b0983d9","_dom_classes":[],"description":"prediction: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":17,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":17,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1ab7bd1180394313a520cc3c47c64f82"}},"9a12c310d6a5497bb36e490df94492c6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9a240c5fbf8441c9a2b97eb4d7490d53","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 17/17 [4:33:44&lt;00:00, 966.13s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_87937cb1115d478b95de892a400dd14f"}},"50410a2540ed4c889b16d5367b0983d9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1ab7bd1180394313a520cc3c47c64f82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9a240c5fbf8441c9a2b97eb4d7490d53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"87937cb1115d478b95de892a400dd14f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b3b370b5163147648e81932b204e2c81":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0944f60aff934b9586d9dcbd58e911d9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_51f71ce7426744979ab05bcf81753b01","IPY_MODEL_8a844929f7e94b0d84830c7cc09e521c"]}},"0944f60aff934b9586d9dcbd58e911d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"51f71ce7426744979ab05bcf81753b01":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3b10cf39550542fbbae24b27abc8990a","_dom_classes":[],"description":"prediction: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1766,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1766,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_77d4ff7050e64d219ada3b8f2bd25818"}},"8a844929f7e94b0d84830c7cc09e521c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f94118b291e64fbbad603c36ec1cdc6f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1766/1766 [1:22:04&lt;00:00,  2.79s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f668ca1b567d4dc38986f21a3ba75f90"}},"3b10cf39550542fbbae24b27abc8990a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"77d4ff7050e64d219ada3b8f2bd25818":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f94118b291e64fbbad603c36ec1cdc6f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f668ca1b567d4dc38986f21a3ba75f90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5e3bb939e4ad40788b4604759ef032c7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1806c2bbb3bc4736ab9d87f5edbc42af","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bb39fc69c13e4758969f6177b9e49bb9","IPY_MODEL_3ec1b351144f466a92c104c9c3ab8968"]}},"1806c2bbb3bc4736ab9d87f5edbc42af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bb39fc69c13e4758969f6177b9e49bb9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b027ad5ace0142dab1db246b734f5e52","_dom_classes":[],"description":"train epoch 1: 100%","_model_name":"FloatProgressModel","bar_style":"","max":1913,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1913,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3021ece5a59b4f1c89547e74f1522dfe"}},"3ec1b351144f466a92c104c9c3ab8968":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_af45dd2c37304d1f968f3ae1a5508ca4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1913/1913 [12:19&lt;00:00,  3.15it/s, loss=2.33]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_419a6a6e131e450d9147a7bba761cc1a"}},"b027ad5ace0142dab1db246b734f5e52":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3021ece5a59b4f1c89547e74f1522dfe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"af45dd2c37304d1f968f3ae1a5508ca4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"419a6a6e131e450d9147a7bba761cc1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"56b4a0aa971c4472bc73b309170ec67a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d3b9c14c79b9443da0422eb012990412","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e4e132aa18cb468d8b9b6d517653bb05","IPY_MODEL_f853cfeb265d439e86586c64f87036f8"]}},"d3b9c14c79b9443da0422eb012990412":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e4e132aa18cb468d8b9b6d517653bb05":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0fd3cb74ad194ad693c41e0850518fd1","_dom_classes":[],"description":"validation: 100%","_model_name":"FloatProgressModel","bar_style":"","max":23,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":23,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a6790f1f742f430487b9dbe5fa1dc62d"}},"f853cfeb265d439e86586c64f87036f8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1569d0b5632044e68f615a8628e2b61d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 23/23 [00:27&lt;00:00,  1.62s/it, valid_loss=3.18]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8e9eba823f6e43b1ab0b49440948455a"}},"0fd3cb74ad194ad693c41e0850518fd1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a6790f1f742f430487b9dbe5fa1dc62d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1569d0b5632044e68f615a8628e2b61d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8e9eba823f6e43b1ab0b49440948455a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5955642a9671400590eeaab8c3da248e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_38926a9afd60421091d96d0decdd110a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_07b4398f088f4181a16685633c44a667","IPY_MODEL_57d2529f77b74010a2d398200741c3c4"]}},"38926a9afd60421091d96d0decdd110a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"07b4398f088f4181a16685633c44a667":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d3ba07ca85b24c52b86e3a99bae00a59","_dom_classes":[],"description":"train epoch 2: 100%","_model_name":"FloatProgressModel","bar_style":"","max":1913,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1913,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_026a167097ba4acea537bd167dd4adca"}},"57d2529f77b74010a2d398200741c3c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b7dabdf6694744b8932a3d739151ceb9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1913/1913 [12:23&lt;00:00,  2.95it/s, loss=2.25]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9cb32eb777624089bba0dedfec157646"}},"d3ba07ca85b24c52b86e3a99bae00a59":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"026a167097ba4acea537bd167dd4adca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b7dabdf6694744b8932a3d739151ceb9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9cb32eb777624089bba0dedfec157646":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"30dd49d583b14228857e98f92b098d6a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0073f3ba742544f9bf156c4aed0d4780","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_488b3374137b4682b05b1a76c21c091e","IPY_MODEL_b55d8985907a413b8c24cc984d579ba6"]}},"0073f3ba742544f9bf156c4aed0d4780":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"488b3374137b4682b05b1a76c21c091e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8866c057eb3c406bae059545c726923a","_dom_classes":[],"description":"validation: 100%","_model_name":"FloatProgressModel","bar_style":"","max":23,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":23,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_94c6d1f804c948fa95277045103e0101"}},"b55d8985907a413b8c24cc984d579ba6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_04887ba8df2b4e9088651865a53fc5b1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 23/23 [00:26&lt;00:00,  1.53s/it, valid_loss=3.18]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2e65a887b407438db71c14dacf76586c"}},"8866c057eb3c406bae059545c726923a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"94c6d1f804c948fa95277045103e0101":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"04887ba8df2b4e9088651865a53fc5b1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2e65a887b407438db71c14dacf76586c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e84084fe97c14fd3b3a791f063780eec":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e2b9f942b2e34fca819c57622b0afe76","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bab4ed991328437dbd9be356124acd49","IPY_MODEL_ff964ea23daa4ff5b94998e31cfe3b24"]}},"e2b9f942b2e34fca819c57622b0afe76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bab4ed991328437dbd9be356124acd49":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d256db765fb746e5ac5af30a7b497a2a","_dom_classes":[],"description":"train epoch 3: 100%","_model_name":"FloatProgressModel","bar_style":"","max":1913,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1913,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d5c26abb92b54c7db1671e8eea4437e3"}},"ff964ea23daa4ff5b94998e31cfe3b24":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_71fb6ed333d94c57afdc8a6d4439d4bf","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1913/1913 [12:19&lt;00:00,  3.09it/s, loss=2.24]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_11ecc6bc285f491a918483187046fd2b"}},"d256db765fb746e5ac5af30a7b497a2a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d5c26abb92b54c7db1671e8eea4437e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"71fb6ed333d94c57afdc8a6d4439d4bf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"11ecc6bc285f491a918483187046fd2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"77a67878de16477880a16272855855c7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f81163f138da47bda444260f38153d0e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5e66b03cd7b3466a9785fa9f473175c4","IPY_MODEL_6948b9c0e90b4024a71d1d26e189b605"]}},"f81163f138da47bda444260f38153d0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5e66b03cd7b3466a9785fa9f473175c4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e35303b6f5b54abaabb9239ebb92a828","_dom_classes":[],"description":"validation: 100%","_model_name":"FloatProgressModel","bar_style":"","max":23,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":23,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_095cdc5a695149f89251ac99a3deeb27"}},"6948b9c0e90b4024a71d1d26e189b605":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_af499e7f0f0e4ff9ac16dc11a736653e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 23/23 [00:26&lt;00:00,  1.53s/it, valid_loss=3.17]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_02887806d174445583de5c3ee39f65b2"}},"e35303b6f5b54abaabb9239ebb92a828":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"095cdc5a695149f89251ac99a3deeb27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"af499e7f0f0e4ff9ac16dc11a736653e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"02887806d174445583de5c3ee39f65b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"22cc82b8b3a54696ac74226aa29641b4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b0644dc90ef64daa98f37085ff42904d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_93d9645b3bb94af7bffa6b464a7a042e","IPY_MODEL_df523cd6159042319d4f739f2e3e55c0"]}},"b0644dc90ef64daa98f37085ff42904d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"93d9645b3bb94af7bffa6b464a7a042e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_74d5f470a43d4ac59c38c8713a517c93","_dom_classes":[],"description":"train epoch 4: 100%","_model_name":"FloatProgressModel","bar_style":"","max":1913,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1913,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fea39a9c518047f5a485012ff5480b4d"}},"df523cd6159042319d4f739f2e3e55c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a4cbd89a88674bdbb0fa30b518d8e121","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1913/1913 [12:14&lt;00:00,  3.12it/s, loss=2.28]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8e57947cdd1e48529814d9b62ccf721b"}},"74d5f470a43d4ac59c38c8713a517c93":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"fea39a9c518047f5a485012ff5480b4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a4cbd89a88674bdbb0fa30b518d8e121":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8e57947cdd1e48529814d9b62ccf721b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cba225d30aee4377a380cf40cd91ab8c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0f2c7e10f0404ffba85fea9e5cc9cb2c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_73ef102f0a7d4ee395bd65b5895f4def","IPY_MODEL_566aac4ba4cc4dbb83f58cb2e22233d7"]}},"0f2c7e10f0404ffba85fea9e5cc9cb2c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"73ef102f0a7d4ee395bd65b5895f4def":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_728ca246aeed4905af7ca9aed6d65271","_dom_classes":[],"description":"validation: 100%","_model_name":"FloatProgressModel","bar_style":"","max":23,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":23,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5b9cf8d30ac046d1be561b4cef3e1e2a"}},"566aac4ba4cc4dbb83f58cb2e22233d7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_44895d63a68343ecacdf8722b6dcc059","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 23/23 [00:26&lt;00:00,  1.63s/it, valid_loss=3.19]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c2433be36fea48f394a107278855b585"}},"728ca246aeed4905af7ca9aed6d65271":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5b9cf8d30ac046d1be561b4cef3e1e2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"44895d63a68343ecacdf8722b6dcc059":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c2433be36fea48f394a107278855b585":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ae50643713864fd6980006feff7ed29c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f54a1b9084d04d8b951090adc3243e79","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c3d1fb5a8c0d4dbe9961cf18f70facb2","IPY_MODEL_08ed9c0cca2844e28ca099b33870b50a"]}},"f54a1b9084d04d8b951090adc3243e79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c3d1fb5a8c0d4dbe9961cf18f70facb2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_147046e0f2c64227a553482909bbe25c","_dom_classes":[],"description":"train epoch 5:  19%","_model_name":"FloatProgressModel","bar_style":"danger","max":1913,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":370,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7e718f7b74584407813ffef9523db031"}},"08ed9c0cca2844e28ca099b33870b50a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_51cf2227c2bd498ead9dc8ff2806f0eb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 370/1913 [02:22&lt;10:03,  2.56it/s, loss=2.24]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1c8a3d20148b482f91c8f44b20f44463"}},"147046e0f2c64227a553482909bbe25c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7e718f7b74584407813ffef9523db031":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"51cf2227c2bd498ead9dc8ff2806f0eb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1c8a3d20148b482f91c8f44b20f44463":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b908233102f144eea231e82be55001b1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_28392ec4f2e444d59fc3f36f65d301cc","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_77e26d042a23461096f3aeeba69a20c1","IPY_MODEL_d75bf5733d8e4b198d197c524916990e"]}},"28392ec4f2e444d59fc3f36f65d301cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"77e26d042a23461096f3aeeba69a20c1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_43c43a681de64febb13729c98636a8e2","_dom_classes":[],"description":"validation: 100%","_model_name":"FloatProgressModel","bar_style":"","max":23,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":23,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8a0e0d1bac7b4438a0f794e34d6f635b"}},"d75bf5733d8e4b198d197c524916990e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b3fcab80f104433a8c89babc3eb2a5ba","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 23/23 [00:27&lt;00:00,  1.66s/it, valid_loss=3.14]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cf370d4a307e4d0e930e36be6e0318b6"}},"43c43a681de64febb13729c98636a8e2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8a0e0d1bac7b4438a0f794e34d6f635b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b3fcab80f104433a8c89babc3eb2a5ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"cf370d4a307e4d0e930e36be6e0318b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4cea1bc37a694a998a117dd24996edcb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ee4b53b80ce44f5faeadec7a852d3f8c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7f50ee76fd6341d0a8a09dd642ed337f","IPY_MODEL_da7749d0e58e45ac80617f38c11139d0"]}},"ee4b53b80ce44f5faeadec7a852d3f8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7f50ee76fd6341d0a8a09dd642ed337f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0288b2c6045b436c83bd99ed634ec425","_dom_classes":[],"description":"prediction: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":17,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":17,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_194dd4abbeac46fbb560909f34f76f53"}},"da7749d0e58e45ac80617f38c11139d0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_62713f646bed4602adf7d5819490c9e6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 17/17 [14:12&lt;00:00, 50.15s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6aab4866262f415dbada8cb549d59249"}},"0288b2c6045b436c83bd99ed634ec425":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"194dd4abbeac46fbb560909f34f76f53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"62713f646bed4602adf7d5819490c9e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6aab4866262f415dbada8cb549d59249":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"mtj7kcY-On-j"},"source":["# **Homework 5 - Sequence-to-sequence**\n","\n","若有任何問題，歡迎來信至助教信箱 ntu-ml-2021spring-ta@googlegroups.com"]},{"cell_type":"markdown","metadata":{"id":"TzF8A3rIOn-q"},"source":["### (4/21 Updates)\n","1. Link to reference [training curves](https://wandb.ai/george0828zhang/hw5.seq2seq.new).\n","\n","### (4/14 Updates) \n","1. Link to tutorial [video](https://youtu.be/htG5WpZVQPU).\n","2. Now defaults to load `\"avg_last_5_checkpoint.pt\"` to generate prediction.\n","3. Expected run time on Colab with Tesla T4\n","\n","|Baseline|Details|Total Time|\n","|-|:-:|:-:|\n","|Simple|2m 15s $\\times$30 epochs|1hr 8m|\n","|Medium|4m $\\times$30 epochs|2hr|\n","|Strong|8m $\\times$30 epochs (backward)<br>+1hr (back-translation)<br>+15m $\\times$30 epochs (forward)|12hr 30m|"]},{"cell_type":"markdown","metadata":{"id":"wwwxaLjxOn-r"},"source":["# Sequence-to-Sequence 介紹\n","- 大多數常見的 seq2seq model 為 encoder-decoder model，主要由兩個部分組成，分別是 encoder 和 decoder，而這兩個部可以使用 recurrent neural network (RNN)或 transformer 來實作，主要是用來解決輸入和輸出的長度不一樣的情況\n","- **Encoder** 是將一連串的輸入，如文字、影片、聲音訊號等，編碼為單個向量，這單個向量可以想像為是整個輸入的抽象表示，包含了整個輸入的資訊\n","- **Decoder** 是將 encoder 輸出的單個向量逐步解碼，一次輸出一個結果，直到將最後目標輸出被產生出來為止，每次輸出會影響下一次的輸出，一般會在開頭加入 \"< BOS >\" 來表示開始解碼，會在結尾輸出 \"< EOS >\" 來表示輸出結束\n","\n","\n","![seq2seq](https://i.imgur.com/0zeDyuI.png)"]},{"cell_type":"markdown","metadata":{"id":"rggQzN9TOn-s"},"source":["# 作業介紹\n","- 英文翻譯中文\n","  - 輸入： 一句英文 （e.g.\t\ttom is a student .） \n","  - 輸出： 中文翻譯 （e.g. \t\t湯姆 是 個 學生 。）\n","\n","- TODO\n","  - 訓練一個 RNN 模型達到 Seq2seq 翻譯\n","  - 訓練一個 Transformer 大幅提升效能\n","  - 實作 Back-translation 大幅提升效能"]},{"cell_type":"markdown","metadata":{"id":"ajJNX-2MOn-s"},"source":["# 下載和引入需要的函式庫"]},{"cell_type":"code","metadata":{"id":"e5beYgcS5PLK","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1619675709686,"user_tz":-480,"elapsed":817,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"2b1a3844-9f41-4faf-fd2d-27b81ca90c38"},"source":["import torch\n","torch.cuda.get_device_name()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Tesla V100-SXM2-16GB'"]},"metadata":{"tags":[]},"execution_count":69}]},{"cell_type":"code","metadata":{"id":"gDj2-mAbOn-s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619661842415,"user_tz":-480,"elapsed":13950,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"2c334a75-6ad7-4b1d-cd17-43b041abc3fe"},"source":["!pip install 'torch>=1.6.0' editdistance matplotlib sacrebleu sacremoses sentencepiece tqdm wandb\n","!pip install --upgrade jupyter ipywidgets"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n","Requirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (0.5.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n","Collecting sacrebleu\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/57/0c7ca4e31a126189dab99c19951910bd081dea5bbd25f24b77107750eae7/sacrebleu-1.5.1-py3-none-any.whl (54kB)\n","\u001b[K     |████████████████████████████████| 61kB 6.2MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 11.6MB/s \n","\u001b[?25hCollecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 33.7MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n","Collecting wandb\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/ee/d755f9e5466df64c8416a2c6a860fb3aaa43ed6ea8e8e8e81460fda5788b/wandb-0.10.28-py2.py3-none-any.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.1MB 57.1MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0) (3.7.4.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.1)\n","Collecting portalocker==2.0.0\n","  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses) (7.1.2)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacremoses) (2019.12.20)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.15.0)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Collecting shortuuid>=0.5.0\n","  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Collecting sentry-sdk>=0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/92/5a33be64990ba815364a8f2dd9e6f51de60d23dfddafb4f1fc5577d4dc64/sentry_sdk-1.0.0-py2.py3-none-any.whl (131kB)\n","\u001b[K     |████████████████████████████████| 133kB 57.9MB/s \n","\u001b[?25hCollecting docker-pycreds>=0.4.0\n","  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n","Collecting configparser>=3.8.1\n","  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n","Collecting subprocess32>=3.5.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n","\u001b[K     |████████████████████████████████| 102kB 12.4MB/s \n","\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Collecting pathtools\n","  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n","Collecting GitPython>=1.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n","\u001b[K     |████████████████████████████████| 163kB 48.9MB/s \n","\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (56.0.0)\n","Collecting gitdb<5,>=4.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n","\u001b[K     |████████████████████████████████| 71kB 9.2MB/s \n","\u001b[?25hCollecting smmap<5,>=3.0.1\n","  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n","Building wheels for collected packages: subprocess32, pathtools\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=577b7afb8ed59efd72deab8ba7f8330819af1ff33b818e3b0972a20233d68dcb\n","  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=444d4c3149b84e28de9757463fc09b7c0d91b04d3cec9d060c92dea958db3952\n","  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n","Successfully built subprocess32 pathtools\n","Installing collected packages: portalocker, sacrebleu, sacremoses, sentencepiece, shortuuid, sentry-sdk, docker-pycreds, configparser, subprocess32, pathtools, smmap, gitdb, GitPython, wandb\n","Successfully installed GitPython-3.1.14 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 portalocker-2.0.0 sacrebleu-1.5.1 sacremoses-0.0.45 sentencepiece-0.1.95 sentry-sdk-1.0.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.10.28\n","Requirement already up-to-date: jupyter in /usr/local/lib/python3.7/dist-packages (1.0.0)\n","Requirement already up-to-date: ipywidgets in /usr/local/lib/python3.7/dist-packages (7.6.3)\n","Requirement already satisfied, skipping upgrade: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter) (5.6.1)\n","Requirement already satisfied, skipping upgrade: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter) (5.2.0)\n","Requirement already satisfied, skipping upgrade: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter) (5.0.3)\n","Requirement already satisfied, skipping upgrade: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter) (4.10.1)\n","Requirement already satisfied, skipping upgrade: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter) (5.3.1)\n","Requirement already satisfied, skipping upgrade: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.5.0)\n","Requirement already satisfied, skipping upgrade: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.0.5)\n","Requirement already satisfied, skipping upgrade: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (5.1.3)\n","Requirement already satisfied, skipping upgrade: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (3.5.1)\n","Requirement already satisfied, skipping upgrade: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets) (1.0.0)\n","Requirement already satisfied, skipping upgrade: pygments in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter) (2.6.1)\n","Requirement already satisfied, skipping upgrade: jinja2>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter) (2.11.3)\n","Requirement already satisfied, skipping upgrade: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter) (1.4.3)\n","Requirement already satisfied, skipping upgrade: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter) (0.4.4)\n","Requirement already satisfied, skipping upgrade: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter) (3.3.0)\n","Requirement already satisfied, skipping upgrade: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter) (0.7.1)\n","Requirement already satisfied, skipping upgrade: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter) (0.3)\n","Requirement already satisfied, skipping upgrade: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter) (0.8.4)\n","Requirement already satisfied, skipping upgrade: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter) (4.7.1)\n","Requirement already satisfied, skipping upgrade: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter) (1.0.18)\n","Requirement already satisfied, skipping upgrade: jupyter-client in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter) (5.3.5)\n","Requirement already satisfied, skipping upgrade: pyzmq>=17.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter) (22.0.3)\n","Requirement already satisfied, skipping upgrade: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter) (0.2.0)\n","Requirement already satisfied, skipping upgrade: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter) (1.9.0)\n","Requirement already satisfied, skipping upgrade: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter) (5.1.1)\n","Requirement already satisfied, skipping upgrade: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter) (1.5.0)\n","Requirement already satisfied, skipping upgrade: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter) (0.9.4)\n","Requirement already satisfied, skipping upgrade: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.8.1)\n","Requirement already satisfied, skipping upgrade: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (4.8.0)\n","Requirement already satisfied, skipping upgrade: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (56.0.0)\n","Requirement already satisfied, skipping upgrade: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.7.5)\n","Requirement already satisfied, skipping upgrade: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (4.4.2)\n","Requirement already satisfied, skipping upgrade: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets) (2.6.0)\n","Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.4->nbconvert->jupyter) (1.1.1)\n","Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter) (20.9)\n","Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter) (1.15.0)\n","Requirement already satisfied, skipping upgrade: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter) (0.5.1)\n","Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter) (0.2.5)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->jupyter-console->jupyter) (2.8.1)\n","Requirement already satisfied, skipping upgrade: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter) (0.7.0)\n","Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->bleach->nbconvert->jupyter) (2.4.7)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"K702cdwQOn-t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619661900590,"user_tz":-480,"elapsed":71229,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"e77b53ba-090f-4dc2-9eda-ec644264cb2f"},"source":["!git clone https://github.com/pytorch/fairseq.git\n","!cd fairseq && git checkout 9a1c497\n","!pip install --upgrade ./fairseq/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'fairseq'...\n","remote: Enumerating objects: 27730, done.\u001b[K\n","remote: Counting objects: 100% (151/151), done.\u001b[K\n","remote: Compressing objects: 100% (91/91), done.\u001b[K\n","remote: Total 27730 (delta 71), reused 113 (delta 60), pack-reused 27579\u001b[K\n","Receiving objects: 100% (27730/27730), 11.61 MiB | 20.79 MiB/s, done.\n","Resolving deltas: 100% (20892/20892), done.\n","Note: checking out '9a1c497'.\n","\n","You are in 'detached HEAD' state. You can look around, make experimental\n","changes and commit them, and you can discard any commits you make in this\n","state without impacting any branches by performing another checkout.\n","\n","If you want to create a new branch to retain commits you create, you may\n","do so (now or later) by using -b with the checkout command again. Example:\n","\n","  git checkout -b <new-branch-name>\n","\n","HEAD is now at 9a1c4970 Make Hydra logging work with DDP (#1568)\n","Processing ./fairseq\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied, skipping upgrade: sacrebleu>=1.4.12 in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+9a1c497) (1.5.1)\n","Requirement already satisfied, skipping upgrade: numpy; python_version >= \"3.7\" in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+9a1c497) (1.19.5)\n","Requirement already satisfied, skipping upgrade: cython in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+9a1c497) (0.29.22)\n","Requirement already satisfied, skipping upgrade: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+9a1c497) (1.14.5)\n","Collecting omegaconf<2.1\n","  Downloading https://files.pythonhosted.org/packages/d0/eb/9d63ce09dd8aa85767c65668d5414958ea29648a0eec80a4a7d311ec2684/omegaconf-2.0.6-py3-none-any.whl\n","Collecting hydra-core<1.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/e3/fbd70dd0d3ce4d1d75c22d56c0c9f895cfa7ed6587a9ffb821d6812d6a60/hydra_core-1.0.6-py3-none-any.whl (123kB)\n","\u001b[K     |████████████████████████████████| 133kB 14.0MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+9a1c497) (2019.12.20)\n","Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+9a1c497) (4.41.1)\n","Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+9a1c497) (1.8.1+cu101)\n","Requirement already satisfied, skipping upgrade: portalocker==2.0.0 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+9a1c497) (2.0.0)\n","Requirement already satisfied, skipping upgrade: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq==1.0.0a0+9a1c497) (2.20)\n","Collecting PyYAML>=5.1.*\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n","\u001b[K     |████████████████████████████████| 645kB 23.4MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from omegaconf<2.1->fairseq==1.0.0a0+9a1c497) (3.7.4.3)\n","Requirement already satisfied, skipping upgrade: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from hydra-core<1.1->fairseq==1.0.0a0+9a1c497) (5.1.2)\n","Collecting antlr4-python3-runtime==4.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/02/789a0bddf9c9b31b14c3e79ec22b9656185a803dc31c15f006f9855ece0d/antlr4-python3-runtime-4.8.tar.gz (112kB)\n","\u001b[K     |████████████████████████████████| 112kB 25.2MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->hydra-core<1.1->fairseq==1.0.0a0+9a1c497) (3.4.1)\n","Building wheels for collected packages: fairseq\n","  Building wheel for fairseq (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fairseq: filename=fairseq-1.0.0a0+9a1c497-cp37-cp37m-linux_x86_64.whl size=2817620 sha256=4dbd2d041c0003135c2bf4f589c7687e963a1e753010b72b7df176d7a0be3f48\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-ypr07zzl/wheels/94/b2/67/6399f5bcb823dc3a8b1e84965aaae15af9ed863fee98a59129\n","Successfully built fairseq\n","Building wheels for collected packages: antlr4-python3-runtime\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-cp37-none-any.whl size=141231 sha256=a1a5fbb7833b29558c0a5690fea652de483b637e4937bdbbf87b2afcda90210b\n","  Stored in directory: /root/.cache/pip/wheels/e3/e2/fa/b78480b448b8579ddf393bebd3f47ee23aa84c89b6a78285c8\n","Successfully built antlr4-python3-runtime\n","Installing collected packages: PyYAML, omegaconf, antlr4-python3-runtime, hydra-core, fairseq\n","  Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed PyYAML-5.4.1 antlr4-python3-runtime-4.8 fairseq-1.0.0a0+9a1c497 hydra-core-1.0.6 omegaconf-2.0.6\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gTNFuZXCO-iu","executionInfo":{"status":"ok","timestamp":1619661930961,"user_tz":-480,"elapsed":101003,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"2c96e818-1c77-4b75-d87b-d39f90c2064d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pAuge8TAOn-t"},"source":["import sys\n","import pdb\n","import pprint\n","import logging\n","import os\n","import random\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils import data\n","import numpy as np\n","import tqdm.auto as tqdm\n","from pathlib import Path\n","from argparse import Namespace\n","from fairseq import utils\n","\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zlgbwvqHOn-u"},"source":["# 設定種子"]},{"cell_type":"code","metadata":{"id":"hSmpVVduOn-u"},"source":["seed = 73\n","random.seed(seed)\n","torch.manual_seed(seed)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)  \n","np.random.seed(seed)  \n","torch.backends.cudnn.benchmark = False\n","torch.backends.cudnn.deterministic = True"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MjoYy8g3On-u"},"source":["# 資料集介紹\n","\n","## 英轉繁雙語資料\n","* [TED2020](#reimers-2020-multilingual-sentence-bert)\n","    - 原始資料量: 398,066句    \n","    - 處理後資料: 393,980句\n","    \n","\n","## 測試資料\n","- 資料量: 4,000句\n","- **中文部分不公開，提供的檔案為假翻譯，全部都是句點。**"]},{"cell_type":"markdown","metadata":{"id":"P4LP4QnBOn-v"},"source":["# 資料下載"]},{"cell_type":"markdown","metadata":{"id":"4EYe8z_bOn-v"},"source":["### 安裝megatools (optional)"]},{"cell_type":"code","metadata":{"id":"N5SpcJbwOn-w"},"source":["#!apt-get install megatools"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z562TetAOn-w"},"source":["## 下載檔案並解壓縮"]},{"cell_type":"code","metadata":{"id":"FAp3-0tTOn-w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619661937755,"user_tz":-480,"elapsed":6196,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"c78877ff-1c4b-4bbc-d0fa-590ab5c1aa12"},"source":["data_dir = './DATA/rawdata'\n","dataset_name = 'ted2020'\n","urls = (\n","    '\"https://onedrive.live.com/download?cid=3E549F3B24B238B4&resid=3E549F3B24B238B4%214989&authkey=AGgQ-DaR8eFSl1A\"', \n","    '\"https://onedrive.live.com/download?cid=3E549F3B24B238B4&resid=3E549F3B24B238B4%214987&authkey=AA4qP_azsicwZZM\"',\n","# # If the above links die, use the following instead. \n","#     \"https://www.csie.ntu.edu.tw/~r09922057/ML2021-hw5/ted2020.tgz\",\n","#     \"https://www.csie.ntu.edu.tw/~r09922057/ML2021-hw5/test.tgz\",\n","# # If the above links die, use the following instead. \n","#     \"https://mega.nz/#!vEcTCISJ!3Rw0eHTZWPpdHBTbQEqBDikDEdFPr7fI8WxaXK9yZ9U\",\n","#     \"https://mega.nz/#!zNcnGIoJ!oPJX9AvVVs11jc0SaK6vxP_lFUNTkEcK2WbxJpvjU5Y\",\n",")\n","file_names = (\n","    'ted2020.tgz', # train & dev\n","    'test.tgz', # test\n",")\n","prefix = Path(data_dir).absolute() / dataset_name\n","\n","prefix.mkdir(parents=True, exist_ok=True)\n","for u, f in zip(urls, file_names):\n","    path = prefix/f\n","    if not path.exists():\n","        if 'mega' in u:\n","            !megadl {u} --path {path}\n","        else:\n","            !wget {u} -O {path}\n","    if path.suffix == \".tgz\":\n","        !tar -xvf {path} -C {prefix}\n","    elif path.suffix == \".zip\":\n","        !unzip -o {path} -d {prefix}\n","!mv {prefix/'raw.en'} {prefix/'train_dev.raw.en'}\n","!mv {prefix/'raw.zh'} {prefix/'train_dev.raw.zh'}\n","!mv {prefix/'test.en'} {prefix/'test.raw.en'}\n","!mv {prefix/'test.zh'} {prefix/'test.raw.zh'}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-04-29 02:05:32--  https://onedrive.live.com/download?cid=3E549F3B24B238B4&resid=3E549F3B24B238B4%214989&authkey=AGgQ-DaR8eFSl1A\n","Resolving onedrive.live.com (onedrive.live.com)... 13.107.42.13\n","Connecting to onedrive.live.com (onedrive.live.com)|13.107.42.13|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://yva8og.dm.files.1drv.com/y4muA9P4IISz3aDIadU6PimwhXp7LDCYt7gUFczen2PG32m0AdKhnz5iFBaaCYQbx7wvPSVZXmQc26aYkhl4QiMmsIZb_M6qO2leSXh1DRPQnZYOn9y99ZfJmgFCvQrLOE-rUAKx-x6WemECwIR_6zzbPgnu6TZy4kcPllW2u_VRjWVX8ulHKGH1N-0C6eJLYk3aTRUZIL3bgvr4_z3fFzxRQ/ted2020.tgz?download&psid=1 [following]\n","--2021-04-29 02:05:33--  https://yva8og.dm.files.1drv.com/y4muA9P4IISz3aDIadU6PimwhXp7LDCYt7gUFczen2PG32m0AdKhnz5iFBaaCYQbx7wvPSVZXmQc26aYkhl4QiMmsIZb_M6qO2leSXh1DRPQnZYOn9y99ZfJmgFCvQrLOE-rUAKx-x6WemECwIR_6zzbPgnu6TZy4kcPllW2u_VRjWVX8ulHKGH1N-0C6eJLYk3aTRUZIL3bgvr4_z3fFzxRQ/ted2020.tgz?download&psid=1\n","Resolving yva8og.dm.files.1drv.com (yva8og.dm.files.1drv.com)... 13.107.42.12\n","Connecting to yva8og.dm.files.1drv.com (yva8og.dm.files.1drv.com)|13.107.42.12|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 28601955 (27M) [application/x-gzip]\n","Saving to: ‘/content/DATA/rawdata/ted2020/ted2020.tgz’\n","\n","/content/DATA/rawda 100%[===================>]  27.28M  39.2MB/s    in 0.7s    \n","\n","2021-04-29 02:05:34 (39.2 MB/s) - ‘/content/DATA/rawdata/ted2020/ted2020.tgz’ saved [28601955/28601955]\n","\n","raw.en\n","raw.zh\n","--2021-04-29 02:05:35--  https://onedrive.live.com/download?cid=3E549F3B24B238B4&resid=3E549F3B24B238B4%214987&authkey=AA4qP_azsicwZZM\n","Resolving onedrive.live.com (onedrive.live.com)... 13.107.42.13\n","Connecting to onedrive.live.com (onedrive.live.com)|13.107.42.13|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://z1a8og.dm.files.1drv.com/y4mPsWhLaaVmTelnWn71suDXEHnleggNM8Q4f6gkbFPk9F3I3GorGLEV_oHbdhFe_Za5jvF3aeOGeW6LbR61mvC3Xze28RULJYDUzLabiJM-N8sCEAXT76aM5myLPS0KbWC8XSgCei6f18m2ztKxOZMdWOoAOBs0RYtoV6mkI4Ejh2oPKJ2VZU3W2YaOnO9HTcNrqrSku1Xl-Re8Hb1YiTDxw/test.tgz?download&psid=1 [following]\n","--2021-04-29 02:05:35--  https://z1a8og.dm.files.1drv.com/y4mPsWhLaaVmTelnWn71suDXEHnleggNM8Q4f6gkbFPk9F3I3GorGLEV_oHbdhFe_Za5jvF3aeOGeW6LbR61mvC3Xze28RULJYDUzLabiJM-N8sCEAXT76aM5myLPS0KbWC8XSgCei6f18m2ztKxOZMdWOoAOBs0RYtoV6mkI4Ejh2oPKJ2VZU3W2YaOnO9HTcNrqrSku1Xl-Re8Hb1YiTDxw/test.tgz?download&psid=1\n","Resolving z1a8og.dm.files.1drv.com (z1a8og.dm.files.1drv.com)... 13.107.42.12\n","Connecting to z1a8og.dm.files.1drv.com (z1a8og.dm.files.1drv.com)|13.107.42.12|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 150315 (147K) [application/x-gzip]\n","Saving to: ‘/content/DATA/rawdata/ted2020/test.tgz’\n","\n","/content/DATA/rawda 100%[===================>] 146.79K   468KB/s    in 0.3s    \n","\n","2021-04-29 02:05:36 (468 KB/s) - ‘/content/DATA/rawdata/ted2020/test.tgz’ saved [150315/150315]\n","\n","test.en\n","test.zh\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zZ1PMPXEOn-x"},"source":["## 設定語言"]},{"cell_type":"code","metadata":{"id":"lVUhPpkwOn-x"},"source":["src_lang = 'zh'\n","tgt_lang = 'en'\n","\n","data_prefix = f'{prefix}/train_dev.raw'\n","test_prefix = f'{prefix}/test.raw'\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9ddSV1PbOn-x","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619661938293,"user_tz":-480,"elapsed":6254,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"69aaa525-f0f0-4d2e-b8b2-90883f16cabb"},"source":["!head {data_prefix+'.'+src_lang} -n 5\n","!head {data_prefix+'.'+tgt_lang} -n 5"],"execution_count":null,"outputs":[{"output_type":"stream","text":["非常謝謝你，克里斯。能有這個機會第二度踏上這個演講台\n","真是一大榮幸。我非常感激。\n","這個研討會給我留下了極為深刻的印象，我想感謝大家 對我之前演講的好評。\n","我是由衷的想這麼說，有部份原因是因為 —— 我真的有需要!\n","請你們設身處地為我想一想！\n","Thank you so much, Chris.\n","And it's truly a great honor to have the opportunity to come to this stage twice; I'm extremely grateful.\n","I have been blown away by this conference, and I want to thank all of you for the many nice comments about what I had to say the other night.\n","And I say that sincerely, partly because  I need that.\n","Put yourselves in my position.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dwGGflGIOn-y"},"source":["## 檔案前處理"]},{"cell_type":"code","metadata":{"id":"fTiioBDSOn-y"},"source":["import re\n","\n","def strQ2B(ustring):\n","    \"\"\"把字串全形轉半形\"\"\"\n","    # 參考來源:https://ithelp.ithome.com.tw/articles/10233122\n","    ss = []\n","    for s in ustring:\n","        rstring = \"\"\n","        for uchar in s:\n","            inside_code = ord(uchar)\n","            if inside_code == 12288:  # 全形空格直接轉換\n","                inside_code = 32\n","            elif (inside_code >= 65281 and inside_code <= 65374):  # 全形字元（除空格）根據關係轉化\n","                inside_code -= 65248\n","            rstring += chr(inside_code)\n","        ss.append(rstring)\n","    return ''.join(ss)\n","                \n","def clean_s(s, lang):\n","    if lang == 'en':\n","        s = re.sub(r\"\\([^()]*\\)\", \"\", s) # remove ([text])\n","        s = s.replace('-', '') # remove '-'\n","        s = re.sub('([.,;!?()\\\"])', r' \\1 ', s) # keep punctuation\n","    elif lang == 'zh':\n","        s = strQ2B(s) # Q2B\n","        s = re.sub(r\"\\([^()]*\\)\", \"\", s) # remove ([text])\n","        s = s.replace(' ', '')\n","        s = s.replace('—', '')\n","        s = s.replace('“', '\"')\n","        s = s.replace('”', '\"')\n","        s = s.replace('_', '')\n","        s = re.sub('([。,;!?()\\\"~「」])', r' \\1 ', s) # keep punctuation\n","    s = ' '.join(s.strip().split())\n","    return s\n","\n","def len_s(s, lang):\n","    if lang == 'zh':\n","        return len(s)\n","    return len(s.split())\n","\n","def clean_corpus(prefix, l1, l2, ratio=9, max_len=1000, min_len=1):\n","    if Path(f'{prefix}.clean.{l1}').exists() and Path(f'{prefix}.clean.{l2}').exists():\n","        print(f'{prefix}.clean.{l1} & {l2} exists. skipping clean.')\n","        return\n","    with open(f'{prefix}.{l1}', 'r') as l1_in_f:\n","        with open(f'{prefix}.{l2}', 'r') as l2_in_f:\n","            with open(f'{prefix}.clean.{l1}', 'w') as l1_out_f:\n","                with open(f'{prefix}.clean.{l2}', 'w') as l2_out_f:\n","                    for s1 in l1_in_f:\n","                        s1 = s1.strip()\n","                        s2 = l2_in_f.readline().strip()\n","                        s1 = clean_s(s1, l1)\n","                        s2 = clean_s(s2, l2)\n","                        s1_len = len_s(s1, l1)\n","                        s2_len = len_s(s2, l2)\n","                        if min_len > 0: # remove short sentence\n","                            if s1_len < min_len or s2_len < min_len:\n","                                continue\n","                        if max_len > 0: # remove long sentence\n","                            if s1_len > max_len or s2_len > max_len:\n","                                continue\n","                        if ratio > 0: # remove by ratio of length\n","                            if s1_len/s2_len > ratio or s2_len/s1_len > ratio:\n","                                continue\n","                        print(s1, file=l1_out_f)\n","                        print(s2, file=l2_out_f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BFG8oJPIOn-z"},"source":["clean_corpus(data_prefix, src_lang, tgt_lang)\n","clean_corpus(test_prefix, src_lang, tgt_lang, ratio=-1, min_len=-1, max_len=-1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ZLnp3aoOn-z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619661961071,"user_tz":-480,"elapsed":15942,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"291281a2-7ade-40ff-817e-0ef96d3832d6"},"source":["!head {data_prefix+'.clean.'+src_lang} -n 5\n","!head {data_prefix+'.clean.'+tgt_lang} -n 5"],"execution_count":null,"outputs":[{"output_type":"stream","text":["非常謝謝你 , 克里斯 。 能有這個機會第二度踏上這個演講台\n","真是一大榮幸 。 我非常感激 。\n","這個研討會給我留下了極為深刻的印象 , 我想感謝大家對我之前演講的好評 。\n","我是由衷的想這麼說 , 有部份原因是因為我真的有需要 !\n","請你們設身處地為我想一想 !\n","Thank you so much , Chris .\n","And it's truly a great honor to have the opportunity to come to this stage twice ; I'm extremely grateful .\n","I have been blown away by this conference , and I want to thank all of you for the many nice comments about what I had to say the other night .\n","And I say that sincerely , partly because I need that .\n","Put yourselves in my position .\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7jyA8qxiOn-0"},"source":["## 切出 train/valid set"]},{"cell_type":"code","metadata":{"id":"5ZYNtFOZOn-0"},"source":["valid_ratio = 0.01 # 3000~4000句就夠了\n","train_ratio = 1 - valid_ratio"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rw11NocMOn-0"},"source":["if (prefix/f'train.clean.{src_lang}').exists() \\\n","and (prefix/f'train.clean.{tgt_lang}').exists() \\\n","and (prefix/f'valid.clean.{src_lang}').exists() \\\n","and (prefix/f'valid.clean.{tgt_lang}').exists():\n","    print(f'train/valid splits exists. skipping split.')\n","else:\n","    line_num = sum(1 for line in open(f'{data_prefix}.clean.{src_lang}'))\n","    labels = list(range(line_num))\n","    random.shuffle(labels)\n","    for lang in [src_lang, tgt_lang]:\n","        train_f = open(os.path.join(data_dir, dataset_name, f'train.clean.{lang}'), 'w')\n","        valid_f = open(os.path.join(data_dir, dataset_name, f'valid.clean.{lang}'), 'w')\n","        count = 0\n","        for line in open(f'{data_prefix}.clean.{lang}', 'r'):\n","            if labels[count]/line_num < train_ratio:\n","                train_f.write(line)\n","            else:\n","                valid_f.write(line)\n","            count += 1\n","        train_f.close()\n","        valid_f.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6hw6XZBEAguo"},"source":["!cp /content/drive/MyDrive/bt/spm8000.model /content/DATA/rawdata/ted2020/\n","!cp /content/drive/MyDrive/bt/spm8000.vocab /content/DATA/rawdata/ted2020/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"51ntZZ6yOn-1"},"source":["## Subword Units \n","翻譯存在的一大問題是未登錄詞(out of vocabulary)，可以使用 subword units 作為斷詞單位來解決。\n","- 使用 [sentencepiece](#kudo-richardson-2018-sentencepiece) 套件\n","- 用 unigram 或 byte-pair encoding (BPE)"]},{"cell_type":"code","metadata":{"id":"Zc80ejBvOn-1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619661963551,"user_tz":-480,"elapsed":5165,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"efa842c0-c76f-4a4c-d7bb-1e8c10b9d2df"},"source":["import sentencepiece as spm\n","vocab_size = 8000\n","if (prefix/f'spm{vocab_size}.model').exists():\n","    print(f'{prefix}/spm{vocab_size}.model exists. skipping spm_train.')\n","else:\n","    spm.SentencePieceTrainer.train(\n","        input=','.join([f'{prefix}/train.clean.{src_lang}',\n","                        f'{prefix}/valid.clean.{src_lang}',\n","                        f'{prefix}/train.clean.{tgt_lang}',\n","                        f'{prefix}/valid.clean.{tgt_lang}']),\n","        model_prefix=prefix/f'spm{vocab_size}',\n","        vocab_size=vocab_size,\n","        character_coverage=1,\n","        model_type='unigram', # 'bpe' 也可\n","        input_sentence_size=1e6,\n","        shuffle_input_sentence=True,\n","        normalization_rule_name='nmt_nfkc_cf',\n","    )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/DATA/rawdata/ted2020/spm8000.model exists. skipping spm_train.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WS5tGrFHOn-1"},"source":["spm_model = spm.SentencePieceProcessor(model_file=str(prefix/f'spm{vocab_size}.model'))\n","in_tag = {\n","    'train': 'train.clean',\n","    'valid': 'valid.clean',\n","    'test': 'test.raw.clean',\n","}\n","for split in ['train', 'valid', 'test']:\n","    for lang in [src_lang, tgt_lang]:\n","        out_path = prefix/f'{split}.{lang}'\n","        if out_path.exists():\n","            print(f\"{out_path} exists. skipping spm_encode.\")\n","        else:\n","            with open(prefix/f'{split}.{lang}', 'w') as out_f:\n","                with open(prefix/f'{in_tag[split]}.{lang}', 'r') as in_f:\n","                    for line in in_f:\n","                        line = line.strip()\n","                        tok = spm_model.encode(line, out_type=str)\n","                        print(' '.join(tok), file=out_f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QkGrm4WrOn-2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619661982081,"user_tz":-480,"elapsed":15829,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"39fea0ba-5f03-48c5-a0d5-d34908f8bc4d"},"source":["!head {data_dir+'/'+dataset_name+'/train.'+src_lang} -n 5\n","!head {data_dir+'/'+dataset_name+'/train.'+tgt_lang} -n 5"],"execution_count":null,"outputs":[{"output_type":"stream","text":["▁ 非常 謝 謝 你 ▁, ▁ 克 里 斯 ▁ 。 ▁ 能 有 這個 機會 第二 度 踏 上 這個 演講 台\n","▁ 真 是 一 大 榮 幸 ▁ 。 ▁我 非常 感 激 ▁ 。\n","▁這個 研 討 會 給我 留 下 了 極 為 深 刻 的 印 象 ▁, ▁我想 感 謝 大家 對 我 之前 演講 的 好 評 ▁ 。\n","▁我 是由 衷 的 想 這麼 說 ▁, ▁有 部份 原因 是因為 我 真的 有 需要 ▁ !\n","▁ 請 你們 設 身 處 地 為 我想 一 想 ▁ !\n","▁thank ▁you ▁so ▁much ▁, ▁chris ▁.\n","▁and ▁it ' s ▁ t ru ly ▁a ▁great ▁ho n or ▁to ▁have ▁the ▁ op port un ity ▁to ▁come ▁to ▁this ▁st age ▁ t wi ce ▁ ; ▁i ' m ▁ex t re me ly ▁gr ate ful ▁.\n","▁i ▁have ▁been ▁ bl own ▁away ▁by ▁this ▁con fer ence ▁, ▁and ▁i ▁want ▁to ▁thank ▁all ▁of ▁you ▁for ▁the ▁many ▁ ni ce ▁ com ment s ▁about ▁what ▁i ▁had ▁to ▁say ▁the ▁other ▁night ▁.\n","▁and ▁i ▁say ▁that ▁since re ly ▁, ▁part ly ▁because ▁i ▁need ▁that ▁.\n","▁put ▁your s el ve s ▁in ▁my ▁po s ition ▁.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Bp9vpotzOn-2"},"source":["## 用 fairseq 將資料轉為 binary"]},{"cell_type":"code","metadata":{"id":"qNsNNv2MOn-3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619662105418,"user_tz":-480,"elapsed":121015,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"869c98b3-45df-4605-c819-943c3968ca88"},"source":["binpath = Path('./DATA/data-bin', dataset_name)\n","if binpath.exists():\n","    print(binpath, \"exists, will not overwrite!\")\n","else:\n","    !python -m fairseq_cli.preprocess \\\n","        --source-lang {src_lang}\\\n","        --target-lang {tgt_lang}\\\n","        --trainpref {prefix/'train'}\\\n","        --validpref {prefix/'valid'}\\\n","        --testpref {prefix/'test'}\\\n","        --destdir {binpath}\\\n","        --joined-dictionary\\\n","        --workers 2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-04-29 02:06:26 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='DATA/data-bin/ted2020', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='zh', srcdict=None, suppress_crashes=False, target_lang='en', task='translation', tensorboard_logdir=None, testpref='/content/DATA/rawdata/ted2020/test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/content/DATA/rawdata/ted2020/train', user_dir=None, validpref='/content/DATA/rawdata/ted2020/valid', wandb_project=None, workers=2)\n","2021-04-29 02:07:10 | INFO | fairseq_cli.preprocess | [zh] Dictionary: 8000 types\n","2021-04-29 02:07:46 | INFO | fairseq_cli.preprocess | [zh] /content/DATA/rawdata/ted2020/train.zh: 390041 sents, 9842606 tokens, 0.0% replaced by <unk>\n","2021-04-29 02:07:46 | INFO | fairseq_cli.preprocess | [zh] Dictionary: 8000 types\n","2021-04-29 02:07:46 | INFO | fairseq_cli.preprocess | [zh] /content/DATA/rawdata/ted2020/valid.zh: 3939 sents, 99156 tokens, 0.00504% replaced by <unk>\n","2021-04-29 02:07:46 | INFO | fairseq_cli.preprocess | [zh] Dictionary: 8000 types\n","2021-04-29 02:07:46 | INFO | fairseq_cli.preprocess | [zh] /content/DATA/rawdata/ted2020/test.zh: 4000 sents, 12000 tokens, 0.0% replaced by <unk>\n","2021-04-29 02:07:46 | INFO | fairseq_cli.preprocess | [en] Dictionary: 8000 types\n","2021-04-29 02:08:23 | INFO | fairseq_cli.preprocess | [en] /content/DATA/rawdata/ted2020/train.en: 390041 sents, 12426366 tokens, 0.0% replaced by <unk>\n","2021-04-29 02:08:23 | INFO | fairseq_cli.preprocess | [en] Dictionary: 8000 types\n","2021-04-29 02:08:24 | INFO | fairseq_cli.preprocess | [en] /content/DATA/rawdata/ted2020/valid.en: 3939 sents, 124688 tokens, 0.0% replaced by <unk>\n","2021-04-29 02:08:24 | INFO | fairseq_cli.preprocess | [en] Dictionary: 8000 types\n","2021-04-29 02:08:24 | INFO | fairseq_cli.preprocess | [en] /content/DATA/rawdata/ted2020/test.en: 4000 sents, 124954 tokens, 0.0% replaced by <unk>\n","2021-04-29 02:08:24 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to DATA/data-bin/ted2020\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bvqPym9jOn-3"},"source":["# 實驗的參數設定表"]},{"cell_type":"code","metadata":{"id":"Vi5I66L7On-3"},"source":["config = Namespace(\n","    datadir = \"./DATA/data-bin/ted2020\",\n","    # savedir = \"/content/drive/MyDrive/bt/\",\n","    savedir = \"/content/backward/\",\n","    source_lang = \"zh\",\n","    target_lang = \"en\",\n","    \n","    # cpu threads when fetching & processing data.\n","    num_workers=2,  \n","    # batch size in terms of tokens. gradient accumulation increases the effective batchsize.\n","    max_tokens=8192,\n","    accum_steps=2,\n","    \n","    # the lr s calculated from Noam lr scheduler. you can tune the maximum lr by this factor.\n","    lr_factor=2.,\n","    lr_warmup=4000,\n","    \n","    # clipping gradient norm helps alleviate gradient exploding\n","    clip_norm=1.0,\n","    \n","    # maximum epochs for training\n","    max_epoch=40,\n","    start_epoch=1,\n","    \n","    # beam size for beam search\n","    beam=5, \n","    # generate sequences of maximum length ax + b, where x is the source length\n","    max_len_a=1.2, \n","    max_len_b=10,\n","    # when decoding, post process sentence by removing sentencepiece symbols.\n","    post_process = \"sentencepiece\",\n","    \n","    # checkpoints\n","    keep_last_epochs=5,\n","    resume=None, # if resume from checkpoint name (under config.savedir)\n","    \n","    # logging\n","    use_wandb=False,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZbDBG0_ROn-4"},"source":["# Logging\n","- logging 套件紀錄一般訊息\n","- wandb 紀錄續練過程 loss, bleu, model weight 等等"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"6dtFxSG7On-4"},"source":["logging.basicConfig(\n","    format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n","    datefmt=\"%Y-%m-%d %H:%M:%S\",\n","    level=\"INFO\", # \"DEBUG\" \"WARNING\" \"ERROR\"\n","    stream=sys.stdout,\n",")\n","proj = \"hw5.seq2seq\"\n","logger = logging.getLogger(proj)\n","if config.use_wandb:\n","    import wandb\n","    wandb.init(project=proj, name=Path(config.savedir).stem, config=config)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gv13040fOn-4"},"source":["# CUDA環境"]},{"cell_type":"code","metadata":{"id":"qzeDxUbEOn-4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619662164882,"user_tz":-480,"elapsed":881,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"d61273a6-0f49-44f0-f805-83d87a3c1419"},"source":["cuda_env = utils.CudaEnvironment()\n","utils.CudaEnvironment.pretty_print_cuda_env_list([cuda_env])\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-04-29 02:09:23 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n","2021-04-29 02:09:23 | INFO | fairseq.utils | rank   0: capabilities =  7.0  ; total memory = 15.782 GB ; name = Tesla V100-SXM2-16GB                    \n","2021-04-29 02:09:23 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"29AF9smROn-4"},"source":["# 讀取資料集"]},{"cell_type":"markdown","metadata":{"id":"jLqBHfDtOn-5"},"source":["## 借用 fairseq 的 TranslationTask\n","* 用來讀進上面 binarized 的檔案\n","* 有現成的 data iterator (dataloader)\n","* 字典 task.source_dictionary 和 task.target_dictionary 也很好用 \n","* 有實做 beam search"]},{"cell_type":"code","metadata":{"id":"ZPcXEZvWOn-5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619662165275,"user_tz":-480,"elapsed":697,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"8a2b3c57-2956-42b0-fa9c-e50ab2512d3d"},"source":["from fairseq.tasks.translation import TranslationConfig, TranslationTask\n","\n","## setup task\n","task_cfg = TranslationConfig(\n","    data=config.datadir,\n","    source_lang=config.source_lang,\n","    target_lang=config.target_lang,\n","    train_subset=\"train\",\n","    required_seq_len_multiple=8,\n","    dataset_impl=\"mmap\",\n","    upsample_primary=1,\n",")\n","task = TranslationTask.setup_task(task_cfg)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-04-29 02:09:24 | INFO | fairseq.tasks.translation | [zh] dictionary: 8000 types\n","2021-04-29 02:09:24 | INFO | fairseq.tasks.translation | [en] dictionary: 8000 types\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iPG0AhzKOn-5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619662165725,"user_tz":-480,"elapsed":900,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"771af973-5730-4bb7-e39b-234c8f736fe4"},"source":["logger.info(\"loading data for epoch 1\")\n","task.load_dataset(split=\"train\", epoch=1, combine=True) # combine if you have back-translation data.\n","task.load_dataset(split=\"valid\", epoch=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-04-29 02:09:25 | INFO | hw5.seq2seq | loading data for epoch 1\n","2021-04-29 02:09:25 | INFO | fairseq.data.data_utils | loaded 390,041 examples from: ./DATA/data-bin/ted2020/train.zh-en.zh\n","2021-04-29 02:09:25 | INFO | fairseq.data.data_utils | loaded 390,041 examples from: ./DATA/data-bin/ted2020/train.zh-en.en\n","2021-04-29 02:09:25 | INFO | fairseq.tasks.translation | ./DATA/data-bin/ted2020 train zh-en 390041 examples\n","2021-04-29 02:09:25 | INFO | fairseq.data.data_utils | loaded 3,939 examples from: ./DATA/data-bin/ted2020/valid.zh-en.zh\n","2021-04-29 02:09:25 | INFO | fairseq.data.data_utils | loaded 3,939 examples from: ./DATA/data-bin/ted2020/valid.zh-en.en\n","2021-04-29 02:09:25 | INFO | fairseq.tasks.translation | ./DATA/data-bin/ted2020 valid zh-en 3939 examples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yRBZUNKaOn-5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619662165727,"user_tz":-480,"elapsed":689,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"90731335-431a-4913-9a11-c6fc84f231ab"},"source":["sample = task.dataset(\"valid\")[1]\n","pprint.pprint(sample)\n","pprint.pprint(\n","    \"Source: \" + \\\n","    task.source_dictionary.string(\n","        sample['source'],\n","        config.post_process,\n","    )\n",")\n","pprint.pprint(\n","    \"Target: \" + \\\n","    task.target_dictionary.string(\n","        sample['target'],\n","        config.post_process,\n","    )\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'id': 1,\n"," 'source': tensor([ 145,  684,   30,  270,   40,  168, 1134,  650,  591,  367, 3117, 2417,\n","        1420,  194,    2]),\n"," 'target': tensor([  18,   14,    6, 2218,   60,   19,   75,    4,  253,   16,  334, 1392,\n","        1689,    7,    2])}\n","'Source: 這實在就是我所做的--光學操控思想'\n","\"Target: that's exactly what i do optical mind control .\"\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oYadEIOhOn-5"},"source":["## Dataset Iterator"]},{"cell_type":"markdown","metadata":{"id":"2z6GudxTOn-6"},"source":["* 將每個 batch 控制在 N 個 token 讓 GPU 記憶體更有效被利用\n","* 讓 training set 每個 epoch 有不同 shuffling\n","* 濾掉長度太長的句子\n","* 將每個 batch 內的句子 pad 成一樣長，好讓 GPU 平行運算\n","* 加上 eos 並 shift 一格\n","    - teacher forcing: 為了訓練模型根據prefix生成下個字，decoder的輸入會是輸出目標序列往右shift一格。\n","    - 一般是會在輸入開頭加個bos token (如下圖)\n","![seq2seq](https://i.imgur.com/0zeDyuI.png)\n","    - fairseq 則是直接把 eos 挪到 beginning，訓練起來效果其實差不多。例如: \n","    ```\n","    # 輸出目標 (target) 和 Decoder輸入 (prev_output_tokens): \n","                   eos = 2\n","                target = 419,  711,  238,  888,  792,   60,  968,    8,    2\n","    prev_output_tokens = 2,  419,  711,  238,  888,  792,   60,  968,    8\n","    ```\n"]},{"cell_type":"code","metadata":{"id":"YZ057ftYOn-6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619662167910,"user_tz":-480,"elapsed":806,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"9fb51b95-d59e-4ba7-dc15-ca70468e2fe6"},"source":["def load_data_iterator(task, split, epoch=1, max_tokens=4000, num_workers=1, cached=True):\n","    batch_iterator = task.get_batch_iterator(\n","        dataset=task.dataset(split),\n","        max_tokens=max_tokens,\n","        max_sentences=None,\n","        max_positions=utils.resolve_max_positions(\n","            task.max_positions(),\n","            max_tokens,\n","        ),\n","        ignore_invalid_inputs=True,\n","        seed=seed,\n","        num_workers=num_workers,\n","        epoch=epoch,\n","        disable_iterator_cache=not cached,\n","        # Set this to False to speed up. However, if set to False, changing max_tokens beyond \n","        # first call of this method has no effect. \n","    )\n","    return batch_iterator\n","\n","demo_epoch_obj = load_data_iterator(task, \"valid\", epoch=1, max_tokens=20, num_workers=1, cached=False)\n","demo_iter = demo_epoch_obj.next_epoch_itr(shuffle=True)\n","sample = next(demo_iter)\n","sample"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-04-29 02:09:27 | WARNING | fairseq.tasks.fairseq_task | 2,586 samples have invalid sizes and will be skipped, max_positions=(20, 20), first few sample ids=[3525, 1062, 527, 2861, 2415, 1633, 1624, 2626, 210, 880]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'id': tensor([3517]),\n"," 'net_input': {'prev_output_tokens': tensor([[   2,    4,   32,   63,    8,  796, 1556, 1562,   13,  691,  116,  124,\n","            188,    4,   33,    4,   32,    1,    1,    1,    1,    1,    1,    1]]),\n","  'src_lengths': tensor([13]),\n","  'src_tokens': tensor([[   1,    1,    1,    4, 1259, 2926,  157, 3552, 1591,  137,  162, 1173,\n","            434,    4,   33,    2]])},\n"," 'nsentences': 1,\n"," 'ntokens': 17,\n"," 'target': tensor([[   4,   32,   63,    8,  796, 1556, 1562,   13,  691,  116,  124,  188,\n","             4,   33,    4,   32,    2,    1,    1,    1,    1,    1,    1,    1]])}"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"A4D7xcJROn-6"},"source":["* 每個 batch 是一個字典，key 是字串，value 是 Tensor，內容說明如下\n","```python\n","batch = {\n","    \"id\": id, # 每個 example 的 id\n","    \"nsentences\": len(samples), # batch size 句子數\n","    \"ntokens\": ntokens, # batch size 字數\n","    \"net_input\": {\n","        \"src_tokens\": src_tokens, # 來源語言的序列\n","        \"src_lengths\": src_lengths, # 每句話沒有 pad 過的長度\n","        \"prev_output_tokens\": prev_output_tokens, # 上面提到右 shift 一格後的目標序列\n","    },\n","    \"target\": target, # 目標序列\n","}\n","```"]},{"cell_type":"markdown","metadata":{"id":"mGQ-jaetOn-6"},"source":["# 定義模型架構\n","* 我們一樣繼承 fairseq 的 encoder, decoder 和 model, 這樣測試階段才能直接用他寫好的 beam search 函式"]},{"cell_type":"code","metadata":{"id":"aagb5F9lOn-6"},"source":["from fairseq.models import (\n","    FairseqEncoder, \n","    FairseqIncrementalDecoder,\n","    FairseqEncoderDecoderModel\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MWKPhjW0On-7"},"source":["## Encoder 編碼器"]},{"cell_type":"markdown","metadata":{"id":"Os4cvkpbOn-7"},"source":["- seq2seq 模型的編碼器為 RNN 或 Transformer Encoder，以下說明以 RNN 為例，Transformer 略有不同。對於每個輸入，Encoder 會輸出一個向量和一個隱藏狀態(hidden state)，並將隱藏狀態用於下一個輸入。換句話說，Encoder 會逐步讀取輸入序列，並在每個 timestep 輸出單個向量，以及在最後 timestep 輸出最終隱藏狀態(content vector)\n","- 參數:\n","  - *args*\n","      - encoder_embed_dim 是 embedding 的維度，主要將 one-hot vector 的單詞向量壓縮到指定的維度，主要是為了降維和濃縮資訊的功用\n","      - encoder_ffn_embed_dim 是 RNN 輸出和隱藏狀態的維度(hidden dimension)\n","      - encoder_layers 是 RNN 要疊多少層\n","      - dropout 是決定有多少的機率會將某個節點變為 0，主要是為了防止 overfitting ，一般來說是在訓練時使用，測試時則不使用\n","  - *dictionary*: fairseq 幫我們做好的 dictionary. 在此用來得到 padding index，好用來得到 encoder padding mask. \n","  - *embed_tokens*: 事先做好的詞嵌入 (nn.Embedding)\n","\n","- 輸入: \n","    - *src_tokens*: 英文的整數序列 e.g. 1, 28, 29, 205, 2 \n","- 輸出: \n","    - *outputs*: 最上層 RNN 每個 timestep 的輸出，後續可以用 Attention 再進行處理\n","    - *final_hiddens*: 每層最終 timestep 的隱藏狀態，將傳遞到 Decoder 進行解碼\n","    - *encoder_padding_mask*: 告訴我們哪些是位置的資訊不重要。\n"]},{"cell_type":"code","metadata":{"id":"9oACs9h9On-7"},"source":["class RNNEncoder(FairseqEncoder):\n","    def __init__(self, args, dictionary, embed_tokens):\n","        super().__init__(dictionary)\n","        self.embed_tokens = embed_tokens\n","        \n","        self.embed_dim = args.encoder_embed_dim\n","        self.hidden_dim = args.encoder_ffn_embed_dim\n","        self.num_layers = args.encoder_layers\n","        \n","        self.dropout_in_module = nn.Dropout(args.dropout)\n","        self.rnn = nn.GRU(\n","            self.embed_dim, \n","            self.hidden_dim, \n","            self.num_layers, \n","            dropout=args.dropout, \n","            batch_first=False, \n","            bidirectional=True\n","        )\n","        self.dropout_out_module = nn.Dropout(args.dropout)\n","        \n","        self.padding_idx = dictionary.pad()\n","        \n","    def combine_bidir(self, outs, bsz: int):\n","        out = outs.view(self.num_layers, 2, bsz, -1).transpose(1, 2).contiguous()\n","        return out.view(self.num_layers, bsz, -1)\n","\n","    def forward(self, src_tokens, **unused):\n","        bsz, seqlen = src_tokens.size()\n","        \n","        # get embeddings\n","        x = self.embed_tokens(src_tokens)\n","        x = self.dropout_in_module(x)\n","\n","        # B x T x C -> T x B x C\n","        x = x.transpose(0, 1)\n","        \n","        # 過雙向RNN\n","        h0 = x.new_zeros(2 * self.num_layers, bsz, self.hidden_dim)\n","        x, final_hiddens = self.rnn(x, h0)\n","        outputs = self.dropout_out_module(x)\n","        # outputs = [sequence len, batch size, hid dim * directions] 是最上層RNN的輸出\n","        # hidden =  [num_layers * directions, batch size  , hid dim]\n","        \n","        # 因為 Encoder 是雙向的RNN，所以需要將同一層兩個方向的 hidden state 接在一起\n","        final_hiddens = self.combine_bidir(final_hiddens, bsz)\n","        # hidden =  [num_layers x batch x num_directions*hidden]\n","        \n","        encoder_padding_mask = src_tokens.eq(self.padding_idx).t()\n","        return tuple(\n","            (\n","                outputs,  # seq_len x batch x hidden\n","                final_hiddens,  # num_layers x batch x num_directions*hidden\n","                encoder_padding_mask,  # seq_len x batch\n","            )\n","        )\n","    \n","    def reorder_encoder_out(self, encoder_out, new_order):\n","        # 這個beam search時會用到，意義並不是很重要\n","        return tuple(\n","            (\n","                encoder_out[0].index_select(1, new_order),\n","                encoder_out[1].index_select(1, new_order),\n","                encoder_out[2].index_select(1, new_order),\n","            )\n","        )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iYoWyfGiOn-7"},"source":["## Attention"]},{"cell_type":"markdown","metadata":{"id":"6s4ET6s9On-8"},"source":["- 當輸入過長，或是單獨靠 “content vector” 無法取得整個輸入的意思時，用 Attention Mechanism 來提供 Decoder 更多的資訊\n","- 根據現在 **Decoder embeddings** ，去計算在 **Encoder outputs** 中，那些與其有較高的關係，根據關係的數值來把 Encoder outputs 平均起來作為 **Decoder** RNN 的輸入 \n","- 常見 Attention 的實作是用 Neural Network / Dot Product 來算 **query** (decoder embeddings) 和 **key** (Encoder outputs) 之間的關係，再對所有算出來的數值做 **softmax** 得到分佈，最後根據這個分佈對 **values** (Encoder outputs) 做 **weight sum**\n","\n","- 參數:\n","  - *input_embed_dim*: key 的維度，應是 decoder 要做 attend 時的向量的維度\n","  - *source_embed_dim*: query 的維度，應是要被 attend 的向量(encoder outputs)的維度\n","  - *output_embed_dim*: value 的維度，應是做完 attention 後，下一層預期的向量維度\n","\n","- 輸入: \n","    - *inputs*: 就是 key，要 attend 別人的向量\n","    - *encoder_outputs*: 是 query/value，被 attend 的向量\n","    - *encoder_padding_mask*: 告訴我們哪些是位置的資訊不重要。\n","- 輸出: \n","    - *output*: 做完 attention 後的 context vector\n","    - *attention score*: attention 的分布\n"]},{"cell_type":"code","metadata":{"id":"11mfLrT6On-8"},"source":["class AttentionLayer(nn.Module):\n","    def __init__(self, input_embed_dim, source_embed_dim, output_embed_dim, bias=False):\n","        super().__init__()\n","\n","        self.input_proj = nn.Linear(input_embed_dim, source_embed_dim, bias=bias)\n","        self.output_proj = nn.Linear(\n","            input_embed_dim + source_embed_dim, output_embed_dim, bias=bias\n","        )\n","\n","    def forward(self, inputs, encoder_outputs, encoder_padding_mask):\n","        # inputs: T, B, dim\n","        # encoder_outputs: S x B x dim\n","        # padding mask:  S x B\n","        \n","        # convert all to batch first\n","        inputs = inputs.transpose(1,0) # B, T, dim\n","        encoder_outputs = encoder_outputs.transpose(1,0) # B, S, dim\n","        encoder_padding_mask = encoder_padding_mask.transpose(1,0) # B, S\n","        \n","        # 投影到encoder_outputs的維度\n","        x = self.input_proj(inputs)\n","\n","        # 計算attention\n","        # (B, T, dim) x (B, dim, S) = (B, T, S)\n","        attn_scores = torch.bmm(x, encoder_outputs.transpose(1,2))\n","\n","        # 擋住padding位置的attention\n","        if encoder_padding_mask is not None:\n","            # 利用broadcast  B, S -> (B, 1, S)\n","            encoder_padding_mask = encoder_padding_mask.unsqueeze(1)\n","            attn_scores = (\n","                attn_scores.float()\n","                .masked_fill_(encoder_padding_mask, float(\"-inf\"))\n","                .type_as(attn_scores)\n","            )  # FP16 support: cast to float and back\n","\n","        # 在source對應維度softmax\n","        attn_scores = F.softmax(attn_scores, dim=-1)\n","\n","        # 形狀 (B, T, S) x (B, S, dim) = (B, T, dim) 加權平均\n","        x = torch.bmm(attn_scores, encoder_outputs)\n","\n","        # (B, T, dim)\n","        x = torch.cat((x, inputs), dim=-1)\n","        x = torch.tanh(self.output_proj(x)) # concat + linear + tanh\n","        \n","        # 回復形狀 (B, T, dim) -> (T, B, dim)\n","        return x.transpose(1,0), attn_scores"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sw_GSLGWOn-8"},"source":["## Decoder 解碼器"]},{"cell_type":"markdown","metadata":{"id":"LUPcdgiWOn-8"},"source":["* 解碼器的 hidden states 會用編碼器最終隱藏狀態來初始化(content vector)\n","* 解碼器同時也根據目前 timestep 的輸入(也就是前幾個 timestep 的 output)，改變 hidden states，並輸出結果 \n","* 如果加入 attention 可以使表現更好\n","* 我們把 seq2seq 步驟寫在解碼器裡，好讓等等 Seq2Seq 這個型別可以通用 RNN 和 Transformer，而不用再改寫\n","- 參數:\n","  - *args*\n","      - decoder_embed_dim 是解碼器 embedding 的維度，類同 encoder_embed_dim，\n","      - decoder_ffn_embed_dim 是解碼器 RNN 的隱藏維度，類同 encoder_ffn_embed_dim\n","      - decoder_layers 解碼器 RNN 的層數\n","      - share_decoder_input_output_embed 通常 decoder 最後輸出的投影矩陣會和輸入 embedding 共用參數\n","  - *dictionary*: fairseq 幫我們做好的 dictionary.\n","  - *embed_tokens*: 事先做好的詞嵌入(nn.Embedding)\n","- 輸入: \n","    - *prev_output_tokens*: 英文的整數序列 e.g. 1, 28, 29, 205, 2 已經 shift 一格的 target\n","    - *encoder_out*: 編碼器的輸出\n","    - *incremental_state*: 這是測試階段為了加速，所以會記錄每個 timestep 的 hidden state 詳見 forward\n","- 輸出: \n","    - *outputs*: decoder 每個 timestep 的 logits，還沒經過 softmax 的分布\n","    - *extra*: 沒用到"]},{"cell_type":"code","metadata":{"id":"ZXV9HKy1On-9"},"source":["class RNNDecoder(FairseqIncrementalDecoder):\n","    def __init__(self, args, dictionary, embed_tokens):\n","        super().__init__(dictionary)\n","        self.embed_tokens = embed_tokens\n","        \n","        assert args.decoder_layers == args.encoder_layers, f\"\"\"seq2seq rnn requires that encoder \n","        and decoder have same layers of rnn. got: {args.encoder_layers, args.decoder_layers}\"\"\"\n","        assert args.decoder_ffn_embed_dim == args.encoder_ffn_embed_dim*2, f\"\"\"seq2seq-rnn requires \n","        that decoder hidden to be 2*encoder hidden dim. got: {args.decoder_ffn_embed_dim, args.encoder_ffn_embed_dim*2}\"\"\"\n","        \n","        self.embed_dim = args.decoder_embed_dim\n","        self.hidden_dim = args.decoder_ffn_embed_dim\n","        self.num_layers = args.decoder_layers\n","        \n","        \n","        self.dropout_in_module = nn.Dropout(args.dropout)\n","        self.rnn = nn.GRU(\n","            self.embed_dim, \n","            self.hidden_dim, \n","            self.num_layers, \n","            dropout=args.dropout, \n","            batch_first=False, \n","            bidirectional=False\n","        )\n","        self.attention = AttentionLayer(\n","            self.embed_dim, self.hidden_dim, self.embed_dim, bias=False\n","        ) \n","        # self.attention = None\n","        self.dropout_out_module = nn.Dropout(args.dropout)\n","        \n","        if self.hidden_dim != self.embed_dim:\n","            self.project_out_dim = nn.Linear(self.hidden_dim, self.embed_dim)\n","        else:\n","            self.project_out_dim = None\n","        \n","        if args.share_decoder_input_output_embed:\n","            self.output_projection = nn.Linear(\n","                self.embed_tokens.weight.shape[1],\n","                self.embed_tokens.weight.shape[0],\n","                bias=False,\n","            )\n","            self.output_projection.weight = self.embed_tokens.weight\n","        else:\n","            self.output_projection = nn.Linear(\n","                self.output_embed_dim, len(dictionary), bias=False\n","            )\n","            nn.init.normal_(\n","                self.output_projection.weight, mean=0, std=self.output_embed_dim ** -0.5\n","            )\n","        \n","    def forward(self, prev_output_tokens, encoder_out, incremental_state=None, **unused):\n","        # 取出encoder的輸出\n","        encoder_outputs, encoder_hiddens, encoder_padding_mask = encoder_out\n","        # outputs:          seq_len x batch x num_directions*hidden\n","        # encoder_hiddens:  num_layers x batch x num_directions*encoder_hidden\n","        # padding_mask:     seq_len x batch\n","        \n","        if incremental_state is not None and len(incremental_state) > 0:\n","            # 有上個timestep留下的資訊，讀進來就可以繼續decode，不用從bos重來\n","            prev_output_tokens = prev_output_tokens[:, -1:]\n","            cache_state = self.get_incremental_state(incremental_state, \"cached_state\")\n","            prev_hiddens = cache_state[\"prev_hiddens\"]\n","        else:\n","            # 沒有incremental state代表這是training或者是test time時的第一步\n","            # 準備seq2seq: 把encoder_hiddens pass進去decoder的hidden states\n","            prev_hiddens = encoder_hiddens\n","        \n","        bsz, seqlen = prev_output_tokens.size()\n","        \n","        # embed tokens\n","        x = self.embed_tokens(prev_output_tokens)\n","        x = self.dropout_in_module(x)\n","\n","        # B x T x C -> T x B x C\n","        x = x.transpose(0, 1)\n","                \n","        # 做decoder-to-encoder attention\n","        if self.attention is not None:\n","            x, attn = self.attention(x, encoder_outputs, encoder_padding_mask)\n","                        \n","        # 過單向RNN\n","        x, final_hiddens = self.rnn(x, prev_hiddens)\n","        # outputs = [sequence len, batch size, hid dim]\n","        # hidden =  [num_layers * directions, batch size  , hid dim]\n","        x = self.dropout_out_module(x)\n","                \n","        # 投影到embedding size (如果hidden 和embed size不一樣，然後share_embedding又設成True,需要額外project一次)\n","        if self.project_out_dim != None:\n","            x = self.project_out_dim(x)\n","        \n","        # 投影到vocab size 的分佈\n","        x = self.output_projection(x)\n","        \n","        # T x B x C -> B x T x C\n","        x = x.transpose(1, 0)\n","        \n","        # 如果是Incremental, 記錄這個timestep的hidden states, 下個timestep讀回來\n","        cache_state = {\n","            \"prev_hiddens\": final_hiddens,\n","        }\n","        self.set_incremental_state(incremental_state, \"cached_state\", cache_state)\n","        \n","        return x, None\n","    \n","    def reorder_incremental_state(\n","        self,\n","        incremental_state,\n","        new_order,\n","    ):\n","        # 這個beam search時會用到，意義並不是很重要\n","        cache_state = self.get_incremental_state(incremental_state, \"cached_state\")\n","        prev_hiddens = cache_state[\"prev_hiddens\"]\n","        prev_hiddens = [p.index_select(0, new_order) for p in prev_hiddens]\n","        cache_state = {\n","            \"prev_hiddens\": torch.stack(prev_hiddens),\n","        }\n","        self.set_incremental_state(incremental_state, \"cached_state\", cache_state)\n","        return"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ghfUec6sOn-9"},"source":["## Seq2Seq\n","- 由 **Encoder** 和 **Decoder** 組成\n","- 接收輸入並傳給 **Encoder** \n","- 將 **Encoder** 的輸出傳給 **Decoder**\n","- **Decoder** 根據前幾個 timestep 的輸出和 **Encoder** 輸出進行解碼  \n","- 當解碼完成後，將 **Decoder** 的輸出傳回 "]},{"cell_type":"code","metadata":{"id":"Q3LkVJXdOn-9"},"source":["class Seq2Seq(FairseqEncoderDecoderModel):\n","    def __init__(self, args, encoder, decoder):\n","        super().__init__(encoder, decoder)\n","        self.args = args\n","    \n","    def forward(\n","        self,\n","        src_tokens,\n","        src_lengths,\n","        prev_output_tokens,\n","        return_all_hiddens: bool = True,\n","    ):\n","        \"\"\"\n","        Run the forward pass for an encoder-decoder model.\n","        \"\"\"\n","        encoder_out = self.encoder(\n","            src_tokens, src_lengths=src_lengths, return_all_hiddens=return_all_hiddens\n","        )\n","        logits, extra = self.decoder(\n","            prev_output_tokens,\n","            encoder_out=encoder_out,\n","            src_lengths=src_lengths,\n","            return_all_hiddens=return_all_hiddens,\n","        )\n","        return logits, extra"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZCzjLJBQOn--"},"source":["# 模型初始化"]},{"cell_type":"code","metadata":{"id":"-XwshPaeOn--"},"source":[" # HINT: transformer 架構\n","from fairseq.models.transformer import (\n","    TransformerEncoder, \n","    TransformerDecoder,\n","   )\n","\n","def build_model(args, task):\n","    \"\"\" 按照參數設定建置模型 \"\"\"\n","    src_dict, tgt_dict = task.source_dictionary, task.target_dictionary\n","\n","    # 詞嵌入\n","    encoder_embed_tokens = nn.Embedding(len(src_dict), args.encoder_embed_dim, src_dict.pad())\n","    decoder_embed_tokens = nn.Embedding(len(tgt_dict), args.decoder_embed_dim, tgt_dict.pad())\n","    \n","    # 編碼器與解碼器\n","    # TODO: 替換成 TransformerEncoder 和 TransformerDecoder\n","    encoder = TransformerEncoder(args, src_dict, encoder_embed_tokens)\n","    decoder = TransformerDecoder(args, tgt_dict, decoder_embed_tokens)\n","    \n","    # 序列到序列模型\n","    model = Seq2Seq(args, encoder, decoder)\n","    \n","    # 序列到序列模型的初始化很重要 需要特別處理\n","    def init_params(module):\n","        from fairseq.modules import MultiheadAttention\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=0.02)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        if isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=0.02)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        if isinstance(module, MultiheadAttention):\n","            module.q_proj.weight.data.normal_(mean=0.0, std=0.02)\n","            module.k_proj.weight.data.normal_(mean=0.0, std=0.02)\n","            module.v_proj.weight.data.normal_(mean=0.0, std=0.02)\n","        if isinstance(module, nn.RNNBase):\n","            for name, param in module.named_parameters():\n","                if \"weight\" in name or \"bias\" in name:\n","                    param.data.uniform_(-0.1, 0.1)\n","            \n","    # 初始化模型\n","    model.apply(init_params)\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xfuouFRkOn--"},"source":["## 設定模型相關參數\n","參考參數\n","\n","|model|embedding dim|encoder ffn|encoder layers|decoder ffn|decoder layers|\n","|-|-|-|-|-|-|\n","|RNN|256|512|1|1024|1|\n","|Transformer|256|1024|4|1024|4|\n","\n","Strong baseline 用的參數可以參考 [Attention is all you need](#vaswani2017) 的 Table 3 的 transformer-base"]},{"cell_type":"code","metadata":{"id":"MJYhp_EPOn--"},"source":["arch_args = Namespace(\n","    encoder_embed_dim=512,\n","    encoder_ffn_embed_dim=2048,\n","    encoder_layers=6,\n","    decoder_embed_dim=512,\n","    decoder_ffn_embed_dim=2048,\n","    decoder_layers=6,\n","    share_decoder_input_output_embed=True,\n","    dropout=0.1,\n",")\n","\n","# HINT: 補上Transformer用的參數\n","def add_transformer_args(args):\n","    args.encoder_attention_heads=8\n","    args.encoder_normalize_before=True\n","    \n","    args.decoder_attention_heads=8\n","    args.decoder_normalize_before=True\n","    \n","    args.activation_fn=\"relu\"\n","    args.max_source_positions=1024\n","    args.max_target_positions=1024\n","    \n","    # 補上我們沒有設定的Transformer預設參數\n","    from fairseq.models.transformer import base_architecture \n","    base_architecture(arch_args)\n","\n","add_transformer_args(arch_args)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nz7DDSzTOn-_"},"source":["if config.use_wandb:\n","    wandb.config.update(vars(arch_args))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9DQ_jAZ3On-_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619662186722,"user_tz":-480,"elapsed":2202,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"5ea23fda-d292-4076-cf5a-90ae582ade58"},"source":["model = build_model(arch_args, task)\n","logger.info(model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-04-29 02:09:45 | INFO | hw5.seq2seq | Seq2Seq(\n","  (encoder): TransformerEncoder(\n","    (dropout_module): FairseqDropout()\n","    (embed_tokens): Embedding(8000, 512, padding_idx=1)\n","    (embed_positions): SinusoidalPositionalEmbedding()\n","    (layers): ModuleList(\n","      (0): TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout_module): FairseqDropout()\n","        (activation_dropout_module): FairseqDropout()\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (1): TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout_module): FairseqDropout()\n","        (activation_dropout_module): FairseqDropout()\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (2): TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout_module): FairseqDropout()\n","        (activation_dropout_module): FairseqDropout()\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (3): TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout_module): FairseqDropout()\n","        (activation_dropout_module): FairseqDropout()\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (4): TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout_module): FairseqDropout()\n","        (activation_dropout_module): FairseqDropout()\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (5): TransformerEncoderLayer(\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout_module): FairseqDropout()\n","        (activation_dropout_module): FairseqDropout()\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (decoder): TransformerDecoder(\n","    (dropout_module): FairseqDropout()\n","    (embed_tokens): Embedding(8000, 512, padding_idx=1)\n","    (embed_positions): SinusoidalPositionalEmbedding()\n","    (layers): ModuleList(\n","      (0): TransformerDecoderLayer(\n","        (dropout_module): FairseqDropout()\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (activation_dropout_module): FairseqDropout()\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (1): TransformerDecoderLayer(\n","        (dropout_module): FairseqDropout()\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (activation_dropout_module): FairseqDropout()\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (2): TransformerDecoderLayer(\n","        (dropout_module): FairseqDropout()\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (activation_dropout_module): FairseqDropout()\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (3): TransformerDecoderLayer(\n","        (dropout_module): FairseqDropout()\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (activation_dropout_module): FairseqDropout()\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (4): TransformerDecoderLayer(\n","        (dropout_module): FairseqDropout()\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (activation_dropout_module): FairseqDropout()\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (5): TransformerDecoderLayer(\n","        (dropout_module): FairseqDropout()\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (activation_dropout_module): FairseqDropout()\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","    (output_projection): Linear(in_features=512, out_features=8000, bias=False)\n","  )\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0H859YYjOn-_"},"source":["# Optimization 最佳化"]},{"cell_type":"markdown","metadata":{"id":"6xJ-oFmUOn-_"},"source":["## Loss: Label Smoothing Regularization\n","* 讓模型學習輸出較不集中的分佈，防止模型過度自信\n","* 有時候Ground Truth並非唯一答案，所以在算loss時，我們會保留一部份機率給正確答案以外的label\n","* 可以有效防止過度擬合\n","\n","code [source](https://fairseq.readthedocs.io/en/latest/_modules/fairseq/criterions/label_smoothed_cross_entropy.html)"]},{"cell_type":"code","metadata":{"id":"aMcGwJdaOn-_"},"source":["class LabelSmoothedCrossEntropyCriterion(nn.Module):\n","    def __init__(self, smoothing, ignore_index=None, reduce=True):\n","        super().__init__()\n","        self.smoothing = smoothing\n","        self.ignore_index = ignore_index\n","        self.reduce = reduce\n","    \n","    def forward(self, lprobs, target):\n","        if target.dim() == lprobs.dim() - 1:\n","            target = target.unsqueeze(-1)\n","        # nll: Negative log likelihood，當目標是one-hot時的cross-entropy loss. 以下同 F.nll_loss\n","        nll_loss = -lprobs.gather(dim=-1, index=target)\n","        # 將一部分正確答案的機率分配給其他label 所以當計算cross-entropy時等於把所有label的log prob加起來\n","        smooth_loss = -lprobs.sum(dim=-1, keepdim=True)\n","        if self.ignore_index is not None:\n","            pad_mask = target.eq(self.ignore_index)\n","            nll_loss.masked_fill_(pad_mask, 0.0)\n","            smooth_loss.masked_fill_(pad_mask, 0.0)\n","        else:\n","            nll_loss = nll_loss.squeeze(-1)\n","            smooth_loss = smooth_loss.squeeze(-1)\n","        if self.reduce:\n","            nll_loss = nll_loss.sum()\n","            smooth_loss = smooth_loss.sum()\n","        # 計算cross-entropy時 加入分配給其他label的loss\n","        eps_i = self.smoothing / lprobs.size(-1)\n","        loss = (1.0 - self.smoothing) * nll_loss + eps_i * smooth_loss\n","        return loss\n","\n","# 一般都用0.1效果就很好了\n","criterion = LabelSmoothedCrossEntropyCriterion(\n","    smoothing=0.1,\n","    ignore_index=task.target_dictionary.pad(),\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6sSy11RQOn_A"},"source":["## Optimizer: Adam + lr scheduling\n","Inverse square root 排程對於訓練 Transformer 時的穩定性很重要，後來也用在 RNN 上。\n","根據底下公式來更新 learning rate，前期線性增長，後期根據更新步數方根的倒數來遞減。\n","$$lrate = d_{\\text{model}}^{-0.5}\\cdot\\min({step\\_num}^{-0.5},{step\\_num}\\cdot{warmup\\_steps}^{-1.5})$$\n","code [source](https://nlp.seas.harvard.edu/2018/04/03/attention.html)"]},{"cell_type":"code","metadata":{"id":"GtX0YPVqOn_A"},"source":["class NoamOpt:\n","    \"Optim wrapper that implements rate.\"\n","    def __init__(self, model_size, factor, warmup, optimizer):\n","        self.optimizer = optimizer\n","        self._step = 0\n","        self.warmup = warmup\n","        self.factor = factor\n","        self.model_size = model_size\n","        self._rate = 0\n","    \n","    @property\n","    def param_groups(self):\n","        return self.optimizer.param_groups\n","        \n","    def multiply_grads(self, c):\n","        \"\"\"Multiplies grads by a constant *c*.\"\"\"                \n","        for group in self.param_groups:\n","            for p in group['params']:\n","                if p.grad is not None:\n","                    p.grad.data.mul_(c)\n","        \n","    def step(self):\n","        \"Update parameters and rate\"\n","        self._step += 1\n","        rate = self.rate()\n","        for p in self.param_groups:\n","            p['lr'] = rate\n","        self._rate = rate\n","        self.optimizer.step()\n","        \n","    def rate(self, step = None):\n","        \"Implement `lrate` above\"\n","        if step is None:\n","            step = self._step\n","        return 0 if not step else self.factor * \\\n","            (self.model_size ** (-0.5) *\n","            min(step ** (-0.5), step * self.warmup ** (-1.5)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uj2_BT50On_A"},"source":["## 排程視覺化"]},{"cell_type":"code","metadata":{"id":"P_yUU45zOn_B","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1619662191407,"user_tz":-480,"elapsed":1416,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"6346cc47-6340-41b2-de27-e0f456f77f9e"},"source":["optimizer = NoamOpt(\n","    model_size=arch_args.encoder_embed_dim, \n","    factor=config.lr_factor, \n","    warmup=config.lr_warmup, \n","    optimizer=torch.optim.AdamW(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9, weight_decay=0.0001))\n","plt.plot(np.arange(1, 100000), [optimizer.rate(i) for i in range(1, 100000)])\n","plt.legend([f\"{optimizer.model_size}:{optimizer.warmup}\"])\n","None"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"sgQDxh4pOn_B"},"source":["# 訓練步驟"]},{"cell_type":"markdown","metadata":{"id":"Jf60B8CxOn_B"},"source":["## Training 訓練"]},{"cell_type":"code","metadata":{"id":"jrZbDw4bOn_B"},"source":["from fairseq.data import iterators\n","from torch.cuda.amp import GradScaler, autocast\n","\n","def train_one_epoch(epoch_itr, model, task, criterion, optimizer, accum_steps=1):\n","    itr = epoch_itr.next_epoch_itr(shuffle=True)\n","    itr = iterators.GroupedIterator(itr, accum_steps) # 梯度累積: 每 accum_steps 個 sample 更新一次\n","    \n","    stats = {\"loss\": []}\n","    scaler = GradScaler() # 混和精度訓練 automatic mixed precision (amp) \n","    \n","    model.train()\n","    progress = tqdm.tqdm(itr, desc=f\"train epoch {epoch_itr.epoch}\", leave=False)\n","    for samples in progress:\n","        model.zero_grad()\n","        accum_loss = 0\n","        sample_size = 0\n","        # 梯度累積: 每 accum_steps 個 sample 更新一次\n","        for i, sample in enumerate(samples):\n","            if i == 1:\n","                # emptying the CUDA cache after the first step can reduce the chance of OOM\n","                torch.cuda.empty_cache()\n","\n","            sample = utils.move_to_cuda(sample, device=device)\n","            target = sample[\"target\"]\n","            sample_size_i = sample[\"ntokens\"]\n","            sample_size += sample_size_i\n","            \n","            # 混和精度訓練 \n","            with autocast():\n","                net_output = model.forward(**sample[\"net_input\"])\n","                lprobs = F.log_softmax(net_output[0], -1)            \n","                loss = criterion(lprobs.view(-1, lprobs.size(-1)), target.view(-1))\n","                \n","                # logging\n","                accum_loss += loss.item()\n","                # back-prop\n","                scaler.scale(loss).backward()                \n","        \n","        scaler.unscale_(optimizer)\n","        optimizer.multiply_grads(1 / (sample_size or 1.0)) # (sample_size or 1.0) handles the case of a zero gradient\n","        gnorm = nn.utils.clip_grad_norm_(model.parameters(), config.clip_norm) # 梯度裁剪 防止梯度爆炸\n","        \n","        scaler.step(optimizer)\n","        scaler.update()\n","        \n","        # logging\n","        loss_print = accum_loss/sample_size\n","        stats[\"loss\"].append(loss_print)\n","        progress.set_postfix(loss=loss_print)\n","        if config.use_wandb:\n","            wandb.log({\n","                \"train/loss\": loss_print,\n","                \"train/grad_norm\": gnorm.item(),\n","                \"train/lr\": optimizer.rate(),\n","                \"train/sample_size\": sample_size,\n","            })\n","        \n","    loss_print = np.mean(stats[\"loss\"])\n","    logger.info(f\"training loss: {loss_print:.4f}\")\n","    return stats"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-BZOrLgfOn_C"},"source":["## Validation & Inference 檢驗和推論\n","為防止訓練發生過度擬合，每過一段時間要做一次檢測，計算模型在未看過的資料上的表現。\n","- 過程基本上和training一樣，另外加上 inference\n","- 檢驗完畢可順便儲存模型參數\n","\n","單看 validation loss，我們很難知道模型真實的效能\n","- 直接用當前模型去生成翻譯結果 (hypothesis)，再和正確答案 (reference) 計算 BLEU score\n","- 也可用肉眼看翻譯結果的好壞\n","- 我們用 fairseq 寫好的 sequence generator 來進行 beam search 生成翻譯結果"]},{"cell_type":"code","metadata":{"id":"LKkzxmA6On_C"},"source":["# fairseq 的 beam search generator\n","# 給定模型和輸入序列，用 beam search 生成翻譯結果\n","sequence_generator = task.build_generator([model], config)\n","\n","def decode(toks, dictionary):\n","    # 從 Tensor 轉成人看得懂的句子\n","    s = dictionary.string(\n","        toks.int().cpu(),\n","        config.post_process,\n","    )\n","    return s if s else \"<unk>\"\n","\n","def inference_step(sample, model):\n","    gen_out = sequence_generator.generate([model], sample)\n","    srcs = []\n","    hyps = []\n","    refs = []\n","    for i in range(len(gen_out)):\n","        # 對於每個 sample, 收集輸入，輸出和參考答案，稍後計算 BLEU\n","        srcs.append(decode(\n","            utils.strip_pad(sample[\"net_input\"][\"src_tokens\"][i], task.source_dictionary.pad()), \n","            task.source_dictionary,\n","        ))\n","        hyps.append(decode(\n","            gen_out[i][0][\"tokens\"], # 0 代表取出 beam 內分數第一的輸出結果\n","            task.target_dictionary,\n","        ))\n","        refs.append(decode(\n","            utils.strip_pad(sample[\"target\"][i], task.target_dictionary.pad()), \n","            task.target_dictionary,\n","        ))\n","    return srcs, hyps, refs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2oiEZkmTOn_C"},"source":["import shutil\n","import sacrebleu\n","\n","def validate(model, task, criterion, log_to_wandb=True):\n","    logger.info('begin validation')\n","    itr = load_data_iterator(task, \"valid\", 1, config.max_tokens, config.num_workers).next_epoch_itr(shuffle=False)\n","    \n","    stats = {\"loss\":[], \"bleu\": 0, \"srcs\":[], \"hyps\":[], \"refs\":[]}\n","    srcs = []\n","    hyps = []\n","    refs = []\n","    \n","    model.eval()\n","    progress = tqdm.tqdm(itr, desc=f\"validation\", leave=False)\n","    with torch.no_grad():\n","        for i, sample in enumerate(progress):\n","            # validation loss\n","            sample = utils.move_to_cuda(sample, device=device)\n","            net_output = model.forward(**sample[\"net_input\"])\n","\n","            lprobs = F.log_softmax(net_output[0], -1)\n","            target = sample[\"target\"]\n","            sample_size = sample[\"ntokens\"]\n","            loss = criterion(lprobs.view(-1, lprobs.size(-1)), target.view(-1)) / sample_size\n","            progress.set_postfix(valid_loss=loss.item())\n","            stats[\"loss\"].append(loss)\n","            \n","            # 進行推論\n","            s, h, r = inference_step(sample, model)\n","            srcs.extend(s)\n","            hyps.extend(h)\n","            refs.extend(r)\n","            \n","    tok = 'zh' if task.cfg.target_lang == 'zh' else '13a'\n","    stats[\"loss\"] = torch.stack(stats[\"loss\"]).mean().item()\n","    stats[\"bleu\"] = sacrebleu.corpus_bleu(hyps, [refs], tokenize=tok) # 計算BLEU score\n","    stats[\"srcs\"] = srcs\n","    stats[\"hyps\"] = hyps\n","    stats[\"refs\"] = refs\n","    \n","    if config.use_wandb and log_to_wandb:\n","        wandb.log({\n","            \"valid/loss\": stats[\"loss\"],\n","            \"valid/bleu\": stats[\"bleu\"].score,\n","        }, commit=False)\n","    \n","    showid = np.random.randint(len(hyps))\n","    logger.info(\"example source: \" + srcs[showid])\n","    logger.info(\"example hypothesis: \" + hyps[showid])\n","    logger.info(\"example reference: \" + refs[showid])\n","    \n","    # show bleu results\n","    logger.info(f\"validation loss:\\t{stats['loss']:.4f}\")\n","    logger.info(stats[\"bleu\"].format())\n","    return stats"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jkGxeGgHOn_C"},"source":["# 儲存及載入模型參數"]},{"cell_type":"code","metadata":{"id":"-93km3enOn_D"},"source":["def validate_and_save(model, task, criterion, optimizer, epoch, save=True):   \n","    stats = validate(model, task, criterion)\n","    bleu = stats['bleu']\n","    loss = stats['loss']\n","    if save:\n","        # save epoch checkpoints\n","        savedir = Path(config.savedir).absolute()\n","        savedir.mkdir(parents=True, exist_ok=True)\n","        bleu_list.append(str(stats[\"bleu\"].format()).split(' ')[2])\n","\n","        check = {\n","            \"model\": model.state_dict(),\n","            \"stats\": {\"bleu\": bleu.score, \"loss\": loss},\n","            \"optim\": {\"step\": optimizer._step}\n","        }\n","        torch.save(check, savedir/f\"checkpoint{epoch}.pt\")\n","        shutil.copy(savedir/f\"checkpoint{epoch}.pt\", savedir/f\"checkpoint_last.pt\")\n","        logger.info(f\"saved epoch checkpoint: {savedir}/checkpoint{epoch}.pt\")\n","    \n","        # save epoch samples\n","        with open(savedir/f\"samples{epoch}.{config.source_lang}-{config.target_lang}.txt\", \"w\") as f:\n","            for s, h in zip(stats[\"srcs\"], stats[\"hyps\"]):\n","                f.write(f\"{s}\\t{h}\\n\")\n","\n","        # get best valid bleu    \n","        if getattr(validate_and_save, \"best_bleu\", 0) < bleu.score:\n","            validate_and_save.best_bleu = bleu.score\n","            torch.save(check, savedir/f\"checkpoint_best.pt\")\n","            \n","        # del_file = savedir / f\"checkpoint{epoch - config.keep_last_epochs}.pt\"\n","        # if del_file.exists():\n","        #     del_file.unlink()\n","    \n","    return stats, bleu_list\n","\n","def try_load_checkpoint(model, optimizer=None, name=None):\n","    name = name if name else \"checkpoint_last.pt\"\n","    checkpath = Path(config.savedir)/name\n","    if checkpath.exists():\n","        check = torch.load(checkpath)\n","        model.load_state_dict(check[\"model\"])\n","        stats = check[\"stats\"]\n","        step = \"unknown\"\n","        if optimizer != None:\n","            optimizer._step = step = check[\"optim\"][\"step\"]\n","        logger.info(f\"loaded checkpoint {checkpath}: step={step} loss={stats['loss']} bleu={stats['bleu']}\")\n","    else:\n","        logger.info(f\"no checkpoints found at {checkpath}!\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-zvQfCk6On_D"},"source":["# 主程式\n","## 訓練迴圈"]},{"cell_type":"code","metadata":{"id":"J6uHysD7On_D"},"source":["model = model.to(device=device)\n","criterion = criterion.to(device=device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CkayyidrOn_E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619662241071,"user_tz":-480,"elapsed":810,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"ad9192fe-abd6-4c65-bff3-163c41efc30e"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Thu Apr 29 02:10:40 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    39W / 300W |   1531MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2DoAPekOOn_E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619662253926,"user_tz":-480,"elapsed":788,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"57735895-85e2-4511-b1b6-d28569b0636a"},"source":["logger.info(\"task: {}\".format(task.__class__.__name__))\n","logger.info(\"encoder: {}\".format(model.encoder.__class__.__name__))\n","logger.info(\"decoder: {}\".format(model.decoder.__class__.__name__))\n","logger.info(\"criterion: {}\".format(criterion.__class__.__name__))\n","logger.info(\"optimizer: {}\".format(optimizer.__class__.__name__))\n","logger.info(\n","    \"num. model params: {:,} (num. trained: {:,})\".format(\n","        sum(p.numel() for p in model.parameters()),\n","        sum(p.numel() for p in model.parameters() if p.requires_grad),\n","    )\n",")\n","logger.info(f\"max tokens per batch = {config.max_tokens}, accumulate steps = {config.accum_steps}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-04-29 02:10:53 | INFO | hw5.seq2seq | task: TranslationTask\n","2021-04-29 02:10:53 | INFO | hw5.seq2seq | encoder: TransformerEncoder\n","2021-04-29 02:10:53 | INFO | hw5.seq2seq | decoder: TransformerDecoder\n","2021-04-29 02:10:53 | INFO | hw5.seq2seq | criterion: LabelSmoothedCrossEntropyCriterion\n","2021-04-29 02:10:53 | INFO | hw5.seq2seq | optimizer: NoamOpt\n","2021-04-29 02:10:53 | INFO | hw5.seq2seq | num. model params: 52,332,544 (num. trained: 52,332,544)\n","2021-04-29 02:10:53 | INFO | hw5.seq2seq | max tokens per batch = 8192, accumulate steps = 2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"uvbzbYP9On_E","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["16e38fbca53c40b087d971257ffe1fe0","d72dfe4b8ece46e8a2e19ac205168ab2","681d2de321b744fd995ed3f45e99ae7c","48552e6b8232422ca6b6b5da3943e671","45dd7828ca2844cbbbe2179e257cfa2a","bf7028e3ee9d424ba356f28c5ffac623","8ebc436bfe5f427483bf0e5848519ee3","5b158534a86648b38790714a472e12bc","8f2345c6a74d476ebd468133ee195af5","318f75d9d8334baaa62385f48af8af0a","d2c18e76d5154b27bf1d3a06f6d2db87","dd9f8f637e344ba6a931b04be6ad59e6","c002b5effdc3435487b06ed68444454d","5dd4b6a9e2f44c80aa8d996b069a6d60","50ec20aae90440089630aeac6384d302","92319027210c4c739da8f9aa28814551","752b998c63e6466f921582cc4484601d","953125fda5d14c8b9f484d7e7680f365","04dd2714262f478aa2b9f712f35ab8ab","2124bb656544416cb7fc351b30700aa5","e310a1656bb4400f93d62b5d451ccac2","23595079044e41a8a98d5205553c98df","3b3fa8478ba245fa861820c8f1e7f319","8852c9deedb64b0cb9a98d150565e423","83b22f2ac3c24064b09d8cde92e85603","ebb1081450154be296ef5b882a828488","95301ff06e1a4fe6b7c9b679b8ea881f","d1467beaff7b451aa78c77c74b183be9","2085ac863b5342cc90c7470a6ff27cbc","d58e2481570c4bdf8d79d4712d0894fa","f3b6d15fccb6486ba9ba8e87b59182e2","e30c14d5e2b14b608bae0129911aa7a3","5439b29fe68e4b1486202d867de29b8e","c0c5ac146c4244c59ddb641c2258310c","4c0ced99f38342fb9fbef91d8c3a9b99","9cf2003ad5f7404082892ab586a4c48e","c98e2665499e488194daf8b4fe486be1"]},"executionInfo":{"status":"error","timestamp":1619674429873,"user_tz":-480,"elapsed":275608,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"ada4f38f-cb82-48f2-e2a3-249b155d4445"},"source":["#bleu_list = []\n","epoch_itr = load_data_iterator(task, \"train\", config.start_epoch, config.max_tokens, config.num_workers)\n","try_load_checkpoint(model, optimizer, name=config.resume)\n","while epoch_itr.next_epoch_idx <= config.max_epoch:\n","    # train for one epoch\n","    train_one_epoch(epoch_itr, model, task, criterion, optimizer, config.accum_steps)\n","    stats = validate_and_save(model, task, criterion, optimizer, epoch=epoch_itr.epoch)\n","    logger.info(\"end of epoch {}\".format(epoch_itr.epoch))    \n","    epoch_itr = load_data_iterator(task, \"train\", epoch_itr.next_epoch_idx, config.max_tokens, config.num_workers)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-04-29 05:06:33 | INFO | hw5.seq2seq | loaded checkpoint /content/backward/checkpoint_last.pt: step=24200 loss=2.664158582687378 bleu=20.605370413020456\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"16e38fbca53c40b087d971257ffe1fe0","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='train epoch 31', max=818.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r2021-04-29 05:11:36 | INFO | hw5.seq2seq | training loss: 1.9456\n","2021-04-29 05:11:36 | INFO | hw5.seq2seq | begin validation\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8f2345c6a74d476ebd468133ee195af5","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='validation', max=27.0, style=ProgressStyle(description_wi…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r2021-04-29 05:12:07 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n","2021-04-29 05:12:07 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-04-29 05:12:07 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n","2021-04-29 05:12:08 | INFO | hw5.seq2seq | example source: 新聞的標題是 「 印度:你絕不會想聽的故事 」 。\n","2021-04-29 05:12:08 | INFO | hw5.seq2seq | example hypothesis: the headline was , \" india: you would never want to hear a story . \"\n","2021-04-29 05:12:08 | INFO | hw5.seq2seq | example reference: the report was titled , \" india: the story you never wanted to hear . \"\n","2021-04-29 05:12:08 | INFO | hw5.seq2seq | validation loss:\t2.6703\n","2021-04-29 05:12:08 | INFO | hw5.seq2seq | BLEU = 20.05 56.7/28.1/15.9/9.3 (BP = 0.912 ratio = 0.915 hyp_len = 70534 ref_len = 77050)\n","2021-04-29 05:12:09 | INFO | hw5.seq2seq | saved epoch checkpoint: /content/backward/checkpoint31.pt\n","2021-04-29 05:12:09 | INFO | hw5.seq2seq | end of epoch 31\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"318f75d9d8334baaa62385f48af8af0a","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='train epoch 32', max=818.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r2021-04-29 05:17:12 | INFO | hw5.seq2seq | training loss: 1.9347\n","2021-04-29 05:17:12 | INFO | hw5.seq2seq | begin validation\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"953125fda5d14c8b9f484d7e7680f365","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='validation', max=27.0, style=ProgressStyle(description_wi…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r2021-04-29 05:17:42 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n","2021-04-29 05:17:42 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-04-29 05:17:42 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n","2021-04-29 05:17:44 | INFO | hw5.seq2seq | example source: 這就相當於你在1998年給汽車加滿一次油的錢放到2011年可以讓你在地球和木星之間來回開2次 。\n","2021-04-29 05:17:44 | INFO | hw5.seq2seq | example hypothesis: this is the equivalent of giving a gasoline to the car in 1998 and putting it on twice for you between the earth and jupiter .\n","2021-04-29 05:17:44 | INFO | hw5.seq2seq | example reference: that's the equivalent of you filling up your car with gas in 1998 , waiting until 2011 , and now you can drive to jupiter and back twice .\n","2021-04-29 05:17:44 | INFO | hw5.seq2seq | validation loss:\t2.6798\n","2021-04-29 05:17:44 | INFO | hw5.seq2seq | BLEU = 20.14 56.7/28.1/15.9/9.3 (BP = 0.914 ratio = 0.917 hyp_len = 70678 ref_len = 77050)\n","2021-04-29 05:17:44 | INFO | hw5.seq2seq | saved epoch checkpoint: /content/backward/checkpoint32.pt\n","2021-04-29 05:17:44 | INFO | hw5.seq2seq | end of epoch 32\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"04dd2714262f478aa2b9f712f35ab8ab","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='train epoch 33', max=818.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r2021-04-29 05:22:49 | INFO | hw5.seq2seq | training loss: 1.9242\n","2021-04-29 05:22:49 | INFO | hw5.seq2seq | begin validation\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2124bb656544416cb7fc351b30700aa5","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='validation', max=27.0, style=ProgressStyle(description_wi…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r2021-04-29 05:23:20 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n","2021-04-29 05:23:20 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-04-29 05:23:20 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n","2021-04-29 05:23:21 | INFO | hw5.seq2seq | example source: 在那之前每一件計劃都是我個人的東西 , 所以當大家開始評論 , 開始對你的程式給意見時 , 真的是一種啟示 。\n","2021-04-29 05:23:21 | INFO | hw5.seq2seq | example hypothesis: each project that had been there was a personal project , so when people started talking about it , it was really a revelation to start getting your code .\n","2021-04-29 05:23:21 | INFO | hw5.seq2seq | example reference: and every project before that had been completely personal and it was a revelation when people just started commenting , started giving feedback on your code .\n","2021-04-29 05:23:21 | INFO | hw5.seq2seq | validation loss:\t2.6763\n","2021-04-29 05:23:21 | INFO | hw5.seq2seq | BLEU = 20.58 56.4/28.0/16.0/9.4 (BP = 0.932 ratio = 0.934 hyp_len = 71975 ref_len = 77050)\n","2021-04-29 05:23:22 | INFO | hw5.seq2seq | saved epoch checkpoint: /content/backward/checkpoint33.pt\n","2021-04-29 05:23:22 | INFO | hw5.seq2seq | end of epoch 33\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d1467beaff7b451aa78c77c74b183be9","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='train epoch 34', max=818.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r2021-04-29 05:28:21 | INFO | hw5.seq2seq | training loss: 1.9134\n","2021-04-29 05:28:21 | INFO | hw5.seq2seq | begin validation\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9cf2003ad5f7404082892ab586a4c48e","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='validation', max=27.0, style=ProgressStyle(description_wi…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r2021-04-29 05:28:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n","2021-04-29 05:28:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-04-29 05:28:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n","2021-04-29 05:28:53 | INFO | hw5.seq2seq | example source: 如果你能做到這些 , 那麼你就已經完成了真正的英雄之旅 。\n","2021-04-29 05:28:53 | INFO | hw5.seq2seq | example hypothesis: if you can do that , then you've accomplished actual heroic journeys .\n","2021-04-29 05:28:53 | INFO | hw5.seq2seq | example reference: if you're able to do that , then you've taken the real hero's journey .\n","2021-04-29 05:28:53 | INFO | hw5.seq2seq | validation loss:\t2.6942\n","2021-04-29 05:28:53 | INFO | hw5.seq2seq | BLEU = 20.23 56.9/28.2/16.0/9.5 (BP = 0.910 ratio = 0.914 hyp_len = 70424 ref_len = 77050)\n","2021-04-29 05:28:54 | INFO | hw5.seq2seq | saved epoch checkpoint: /content/backward/checkpoint34.pt\n","2021-04-29 05:28:54 | INFO | hw5.seq2seq | end of epoch 34\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c98e2665499e488194daf8b4fe486be1","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='train epoch 35', max=818.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-55-2a862d2ed341>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mepoch_itr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_epoch_idx\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# train for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_itr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch_itr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"end of epoch {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_itr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-42-e3d66598e8c4>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(epoch_itr, model, task, criterion, optimizer, accum_steps)\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0maccum_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0;31m# back-prop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munscale_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"LMpH9JxSOn_E"},"source":["# Submission 繳交檔案"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FazncN6xHrP-","executionInfo":{"status":"ok","timestamp":1619677436863,"user_tz":-480,"elapsed":900,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"a19cd24c-931d-4279-bef4-19ba93713833"},"source":["bleu_index = {}\n","bleuscore = []\n","maxscore = []\n","bleu_max5 = []\n","for i in range(len(bleu_list)):\n","  bleu_index[str(i+1)] = bleu_list[i]\n","  bleuscore.append(float(bleu_list[i]))\n","\n","for i in range(5):\n","  maxscore.append(float(bleuscore.pop(bleuscore.index(max(bleuscore)))))\n","for key, value in bleu_index.items():\n","  if (float(value) in maxscore):\n","    bleu_max5.append(key)\n","bleu_max5  "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: '22', 1: '22', 2: '20', 3: '16', 4: '15', 5: '14', 6: '12'}"]},"metadata":{"tags":[]},"execution_count":108}]},{"cell_type":"code","metadata":{"id":"lXmRILOSQQeB"},"source":["!mkdir /content/max_checkpoint/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uzByzUZ6Pv6f","executionInfo":{"status":"ok","timestamp":1619677770071,"user_tz":-480,"elapsed":18103,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"30778395-586b-4cdc-cadf-5b7362015d02"},"source":["f0= '/content/backward/checkpoint%s.pt'%bleu_max5[0]\n","!$f0 = f0\n","!echo $f0\n","!cp -r $f0 '/content/max_checkpoint/'\n","f1 = '/content/backward/checkpoint%s.pt'%bleu_max5[1]\n","!$f1 = f1\n","!echo $f1\n","!cp -r $f1 '/content/max_checkpoint/'\n","f2 = '/content/backward/checkpoint%s.pt'%bleu_max5[2]\n","!$f2 = f2\n","!echo $f2\n","!cp -r $f2 '/content/max_checkpoint/'\n","f4 = '/content/backward/checkpoint%s.pt'%bleu_max5[4]\n","!$f4 = f4\n","!echo $f4\n","!cp -r $f4 '/content/max_checkpoint/'\n","f3 = '/content/backward/checkpoint%s.pt'%bleu_max5[3]\n","!$f3 = f3\n","!echo $f3\n","!cp -r $f3 '/content/max_checkpoint/'\n","f5 = '/content/backward/checkpoint%s.pt'%bleu_max5[5]\n","!$f5 = f5\n","!echo $f5\n","!cp -r $f5 '/content/max_checkpoint/'\n","f6 = '/content/backward/checkpoint%s.pt'%bleu_max5[6]\n","!$f6 = f6\n","!echo $f6\n","!cp -r $f6 '/content/max_checkpoint/'\n","    "],"execution_count":null,"outputs":[{"output_type":"stream","text":["/bin/bash: /content/backward/checkpoint22.pt: Permission denied\n","/content/backward/checkpoint22.pt\n","/bin/bash: /content/backward/checkpoint22.pt: Permission denied\n","/content/backward/checkpoint22.pt\n","/bin/bash: /content/backward/checkpoint20.pt: Permission denied\n","/content/backward/checkpoint20.pt\n","/bin/bash: /content/backward/checkpoint15.pt: Permission denied\n","/content/backward/checkpoint15.pt\n","/bin/bash: /content/backward/checkpoint16.pt: Permission denied\n","/content/backward/checkpoint16.pt\n","/bin/bash: /content/backward/checkpoint14.pt: Permission denied\n","/content/backward/checkpoint14.pt\n","/bin/bash: /content/backward/checkpoint12.pt: Permission denied\n","/content/backward/checkpoint12.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qYqjir4zOn_E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619677834262,"user_tz":-480,"elapsed":4321,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"e164604a-1ea3-4472-8910-d59c5a5bf7ad"},"source":["# 把幾個 checkpoint 平均起來可以達到 ensemble 的效果\n","#checkdir='/content/drive/MyDrive/bt'\n","checkdir='/content/max_checkpoint'\n","!python ./fairseq/scripts/average_checkpoints.py \\\n","--inputs {checkdir} \\\n","--num-epoch-checkpoints 5 \\\n","--output {checkdir}/avg_last_5_checkpoint.pt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Namespace(checkpoint_upper_bound=None, inputs=['/content/max_checkpoint'], num_epoch_checkpoints=5, num_update_checkpoints=None, output='/content/max_checkpoint/avg_last_5_checkpoint.pt')\n","averaging checkpoints:  ['/content/max_checkpoint/checkpoint22.pt', '/content/max_checkpoint/checkpoint20.pt', '/content/max_checkpoint/checkpoint16.pt', '/content/max_checkpoint/checkpoint15.pt', '/content/max_checkpoint/checkpoint14.pt']\n","Finished writing averaged checkpoint to /content/max_checkpoint/avg_last_5_checkpoint.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QgZj5hCvU6dM"},"source":["!cp /content/max_checkpoint/avg_last_5_checkpoint.pt /content/backward/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yb9K5dB_On_F"},"source":["## 確認生成繳交檔案的模型參數"]},{"cell_type":"code","metadata":{"id":"b9N5Kp1eOn_F","colab":{"base_uri":"https://localhost:8080/","height":207,"referenced_widgets":["ac8fd36b760b4a37944694797c4ccad8","2faf265c8e024192b7937c34e997c913","64b2cdb2ef664851889009307c483362","3c92e4eeb8c2407f9342ac2468fd9f01","35de21041d7b40538208fd3992cf41cb","c69c1d8ddd5449208ee0560e9a4268f1","e4a2bd19bfed420aa219b255af295ae8","2eb49c9661ea4264880b5c23b0ab41d0"]},"executionInfo":{"status":"ok","timestamp":1619677973334,"user_tz":-480,"elapsed":33130,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"b1a10ba5-701d-441f-aab6-3f4efbb43181"},"source":["# checkpoint_last.pt : 最後一次檢驗的檔案\n","# checkpoint_best.pt : 檢驗 BLEU 最高的檔案\n","# avg_last_5_checkpoint.pt:　最5後個檔案平均\n","try_load_checkpoint(model, name=\"avg_last_5_checkpoint.pt\")\n","validate(model, task, criterion, log_to_wandb=False)\n","None"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-04-29 06:32:21 | INFO | hw5.seq2seq | loaded checkpoint /content/backward/avg_last_5_checkpoint.pt: step=unknown loss=2.59552001953125 bleu=20.454427985585347\n","2021-04-29 06:32:21 | INFO | hw5.seq2seq | begin validation\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ac8fd36b760b4a37944694797c4ccad8","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='validation', max=27.0, style=ProgressStyle(description_wi…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["2021-04-29 06:32:52 | WARNING | sacrebleu | That's 100 lines that end in a tokenized period ('.')\n","2021-04-29 06:32:52 | WARNING | sacrebleu | It looks like you forgot to detokenize your test data, which may hurt your score.\n","2021-04-29 06:32:52 | WARNING | sacrebleu | If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n","2021-04-29 06:32:53 | INFO | hw5.seq2seq | example source: 這是個有意義的結論 , 原因有幾點 。\n","2021-04-29 06:32:53 | INFO | hw5.seq2seq | example hypothesis: it's a meaningful conclusion for a few reasons .\n","2021-04-29 06:32:53 | INFO | hw5.seq2seq | example reference: makes sense . and this is important for a couple of reasons .\n","2021-04-29 06:32:53 | INFO | hw5.seq2seq | validation loss:\t2.5199\n","2021-04-29 06:32:53 | INFO | hw5.seq2seq | BLEU = 21.71 58.4/30.0/17.5/10.5 (BP = 0.912 ratio = 0.915 hyp_len = 70519 ref_len = 77050)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bBqkz4baOn_F"},"source":["## 進行預測"]},{"cell_type":"code","metadata":{"id":"iqu5h1PaOn_F"},"source":["def generate_prediction(model, task, split=\"test\", outfile=\"/content/drive/MyDrive/Colab Notebooks/prediction.txt\"):    \n","    task.load_dataset(split=split, epoch=1)\n","    itr = load_data_iterator(task, split, 1, config.max_tokens, config.num_workers).next_epoch_itr(shuffle=False)\n","    \n","    idxs = []\n","    hyps = []\n","\n","    model.eval()\n","    progress = tqdm.tqdm(itr, desc=f\"prediction\")\n","    with torch.no_grad():\n","        for i, sample in enumerate(progress):\n","            # validation loss\n","            sample = utils.move_to_cuda(sample, device=device)\n","\n","            # 進行推論\n","            s, h, r = inference_step(sample, model)\n","            \n","            hyps.extend(h)\n","            idxs.extend(list(sample['id']))\n","            \n","    # 根據 preprocess 時的順序排列\n","    hyps = [x for _,x in sorted(zip(idxs,hyps))]\n","    \n","    with open(outfile, \"w\") as f:\n","        for h in hyps:\n","            f.write(h+\"\\n\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U2fCCrN7On_F","colab":{"base_uri":"https://localhost:8080/","height":117,"referenced_widgets":["76c81bffc5564940be82b1a85da5170a","7086b2d44d3e408bbb3527d51447721a","836ff4bd26ca4fafac79dc0f25b2fdb5","9a12c310d6a5497bb36e490df94492c6","50410a2540ed4c889b16d5367b0983d9","1ab7bd1180394313a520cc3c47c64f82","9a240c5fbf8441c9a2b97eb4d7490d53","87937cb1115d478b95de892a400dd14f"]},"executionInfo":{"status":"ok","timestamp":1619440293305,"user_tz":-480,"elapsed":1059202,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"9cb538fc-c4b7-44dd-b722-22df26c1a9bb"},"source":["generate_prediction(model, task)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-04-26 12:31:12 | INFO | fairseq.data.data_utils | loaded 4,000 examples from: ./DATA/data-bin/ted2020/test.en-zh.en\n","2021-04-26 12:31:12 | INFO | fairseq.data.data_utils | loaded 4,000 examples from: ./DATA/data-bin/ted2020/test.en-zh.zh\n","2021-04-26 12:31:12 | INFO | fairseq.tasks.translation | ./DATA/data-bin/ted2020 test en-zh 4000 examples\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"76c81bffc5564940be82b1a85da5170a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='prediction', max=17.0, style=ProgressStyle(description_wi…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"D-S742D2On_G","colab":{"base_uri":"https://localhost:8080/","height":165},"executionInfo":{"status":"error","timestamp":1619350785413,"user_tz":-480,"elapsed":51014,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"95aca273-c7d5-4f54-b4e2-d9855514ebb7"},"source":["raise"],"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-78-9c9a2cba73bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"]}]},{"cell_type":"markdown","metadata":{"id":"IXSf8U9YOn_G"},"source":["# Back-translation"]},{"cell_type":"markdown","metadata":{"id":"6U5_HWfyOn_G"},"source":["## 訓練一個反向的翻譯模型"]},{"cell_type":"markdown","metadata":{"id":"ZDVapvBzOn_G"},"source":["1. 將實驗的參數設定表中(config)的source_lang與target_lang互相交換\n","2. 將實驗的參數設定表中(config)的savedir更改(ex. \"./checkpoints/rnn-back\")\n","3. 訓練一個反向模型"]},{"cell_type":"code","metadata":{"id":"QRWRBR_HDT8e"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IPhvy3XHOn_G"},"source":["## 利用反向模型生成額外資料"]},{"cell_type":"markdown","metadata":{"id":"4A4zGJg4On_G"},"source":["### 下載 monolingual data"]},{"cell_type":"code","metadata":{"id":"bTQrH24nOn_H","executionInfo":{"status":"ok","timestamp":1619678028588,"user_tz":-480,"elapsed":906,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}}},"source":["mono_dataset_name = 'mono'"],"execution_count":120,"outputs":[]},{"cell_type":"code","metadata":{"id":"iDqGHNIaOn_H","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619678032630,"user_tz":-480,"elapsed":4712,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"f31aa6f7-33ff-4af4-953c-e3424081d973"},"source":["data_dir = './DATA/rawdata'\n","dataset_name = 'ted2020'\n","mono_prefix = Path(data_dir).absolute() / mono_dataset_name\n","print(mono_prefix)\n","mono_prefix.mkdir(parents=True, exist_ok=True)\n","\n","urls = (\n","    '\"https://onedrive.live.com/download?cid=3E549F3B24B238B4&resid=3E549F3B24B238B4%214986&authkey=AANUKbGfZx0kM80\"',\n","# # If the above links die, use the following instead. \n","#     \"https://www.csie.ntu.edu.tw/~r09922057/ML2021-hw5/ted_zh_corpus.deduped.gz\",\n","# # If the above links die, use the following instead. \n","#     \"https://mega.nz/#!vMNnDShR!4eHDxzlpzIpdpeQTD-htatU_C7QwcBTwGDaSeBqH534\",\n",")\n","file_names = (\n","    'ted_zh_corpus.deduped.gz',\n",")\n","\n","for u, f in zip(urls, file_names):\n","    path = mono_prefix/f\n","    if not path.exists():\n","        if 'mega' in u:\n","            !megadl {u} --path {path}\n","        else:\n","            !wget {u} -O {path}\n","    else:\n","        print(f'{f} is exist, skip downloading')\n","    if path.suffix == \".tgz\":\n","        !tar -xvf {path} -C {prefix}\n","    elif path.suffix == \".zip\":\n","        !unzip -o {path} -d {prefix}\n","    elif path.suffix == \".gz\":\n","        !gzip -fkd {path}"],"execution_count":121,"outputs":[{"output_type":"stream","text":["/content/DATA/rawdata/mono\n","--2021-04-29 06:33:48--  https://onedrive.live.com/download?cid=3E549F3B24B238B4&resid=3E549F3B24B238B4%214986&authkey=AANUKbGfZx0kM80\n","Resolving onedrive.live.com (onedrive.live.com)... 13.107.43.13\n","Connecting to onedrive.live.com (onedrive.live.com)|13.107.43.13|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://zla8og.dm.files.1drv.com/y4mWCSjPNqYwYh_ii5rHFO09kOuOlHk_8zuJZv6_hfzWkkUFZvJqaZlm3Ypm2Aehk1jwTshYXh4-JcZiXN_RgU2_4B_KW66IP_s1yDO-U84yOyWqfVV0d_CuqM8dkFWRyaOa6DAF97vi66vcLXvx_HcZTWf7s14yd95RTol0C45nulG-USQMsQEblqcIW3Gv0TRJJI6uSXqgXxk99maiuZiuQ/ted_zh_corpus.deduped.gz?download&psid=1 [following]\n","--2021-04-29 06:33:48--  https://zla8og.dm.files.1drv.com/y4mWCSjPNqYwYh_ii5rHFO09kOuOlHk_8zuJZv6_hfzWkkUFZvJqaZlm3Ypm2Aehk1jwTshYXh4-JcZiXN_RgU2_4B_KW66IP_s1yDO-U84yOyWqfVV0d_CuqM8dkFWRyaOa6DAF97vi66vcLXvx_HcZTWf7s14yd95RTol0C45nulG-USQMsQEblqcIW3Gv0TRJJI6uSXqgXxk99maiuZiuQ/ted_zh_corpus.deduped.gz?download&psid=1\n","Resolving zla8og.dm.files.1drv.com (zla8og.dm.files.1drv.com)... 13.107.43.12\n","Connecting to zla8og.dm.files.1drv.com (zla8og.dm.files.1drv.com)|13.107.43.12|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 21709855 (21M) [application/x-gzip]\n","Saving to: ‘/content/DATA/rawdata/mono/ted_zh_corpus.deduped.gz’\n","\n","/content/DATA/rawda 100%[===================>]  20.70M  16.1MB/s    in 1.3s    \n","\n","2021-04-29 06:33:50 (16.1 MB/s) - ‘/content/DATA/rawdata/mono/ted_zh_corpus.deduped.gz’ saved [21709855/21709855]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Hnwxh47POn_H"},"source":["### TODO: 清理資料集\n","\n","1. 將太長、太短的句子移除\n","2. 統一標點符號\n","\n","hint: 可以使用clean_s()來協助"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BiRPWYth2PkQ","executionInfo":{"status":"ok","timestamp":1619678032631,"user_tz":-480,"elapsed":2941,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"a17be228-815b-43c9-98bf-7be1f8f973c0"},"source":["!cp /content/DATA/rawdata/mono/ted_zh_corpus.deduped /content/DATA/rawdata/mono/ted_zh_corpus.deduped.zh\n","src_lang = 'zh'\n","tgt_lang = 'en'\n","mdata_prefix = f'{mono_prefix}/ted_zh_corpus.deduped'\n","\n","\n","!head {mdata_prefix} -n 5"],"execution_count":122,"outputs":[{"output_type":"stream","text":["在 16 世紀中葉 意大利人被一種男歌手迷住了 那種男歌手的音域廣闊，包含的音高 先前是一般成年男性不可能達到的\n","但是，這天賦有一個很高的代價\n","要防止他們變聲 這些歌手在青春期前被閹割 來停止荷爾蒙的變化， 以免他們的聲線變低沉\n","被稱為「閹伶」，他們輕輕的、 天使般的聲音在整個歐洲很有名 直到這個殘酷的程序， 在 19 世紀被禁止\n","雖然阻止聲帶的成長， 可以產生一個非凡廣闊的音域 但自然發展的聲音， 已經具有極多的可能性\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J4oPNouVslpD","executionInfo":{"status":"ok","timestamp":1619678036115,"user_tz":-480,"elapsed":920,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}}},"source":["with open('/content/DATA/rawdata/mono/ted_zh_corpus.deduped.zh', 'r') as f:\n","  with open('/content/DATA/rawdata/mono/ted_zh_corpus.deduped.en', 'w') as en:\n","    for i in f:\n","      en.write('。\\n')"],"execution_count":123,"outputs":[]},{"cell_type":"code","metadata":{"id":"PNUmt0DpOn_H","executionInfo":{"status":"ok","timestamp":1619678057402,"user_tz":-480,"elapsed":22014,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}}},"source":["import re\n","\n","def strQ2B(ustring):\n","    \"\"\"把字串全形轉半形\"\"\"\n","    # 參考來源:https://ithelp.ithome.com.tw/articles/10233122\n","    ss = []\n","    for s in ustring:\n","        rstring = \"\"\n","        for uchar in s:\n","            inside_code = ord(uchar)\n","            if inside_code == 12288:  # 全形空格直接轉換\n","                inside_code = 32\n","            elif (inside_code >= 65281 and inside_code <= 65374):  # 全形字元（除空格）根據關係轉化\n","                inside_code -= 65248\n","            rstring += chr(inside_code)\n","        ss.append(rstring)\n","    return ''.join(ss)\n","                \n","def clean_s(s, lang):\n","    if lang == 'en':\n","        s = re.sub(r\"\\([^()]*\\)\", \"\", s) # remove ([text])\n","        s = s.replace('-', '') # remove '-'\n","        s = re.sub('([.,;!?()\\\"])', r' \\1 ', s) # keep punctuation\n","    elif lang == 'zh':\n","        s = strQ2B(s) # Q2B\n","        s = re.sub(r\"\\([^()]*\\)\", \"\", s) # remove ([text])\n","        s = s.replace(' ', '')\n","        s = s.replace('—', '')\n","        s = s.replace('“', '\"')\n","        s = s.replace('”', '\"')\n","        s = s.replace('_', '')\n","        s = re.sub('([。,;!?()\\\"~「」])', r' \\1 ', s) # keep punctuation\n","    s = ' '.join(s.strip().split())\n","    return s\n","\n","def len_s(s, lang):\n","    if lang == 'zh':\n","        return len(s)\n","    return len(s.split())\n","\n","def clean_corpus(prefix, l1, l2, ratio=9, max_len=1000, min_len=1):\n","    if Path(f'{prefix}.clean.{l1}').exists() and Path(f'{prefix}.clean.{l2}').exists():\n","        print(f'{prefix}.clean.{l1} & {l2} exists. skipping clean.')\n","        return\n","    with open(f'{prefix}.{l1}', 'r') as l1_in_f:\n","        with open(f'{prefix}.{l2}', 'r') as l2_in_f:\n","            with open(f'{prefix}.clean.{l1}', 'w') as l1_out_f:\n","                with open(f'{prefix}.clean.{l2}', 'w') as l2_out_f:\n","                    for s1 in l1_in_f:\n","                        s1 = s1.strip()\n","                        s2 = l2_in_f.readline().strip()\n","                        s1 = clean_s(s1, l1)\n","                        s2 = clean_s(s2, l2)\n","                        s1_len = len_s(s1, l1)\n","                        s2_len = len_s(s2, l2)\n","                        if min_len > 0: # remove short sentence\n","                            if s1_len < min_len or s2_len < min_len:\n","                                continue\n","                        if max_len > 0: # remove long sentence\n","                            if s1_len > max_len or s2_len > max_len:\n","                                continue\n","                        if ratio > 0: # remove by ratio of length\n","                            if s1_len/s2_len > ratio or s2_len/s1_len > ratio:\n","                                continue\n","                        print(s1, file=l1_out_f)\n","                        print(s2, file=l2_out_f)\n","\n","clean_corpus(mdata_prefix, src_lang, tgt_lang, ratio=-1, min_len=-1, max_len=-1)"],"execution_count":124,"outputs":[]},{"cell_type":"code","metadata":{"id":"taJSV5Rg2TRg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619678057403,"user_tz":-480,"elapsed":20833,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"3e630795-79d2-48b6-edf5-009c6731302d"},"source":["!head {mdata_prefix+'.clean.'+src_lang} -n 5\n","!head {mdata_prefix+'.clean.'+tgt_lang} -n 5"],"execution_count":125,"outputs":[{"output_type":"stream","text":["在16世紀中葉意大利人被一種男歌手迷住了那種男歌手的音域廣闊 , 包含的音高先前是一般成年男性不可能達到的\n","但是 , 這天賦有一個很高的代價\n","要防止他們變聲這些歌手在青春期前被閹割來停止荷爾蒙的變化 , 以免他們的聲線變低沉\n","被稱為 「 閹伶 」 , 他們輕輕的、天使般的聲音在整個歐洲很有名直到這個殘酷的程序 , 在19世紀被禁止\n","雖然阻止聲帶的成長 , 可以產生一個非凡廣闊的音域但自然發展的聲音 , 已經具有極多的可能性\n","。\n","。\n","。\n","。\n","。\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WcaUvbadOn_H"},"source":["### TODO: Subword Units\n","\n","用反向模型的 spm model 將資料切成 subword units\n","\n","hint: spm model 的路徑為 DATA/raw-data/\\[dataset\\]/spm\\[vocab_num\\].model"]},{"cell_type":"code","metadata":{"id":"TjEfQIlvOn_I","executionInfo":{"status":"ok","timestamp":1619678074562,"user_tz":-480,"elapsed":14580,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}}},"source":["# spm model /Data/\n","spm_model = spm.SentencePieceProcessor(model_file=str(prefix/f'spm{vocab_size}.model'))\n","in_tag = {\n","\n","    'mono': 'ted_zh_corpus.deduped.clean',\n","}\n","for split in ['mono']:\n","    for lang in [src_lang, tgt_lang]:\n","        out_path = mono_prefix/f'{split}.{lang}'\n","        if out_path.exists():\n","            print(f\"{out_path} exists. skipping spm_encode.\")\n","        else:\n","            with open(mono_prefix/f'{split}.{lang}', 'w') as out_f:\n","                with open(mono_prefix/f'{in_tag[split]}.{lang}', 'r') as in_f:\n","                    for line in in_f:\n","                        line = line.strip()\n","                        tok = spm_model.encode(line, out_type=str)\n","                        print(' '.join(tok), file=out_f)"],"execution_count":126,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3boWve8hDAH7","executionInfo":{"status":"ok","timestamp":1619678074955,"user_tz":-480,"elapsed":7958,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"bde93b2c-c442-4c93-9cfa-c807b2a2d610"},"source":["!head {'/content/DATA/rawdata/mono/mono.en'} -n 5\n","!head {'/content/DATA/rawdata/mono/mono.zh'} -n 5\n","!cp /content/DATA/rawdata/mono/mono.zh /content/DATA/rawdata/mono/mono.clean.zh"],"execution_count":127,"outputs":[{"output_type":"stream","text":["▁ 。\n","▁ 。\n","▁ 。\n","▁ 。\n","▁ 。\n","▁在 16 世紀 中 葉 意 大 利 人 被 一種 男 歌 手 迷 住 了 那種 男 歌 手 的 音 域 廣 闊 ▁, ▁ 包 含 的 音 高 先 前 是 一般 成 年 男性 不可能 達到 的\n","▁但是 ▁, ▁這 天 賦 有一個 很 高 的 代 價\n","▁ 要 防 止 他們 變 聲 這些 歌 手 在 青 春 期 前 被 閹 割 來 停 止 荷 爾 蒙 的 變化 ▁, ▁以 免 他們的 聲 線 變 低 沉\n","▁ 被 稱為 ▁「 ▁ 閹 伶 ▁」 ▁, ▁他們 輕 輕 的 、 天 使 般 的聲音 在 整個 歐 洲 很 有 名 直 到 這個 殘 酷 的 程 序 ▁, ▁在 19 世紀 被 禁 止\n","▁雖然 阻 止 聲 帶 的 成長 ▁, ▁ 可以 產生 一個 非 凡 廣 闊 的 音 域 但 自然 發展 的聲音 ▁, ▁ 已經 具有 極 多 的 可能 性\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3f7Oi5qXOn_I"},"source":["### Binarize\n","\n","使用fairseq將資料轉為binary"]},{"cell_type":"code","metadata":{"id":"hFVqcbYcOn_I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619678153016,"user_tz":-480,"elapsed":69309,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"30c7435e-efd5-4a5b-fbf7-650908c259c7"},"source":["binpath = Path('./DATA/data-bin', mono_dataset_name)\n","src_dict_file = './DATA/data-bin/ted2020/dict.en.txt'\n","tgt_dict_file = src_dict_file\n","monopref = str(mono_prefix/\"mono\") # whatever filepath you get after applying subword tokenization\n","if binpath.exists():\n","    print(binpath, \"exists, will not overwrite!\")\n","else:\n","    !python -m fairseq_cli.preprocess\\\n","        --source-lang 'zh'\\\n","        --target-lang 'en'\\\n","        --trainpref {monopref}\\\n","        --destdir {binpath}\\\n","        --srcdict {src_dict_file}\\\n","        --tgtdict {tgt_dict_file}\\\n","        --workers 2"],"execution_count":128,"outputs":[{"output_type":"stream","text":["2021-04-29 06:34:45 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='DATA/data-bin/mono', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='zh', srcdict='./DATA/data-bin/ted2020/dict.en.txt', suppress_crashes=False, target_lang='en', task='translation', tensorboard_logdir=None, testpref=None, tgtdict='./DATA/data-bin/ted2020/dict.en.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/content/DATA/rawdata/mono/mono', user_dir=None, validpref=None, wandb_project=None, workers=2)\n","2021-04-29 06:34:45 | INFO | fairseq_cli.preprocess | [zh] Dictionary: 8000 types\n","2021-04-29 06:35:37 | INFO | fairseq_cli.preprocess | [zh] /content/DATA/rawdata/mono/mono.zh: 782527 sents, 14416029 tokens, 0.00223% replaced by <unk>\n","2021-04-29 06:35:37 | INFO | fairseq_cli.preprocess | [en] Dictionary: 8000 types\n","2021-04-29 06:35:51 | INFO | fairseq_cli.preprocess | [en] /content/DATA/rawdata/mono/mono.en: 782527 sents, 2347581 tokens, 0.0% replaced by <unk>\n","2021-04-29 06:35:51 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to DATA/data-bin/mono\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ezNQeAaQOn_I"},"source":["### TODO: 生成反向翻譯資料\n","\n","將 binarized data 加入原本的資料夾中並用一個 split_name 取名\n","\n","ex. ./DATA/data-bin/ted2020/\\[split_name\\].zh-en.\\[\"en\", \"zh\"\\].\\[\"bin\", \"idx\"\\]\n","\n","便可以使用 generate_prediction(model, task, split=\"split_name\")來產生翻譯資料"]},{"cell_type":"code","metadata":{"id":"S2N3HvjHOn_I","executionInfo":{"status":"ok","timestamp":1619678155402,"user_tz":-480,"elapsed":2356,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}}},"source":["# 將 binarized data 加入原本的資料夾中並用一個 split_name 取名\n","# ex. ./DATA/data-bin/ted2020/\\[split_name\\].zh-en.\\[\"en\", \"zh\"\\].\\[\"bin\", \"idx\"\\]\n","!cp ./DATA/data-bin/mono/train.zh-en.zh.bin ./DATA/data-bin/ted2020/mono.zh-en.zh.bin\n","!cp ./DATA/data-bin/mono/train.zh-en.zh.idx ./DATA/data-bin/ted2020/mono.zh-en.zh.idx\n","!cp ./DATA/data-bin/mono/train.zh-en.en.bin ./DATA/data-bin/ted2020/mono.zh-en.en.bin\n","!cp ./DATA/data-bin/mono/train.zh-en.en.idx ./DATA/data-bin/ted2020/mono.zh-en.en.idx"],"execution_count":129,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t98ABd7kNyy6","executionInfo":{"status":"ok","timestamp":1619678155403,"user_tz":-480,"elapsed":2330,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"1ad69d0b-25b3-4430-f3aa-5f603470ebae"},"source":["try_load_checkpoint(model, name=\"avg_last_5_checkpoint.pt\")"],"execution_count":130,"outputs":[{"output_type":"stream","text":["2021-04-29 06:35:54 | INFO | hw5.seq2seq | loaded checkpoint /content/backward/avg_last_5_checkpoint.pt: step=unknown loss=2.59552001953125 bleu=20.454427985585347\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Dh6Rx97_OGeG","executionInfo":{"status":"ok","timestamp":1619678175590,"user_tz":-480,"elapsed":1386,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}}},"source":["# !cp /content/DATA/rawdata/ted2020/spm8000.model /content/drive/MyDrive/bt\n","# !cp /content/DATA/rawdata/ted2020/spm8000.vocab /content/drive/MyDrive/bt"],"execution_count":131,"outputs":[]},{"cell_type":"code","metadata":{"id":"WaybwcrhOn_J","colab":{"base_uri":"https://localhost:8080/","height":117,"referenced_widgets":["b3b370b5163147648e81932b204e2c81","0944f60aff934b9586d9dcbd58e911d9","51f71ce7426744979ab05bcf81753b01","8a844929f7e94b0d84830c7cc09e521c","3b10cf39550542fbbae24b27abc8990a","77d4ff7050e64d219ada3b8f2bd25818","f94118b291e64fbbad603c36ec1cdc6f","f668ca1b567d4dc38986f21a3ba75f90"]},"executionInfo":{"status":"ok","timestamp":1619681992699,"user_tz":-480,"elapsed":1607053,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"e16b3bc4-fe27-4854-9d3f-7bcbdc58c13b"},"source":["# hint: 用反向模型在 split='mono' 上進行預測，生成 prediction_file\n","# generate_prediction( ... ,split=... ,outfile=... )\n","def generate_prediction(model, task, split=\"mono\", outfile=\"/content/monoprediction.txt\"):    \n","    task.load_dataset(split=split, epoch=1)\n","    itr = load_data_iterator(task, split, 1, config.max_tokens, config.num_workers).next_epoch_itr(shuffle=False)\n","    \n","    idxs = []\n","    hyps = []\n","\n","    model.eval()\n","    progress = tqdm.tqdm(itr, desc=f\"prediction\")\n","    with torch.no_grad():\n","        for i, sample in enumerate(progress):\n","            # validation loss\n","            sample = utils.move_to_cuda(sample, device=device)\n","\n","            # 進行推論\n","            s, h, r = inference_step(sample, model)\n","            \n","            hyps.extend(h)\n","            idxs.extend(list(sample['id']))\n","            \n","    # 根據 preprocess 時的順序排列\n","    hyps = [x for _,x in sorted(zip(idxs,hyps))]\n","    \n","    with open(outfile, \"w\") as f:\n","        for h in hyps:\n","            f.write(h+\"\\n\")\n","generate_prediction(model, task)"],"execution_count":132,"outputs":[{"output_type":"stream","text":["2021-04-29 06:37:03 | INFO | fairseq.data.data_utils | loaded 782,527 examples from: ./DATA/data-bin/ted2020/mono.zh-en.zh\n","2021-04-29 06:37:03 | INFO | fairseq.data.data_utils | loaded 782,527 examples from: ./DATA/data-bin/ted2020/mono.zh-en.en\n","2021-04-29 06:37:03 | INFO | fairseq.tasks.translation | ./DATA/data-bin/ted2020 mono zh-en 782527 examples\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b3b370b5163147648e81932b204e2c81","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='prediction', max=1766.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zqy_CDaCOn_J"},"source":["### TODO: 產生新的dataset\n","\n","1. 將翻譯出來的資料與原先的訓練資料結合\n","2. 使用之前的spm model切出成Subword Units\n","3. 重新使用fairseq將資料轉為binary"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N6fJc5oEhmnn","executionInfo":{"status":"ok","timestamp":1619681996009,"user_tz":-480,"elapsed":1366,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"2fb0ea76-16ba-452e-e990-bbfb7787ea8b"},"source":["with open('/content/monoprediction.txt', 'r') as mono_en:\n","  print(mono_en.readline())"],"execution_count":133,"outputs":[{"output_type":"stream","text":["in the mid16th century , italians were fascinated by a male singer , a wide range of sounds , including the pitches that were previously impossible for adult men .\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zzv4NUL3qmdu","executionInfo":{"status":"ok","timestamp":1619682161623,"user_tz":-480,"elapsed":13866,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}}},"source":["# 合併剛剛生成的 prediction_file (.en) 以及中文 mono.zh (.zh)\n","# \n","# hint: 在此用剛剛的 spm model 對 prediction_file 進行切斷詞\n","# spm_model.encode(line, out_type=str)\n","# output: ./DATA/rawdata/mono/mono.tok.en & mono.tok.zh\n","spm_model = spm.SentencePieceProcessor(model_file=str(prefix/f'spm{vocab_size}.model'))\n","with open('/content/monoprediction.txt', 'r') as r:\n","  with open('/content/DATA/rawdata/mono/mono.clean.en', 'w') as w:\n","    for i in r:\n","      i = i.strip()\n","      token = spm_model.encode(i, out_type=str)\n","      print(' '.join(token), file=w)"],"execution_count":134,"outputs":[]},{"cell_type":"code","metadata":{"id":"sfpuOQvhOn_J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619682263392,"user_tz":-480,"elapsed":99463,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"61c14537-6af3-49b4-9520-745aefff32df"},"source":["\n","# hint: 在此用 fairseq 把這些檔案再 binarize\n","binpath = Path('./DATA/data-bin/synthetic')\n","src_dict_file = './DATA/data-bin/ted2020/dict.en.txt'\n","tgt_dict_file = src_dict_file\n","monopref = '/content/DATA/rawdata/mono/mono.clean' # or whatever path after applying subword tokenization, w/o the suffix (.zh/.en)\n","if binpath.exists():\n","    print(binpath, \"exists, will not overwrite!\")\n","else:\n","    !python -m fairseq_cli.preprocess\\\n","        --source-lang 'zh'\\\n","        --target-lang 'en'\\\n","        --trainpref {monopref}\\\n","        --destdir {binpath}\\\n","        --srcdict {src_dict_file}\\\n","        --tgtdict {tgt_dict_file}\\\n","        --workers 2"],"execution_count":135,"outputs":[{"output_type":"stream","text":["2021-04-29 07:42:45 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='DATA/data-bin/synthetic', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='zh', srcdict='./DATA/data-bin/ted2020/dict.en.txt', suppress_crashes=False, target_lang='en', task='translation', tensorboard_logdir=None, testpref=None, tgtdict='./DATA/data-bin/ted2020/dict.en.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='/content/DATA/rawdata/mono/mono.clean', user_dir=None, validpref=None, wandb_project=None, workers=2)\n","2021-04-29 07:42:45 | INFO | fairseq_cli.preprocess | [zh] Dictionary: 8000 types\n","2021-04-29 07:43:33 | INFO | fairseq_cli.preprocess | [zh] /content/DATA/rawdata/mono/mono.clean.zh: 782527 sents, 14416029 tokens, 0.00223% replaced by <unk>\n","2021-04-29 07:43:33 | INFO | fairseq_cli.preprocess | [en] Dictionary: 8000 types\n","2021-04-29 07:44:21 | INFO | fairseq_cli.preprocess | [en] /content/DATA/rawdata/mono/mono.clean.en: 782527 sents, 17602059 tokens, 0.0% replaced by <unk>\n","2021-04-29 07:44:21 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to DATA/data-bin/synthetic\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HdWRBPO2On_J","executionInfo":{"status":"ok","timestamp":1619682271210,"user_tz":-480,"elapsed":1647,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}}},"source":["# 這裡用剛剛準備的檔案合併原先 ted2020 來生成最終 back-translation 的資料\n","!cp -r ./DATA/data-bin/ted2020/ ./DATA/data-bin/ted2020_with_mono/\n","\n","!cp ./DATA/data-bin/synthetic/train.zh-en.zh.bin ./DATA/data-bin/ted2020_with_mono/train1.en-zh.zh.bin\n","!cp ./DATA/data-bin/synthetic/train.zh-en.zh.idx ./DATA/data-bin/ted2020_with_mono/train1.en-zh.zh.idx\n","!cp ./DATA/data-bin/synthetic/train.zh-en.en.bin ./DATA/data-bin/ted2020_with_mono/train1.en-zh.en.bin\n","!cp ./DATA/data-bin/synthetic/train.zh-en.en.idx ./DATA/data-bin/ted2020_with_mono/train1.en-zh.en.idx"],"execution_count":137,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TSos26jqOn_K"},"source":["### TODO: 重新訓練\n","\n","當已經產生新的資料集\n","\n","1. 將實驗的參數設定表(config)中的datadir改為新的資料集(\"./DATA/data-bin/ted2020_with_mono\")\n","2. 將實驗的參數設定表(config)中的source_lang與target_lang設定還原(\"en\", \"zh\")\n","3. 將實驗的參數設定表(config)中的savedir更改(ex. \"./checkpoints/rnn-bt\")\n","4. 重新訓練"]},{"cell_type":"code","metadata":{"id":"tkrX1CDFHEMb","executionInfo":{"status":"ok","timestamp":1619705507389,"user_tz":-480,"elapsed":850,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}}},"source":["config = Namespace(\n","    datadir = \"./DATA/data-bin/ted2020_with_mono\",\n","    savedir = \"/content/forward/\",\n","    source_lang = \"en\",\n","    target_lang = \"zh\",\n","    \n","    # cpu threads when fetching & processing data.\n","    num_workers=2,  \n","    # batch size in terms of tokens. gradient accumulation increases the effective batchsize.\n","    max_tokens=8192,\n","    accum_steps=2,\n","    \n","    # the lr s calculated from Noam lr scheduler. you can tune the maximum lr by this factor.\n","    lr_factor=2.,\n","    lr_warmup=4000,\n","    \n","    # clipping gradient norm helps alleviate gradient exploding\n","    clip_norm=1.0,\n","    \n","    # maximum epochs for training\n","    max_epoch=40,\n","    start_epoch=1,\n","    \n","    # beam size for beam search\n","    beam=5, \n","    # generate sequences of maximum length ax + b, where x is the source length\n","    max_len_a=1.2, \n","    max_len_b=10,\n","    # when decoding, post process sentence by removing sentencepiece symbols.\n","    post_process = \"sentencepiece\",\n","    \n","    # checkpoints\n","    keep_last_epochs=5,\n","    resume=None, # if resume from checkpoint name (under config.savedir)\n","    \n","    # logging\n","    use_wandb=False,\n",")"],"execution_count":204,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RoM-NOXiHEw_","executionInfo":{"status":"ok","timestamp":1619705508936,"user_tz":-480,"elapsed":876,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"85f1e59f-d467-4168-fd4d-2097fbb215f3"},"source":["logging.basicConfig(\n","    format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n","    datefmt=\"%Y-%m-%d %H:%M:%S\",\n","    level=\"INFO\", # \"DEBUG\" \"WARNING\" \"ERROR\"\n","    stream=sys.stdout,\n",")\n","proj = \"hw5.seq2seq\"\n","logger = logging.getLogger(proj)\n","if config.use_wandb:\n","    import wandb\n","    wandb.init(project=proj, name=Path(config.savedir).stem, config=config)\n","cuda_env = utils.CudaEnvironment()\n","utils.CudaEnvironment.pretty_print_cuda_env_list([cuda_env])\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","from fairseq.tasks.translation import TranslationConfig, TranslationTask\n","\n","## setup task\n","task_cfg = TranslationConfig(\n","    data=config.datadir,\n","    source_lang=config.source_lang,\n","    target_lang=config.target_lang,\n","    train_subset=\"train\",\n","    required_seq_len_multiple=8,\n","    dataset_impl=\"mmap\",\n","    upsample_primary=1,\n",")\n","task = TranslationTask.setup_task(task_cfg)"],"execution_count":205,"outputs":[{"output_type":"stream","text":["2021-04-29 14:11:47 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n","2021-04-29 14:11:47 | INFO | fairseq.utils | rank   0: capabilities =  7.0  ; total memory = 15.782 GB ; name = Tesla V100-SXM2-16GB                    \n","2021-04-29 14:11:47 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n","2021-04-29 14:11:47 | INFO | fairseq.tasks.translation | [en] dictionary: 8000 types\n","2021-04-29 14:11:47 | INFO | fairseq.tasks.translation | [zh] dictionary: 8000 types\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lSR6gFGnHEzg","executionInfo":{"status":"ok","timestamp":1619705509403,"user_tz":-480,"elapsed":796,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"cb4e4688-6236-46db-e7d4-9c62b925396f"},"source":["logger.info(\"loading data for epoch 1\")\n","task.load_dataset(split=\"train\", epoch=1, combine=True) # combine if you have back-translation data.\n","task.load_dataset(split=\"valid\", epoch=1)"],"execution_count":206,"outputs":[{"output_type":"stream","text":["2021-04-29 14:11:48 | INFO | hw5.seq2seq | loading data for epoch 1\n","2021-04-29 14:11:48 | INFO | fairseq.data.data_utils | loaded 390,041 examples from: ./DATA/data-bin/ted2020_with_mono/train.zh-en.en\n","2021-04-29 14:11:48 | INFO | fairseq.data.data_utils | loaded 390,041 examples from: ./DATA/data-bin/ted2020_with_mono/train.zh-en.zh\n","2021-04-29 14:11:48 | INFO | fairseq.tasks.translation | ./DATA/data-bin/ted2020_with_mono train en-zh 390041 examples\n","2021-04-29 14:11:48 | INFO | fairseq.data.data_utils | loaded 782,527 examples from: ./DATA/data-bin/ted2020_with_mono/train1.en-zh.en\n","2021-04-29 14:11:48 | INFO | fairseq.data.data_utils | loaded 782,527 examples from: ./DATA/data-bin/ted2020_with_mono/train1.en-zh.zh\n","2021-04-29 14:11:48 | INFO | fairseq.tasks.translation | ./DATA/data-bin/ted2020_with_mono train1 en-zh 782527 examples\n","2021-04-29 14:11:48 | INFO | fairseq.data.data_utils | loaded 3,939 examples from: ./DATA/data-bin/ted2020_with_mono/valid.zh-en.en\n","2021-04-29 14:11:48 | INFO | fairseq.data.data_utils | loaded 3,939 examples from: ./DATA/data-bin/ted2020_with_mono/valid.zh-en.zh\n","2021-04-29 14:11:48 | INFO | fairseq.tasks.translation | ./DATA/data-bin/ted2020_with_mono valid en-zh 3939 examples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jbUy4_Jdl0z0","executionInfo":{"status":"ok","timestamp":1619705517762,"user_tz":-480,"elapsed":1428,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}}},"source":["!cp /content/backward/avg_last_5_checkpoint.pt /content/drive/MyDrive/"],"execution_count":207,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["5e3bb939e4ad40788b4604759ef032c7","1806c2bbb3bc4736ab9d87f5edbc42af","bb39fc69c13e4758969f6177b9e49bb9","3ec1b351144f466a92c104c9c3ab8968","b027ad5ace0142dab1db246b734f5e52","3021ece5a59b4f1c89547e74f1522dfe","af45dd2c37304d1f968f3ae1a5508ca4","419a6a6e131e450d9147a7bba761cc1a","56b4a0aa971c4472bc73b309170ec67a","d3b9c14c79b9443da0422eb012990412","e4e132aa18cb468d8b9b6d517653bb05","f853cfeb265d439e86586c64f87036f8","0fd3cb74ad194ad693c41e0850518fd1","a6790f1f742f430487b9dbe5fa1dc62d","1569d0b5632044e68f615a8628e2b61d","8e9eba823f6e43b1ab0b49440948455a","5955642a9671400590eeaab8c3da248e","38926a9afd60421091d96d0decdd110a","07b4398f088f4181a16685633c44a667","57d2529f77b74010a2d398200741c3c4","d3ba07ca85b24c52b86e3a99bae00a59","026a167097ba4acea537bd167dd4adca","b7dabdf6694744b8932a3d739151ceb9","9cb32eb777624089bba0dedfec157646","30dd49d583b14228857e98f92b098d6a","0073f3ba742544f9bf156c4aed0d4780","488b3374137b4682b05b1a76c21c091e","b55d8985907a413b8c24cc984d579ba6","8866c057eb3c406bae059545c726923a","94c6d1f804c948fa95277045103e0101","04887ba8df2b4e9088651865a53fc5b1","2e65a887b407438db71c14dacf76586c","e84084fe97c14fd3b3a791f063780eec","e2b9f942b2e34fca819c57622b0afe76","bab4ed991328437dbd9be356124acd49","ff964ea23daa4ff5b94998e31cfe3b24","d256db765fb746e5ac5af30a7b497a2a","d5c26abb92b54c7db1671e8eea4437e3","71fb6ed333d94c57afdc8a6d4439d4bf","11ecc6bc285f491a918483187046fd2b","77a67878de16477880a16272855855c7","f81163f138da47bda444260f38153d0e","5e66b03cd7b3466a9785fa9f473175c4","6948b9c0e90b4024a71d1d26e189b605","e35303b6f5b54abaabb9239ebb92a828","095cdc5a695149f89251ac99a3deeb27","af499e7f0f0e4ff9ac16dc11a736653e","02887806d174445583de5c3ee39f65b2","22cc82b8b3a54696ac74226aa29641b4","b0644dc90ef64daa98f37085ff42904d","93d9645b3bb94af7bffa6b464a7a042e","df523cd6159042319d4f739f2e3e55c0","74d5f470a43d4ac59c38c8713a517c93","fea39a9c518047f5a485012ff5480b4d","a4cbd89a88674bdbb0fa30b518d8e121","8e57947cdd1e48529814d9b62ccf721b","cba225d30aee4377a380cf40cd91ab8c","0f2c7e10f0404ffba85fea9e5cc9cb2c","73ef102f0a7d4ee395bd65b5895f4def","566aac4ba4cc4dbb83f58cb2e22233d7","728ca246aeed4905af7ca9aed6d65271","5b9cf8d30ac046d1be561b4cef3e1e2a","44895d63a68343ecacdf8722b6dcc059","c2433be36fea48f394a107278855b585","ae50643713864fd6980006feff7ed29c","f54a1b9084d04d8b951090adc3243e79","c3d1fb5a8c0d4dbe9961cf18f70facb2","08ed9c0cca2844e28ca099b33870b50a","147046e0f2c64227a553482909bbe25c","7e718f7b74584407813ffef9523db031","51cf2227c2bd498ead9dc8ff2806f0eb","1c8a3d20148b482f91c8f44b20f44463"]},"id":"gUwFl3WKHE2G","executionInfo":{"status":"error","timestamp":1619708740832,"user_tz":-480,"elapsed":3221991,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"0b2a5e91-f85f-4e57-88df-b4db0605dc3c"},"source":["bleu_list = []\n","epoch_itr = load_data_iterator(task, \"train\", config.start_epoch, config.max_tokens, config.num_workers)\n","try_load_checkpoint(model, optimizer, name=config.resume)\n","while epoch_itr.next_epoch_idx <= config.max_epoch:\n","    # train for one epoch\n","    train_one_epoch(epoch_itr, model, task, criterion, optimizer, config.accum_steps)\n","    stats = validate_and_save(model, task, criterion, optimizer, epoch=epoch_itr.epoch)\n","    logger.info(\"end of epoch {}\".format(epoch_itr.epoch))    \n","    epoch_itr = load_data_iterator(task, \"train\", epoch_itr.next_epoch_idx, config.max_tokens, config.num_workers)"],"execution_count":208,"outputs":[{"output_type":"stream","text":["2021-04-29 14:11:58 | WARNING | fairseq.tasks.fairseq_task | 1 samples have invalid sizes and will be skipped, max_positions=(1024, 1024), first few sample ids=[326674]\n","2021-04-29 14:12:01 | INFO | hw5.seq2seq | loaded checkpoint /content/forward/checkpoint_last.pt: step=85322 loss=2.9510977268218994 bleu=29.320080433504394\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5e3bb939e4ad40788b4604759ef032c7","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='train epoch 1', max=1913.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["2021-04-29 14:24:21 | INFO | hw5.seq2seq | training loss: 2.2903\n","2021-04-29 14:24:21 | INFO | hw5.seq2seq | begin validation\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"56b4a0aa971c4472bc73b309170ec67a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='validation', max=23.0, style=ProgressStyle(description_wi…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["2021-04-29 14:24:51 | INFO | hw5.seq2seq | example source: this is actually the cover story of the 2016 january issue of national geographic .\n","2021-04-29 14:24:51 | INFO | hw5.seq2seq | example hypothesis: 這其實是2016年一月國家地理雜誌的封面故事 。\n","2021-04-29 14:24:51 | INFO | hw5.seq2seq | example reference: 這其實是2016年一月國家地理雜誌的封面故事 。\n","2021-04-29 14:24:51 | INFO | hw5.seq2seq | validation loss:\t2.9453\n","2021-04-29 14:24:51 | INFO | hw5.seq2seq | BLEU = 29.15 60.5/36.3/23.1/15.4 (BP = 0.980 ratio = 0.981 hyp_len = 109646 ref_len = 111811)\n","2021-04-29 14:24:51 | INFO | hw5.seq2seq | saved epoch checkpoint: /content/forward/checkpoint1.pt\n","2021-04-29 14:24:51 | INFO | hw5.seq2seq | end of epoch 1\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5955642a9671400590eeaab8c3da248e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='train epoch 2', max=1913.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["2021-04-29 14:37:14 | INFO | hw5.seq2seq | training loss: 2.2827\n","2021-04-29 14:37:14 | INFO | hw5.seq2seq | begin validation\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"30dd49d583b14228857e98f92b098d6a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='validation', max=23.0, style=ProgressStyle(description_wi…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["2021-04-29 14:37:44 | INFO | hw5.seq2seq | example source: from the moment that our ancestors , perhaps two and a half million years ago or so , began imitating , there was a new copying process .\n","2021-04-29 14:37:44 | INFO | hw5.seq2seq | example hypothesis: 從我們祖先的那一刻開始大約兩百五十萬年前開始模仿有一種新的複製過程\n","2021-04-29 14:37:44 | INFO | hw5.seq2seq | example reference: 自從我們祖先大約250萬年前 , 開始模仿 , 就有一個新的複製過程 。\n","2021-04-29 14:37:44 | INFO | hw5.seq2seq | validation loss:\t2.9532\n","2021-04-29 14:37:44 | INFO | hw5.seq2seq | BLEU = 29.22 60.4/36.3/23.0/15.4 (BP = 0.984 ratio = 0.985 hyp_len = 110078 ref_len = 111811)\n","2021-04-29 14:37:44 | INFO | hw5.seq2seq | saved epoch checkpoint: /content/forward/checkpoint2.pt\n","2021-04-29 14:37:44 | INFO | hw5.seq2seq | end of epoch 2\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e84084fe97c14fd3b3a791f063780eec","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='train epoch 3', max=1913.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["2021-04-29 14:50:04 | INFO | hw5.seq2seq | training loss: 2.2746\n","2021-04-29 14:50:04 | INFO | hw5.seq2seq | begin validation\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"77a67878de16477880a16272855855c7","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='validation', max=23.0, style=ProgressStyle(description_wi…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["2021-04-29 14:50:33 | INFO | hw5.seq2seq | example source: who decides whether to release a gene drive that can fly ?\n","2021-04-29 14:50:33 | INFO | hw5.seq2seq | example hypothesis: 誰決定是否要釋放能飛的基因驅動技術 ?\n","2021-04-29 14:50:33 | INFO | hw5.seq2seq | example reference: 誰可以決定是否要釋放一個會飛的基因驅動呢 ?\n","2021-04-29 14:50:33 | INFO | hw5.seq2seq | validation loss:\t2.9509\n","2021-04-29 14:50:33 | INFO | hw5.seq2seq | BLEU = 29.29 60.0/36.0/22.8/15.2 (BP = 0.995 ratio = 0.995 hyp_len = 111269 ref_len = 111811)\n","2021-04-29 14:50:33 | INFO | hw5.seq2seq | saved epoch checkpoint: /content/forward/checkpoint3.pt\n","2021-04-29 14:50:33 | INFO | hw5.seq2seq | end of epoch 3\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"22cc82b8b3a54696ac74226aa29641b4","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='train epoch 4', max=1913.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["2021-04-29 15:02:48 | INFO | hw5.seq2seq | training loss: 2.2680\n","2021-04-29 15:02:48 | INFO | hw5.seq2seq | begin validation\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cba225d30aee4377a380cf40cd91ab8c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='validation', max=23.0, style=ProgressStyle(description_wi…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["2021-04-29 15:03:16 | INFO | hw5.seq2seq | example source: but because i had no family to inquire about me , they could do anything to me .\n","2021-04-29 15:03:16 | INFO | hw5.seq2seq | example hypothesis: 但因為沒有家人向我要求 , 他們可以為我做任何事 。\n","2021-04-29 15:03:16 | INFO | hw5.seq2seq | example reference: 但就因為我沒有家人關心他們就可以對我為所欲為\n","2021-04-29 15:03:16 | INFO | hw5.seq2seq | validation loss:\t2.9550\n","2021-04-29 15:03:16 | INFO | hw5.seq2seq | BLEU = 28.98 61.0/36.7/23.3/15.6 (BP = 0.965 ratio = 0.966 hyp_len = 107964 ref_len = 111811)\n","2021-04-29 15:03:17 | INFO | hw5.seq2seq | saved epoch checkpoint: /content/forward/checkpoint4.pt\n","2021-04-29 15:03:17 | INFO | hw5.seq2seq | end of epoch 4\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ae50643713864fd6980006feff7ed29c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='train epoch 5', max=1913.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-208-47e7badb2e43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mepoch_itr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_epoch_idx\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# train for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_itr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch_itr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"end of epoch {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_itr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-42-e3d66598e8c4>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(epoch_itr, model, task, criterion, optimizer, accum_steps)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0;31m# emptying the CUDA cache after the first step can reduce the chance of OOM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_to_cuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/memory.py\u001b[0m in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m     \"\"\"\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_emptyCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dfp6_riViAR1","executionInfo":{"status":"ok","timestamp":1619705337628,"user_tz":-480,"elapsed":765,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"eb94d972-d281-4eee-b22f-3fd73eb8e0e2"},"source":["bleu_index = {}\n","bleuscore = []\n","maxscore = []\n","bleu_max5 = []\n","for i in range(len(bleu_list)):\n","  bleu_index[str(i+1)] = bleu_list[i]\n","  bleuscore.append(float(bleu_list[i]))\n","\n","for i in range(5):\n","  maxscore.append(float(bleuscore.pop(bleuscore.index(max(bleuscore)))))\n","for key, value in bleu_index.items():\n","  if (float(value) in maxscore):\n","    bleu_max5.append(key)\n","bleu_max5  "],"execution_count":196,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['20', '23', '27', '28', '29', '30']"]},"metadata":{"tags":[]},"execution_count":196}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_HVofznEsXSp","executionInfo":{"status":"ok","timestamp":1619705350251,"user_tz":-480,"elapsed":800,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"9132712d-7319-4456-843e-40e2657f5052"},"source":["!mkdir /content/max_checkpoint_mono/"],"execution_count":197,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‘/content/max_checkpoint_mono/’: File exists\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xoZF014hiHgi","executionInfo":{"status":"ok","timestamp":1619705357984,"user_tz":-480,"elapsed":6679,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"5044f1c7-b881-459a-ff9b-f04f946f7db7"},"source":["f0= '/content/forward/checkpoint%s.pt'%bleu_max5[0]\n","!$f0 = f0\n","!echo $f0\n","!cp -r $f0 '/content/max_checkpoint_mono/'\n","f1 = '/content/forward/checkpoint%s.pt'%bleu_max5[1]\n","!$f1 = f1\n","!echo $f1\n","!cp -r $f1 '/content/max_checkpoint_mono/'\n","f2 = '/content/forward/checkpoint%s.pt'%bleu_max5[2]\n","!$f2 = f2\n","!echo $f2\n","!cp -r $f2 '/content/max_checkpoint_mono/'\n","f4 = '/content/forward/checkpoint%s.pt'%bleu_max5[4]\n","!$f4 = f4\n","!echo $f4\n","!cp -r $f4 '/content/max_checkpoint_mono/'\n","f3 = '/content/forward/checkpoint%s.pt'%bleu_max5[3]\n","!$f3 = f3\n","!echo $f3\n","!cp -r $f3 '/content/max_checkpoint_mono/'\n","# f5 = '/content/forward/checkpoint%s.pt'%bleu_max5[5]\n","# !$f5 = f5\n","# !echo $f5\n","# !cp -r $f5 '/content/max_checkpoint_mono/'"],"execution_count":198,"outputs":[{"output_type":"stream","text":["/bin/bash: /content/forward/checkpoint20.pt: Permission denied\n","/content/forward/checkpoint20.pt\n","/bin/bash: /content/forward/checkpoint23.pt: Permission denied\n","/content/forward/checkpoint23.pt\n","/bin/bash: /content/forward/checkpoint27.pt: Permission denied\n","/content/forward/checkpoint27.pt\n","/bin/bash: /content/forward/checkpoint29.pt: Permission denied\n","/content/forward/checkpoint29.pt\n","/bin/bash: /content/forward/checkpoint28.pt: Permission denied\n","/content/forward/checkpoint28.pt\n","/bin/bash: /content/forward/checkpoint30.pt: Permission denied\n","/content/forward/checkpoint30.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EDK4R2nqHE4j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619705368158,"user_tz":-480,"elapsed":4036,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"b487658f-79bb-489c-8b8b-4f4132d48ce5"},"source":["# 把幾個 checkpoint 平均起來可以達到 ensemble 的效果\n","checkdir='/content/max_checkpoint_mono/'\n","\n","!python ./fairseq/scripts/average_checkpoints.py \\\n","--inputs {checkdir} \\\n","--num-epoch-checkpoints 5 \\\n","--output {checkdir}/avg_last_5_checkpoint.pt"],"execution_count":199,"outputs":[{"output_type":"stream","text":["Namespace(checkpoint_upper_bound=None, inputs=['/content/max_checkpoint_mono/'], num_epoch_checkpoints=5, num_update_checkpoints=None, output='/content/max_checkpoint_mono//avg_last_5_checkpoint.pt')\n","averaging checkpoints:  ['/content/max_checkpoint_mono/checkpoint30.pt', '/content/max_checkpoint_mono/checkpoint29.pt', '/content/max_checkpoint_mono/checkpoint28.pt', '/content/max_checkpoint_mono/checkpoint27.pt', '/content/max_checkpoint_mono/checkpoint23.pt']\n","Finished writing averaged checkpoint to /content/max_checkpoint_mono//avg_last_5_checkpoint.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_YDUmBZT7DQ8","executionInfo":{"status":"ok","timestamp":1619705372592,"user_tz":-480,"elapsed":1364,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}}},"source":["!cp /content/max_checkpoint_mono/avg_last_5_checkpoint.pt /content/forward/"],"execution_count":200,"outputs":[]},{"cell_type":"code","metadata":{"id":"now0G3ZIHE6y","colab":{"base_uri":"https://localhost:8080/","height":136,"referenced_widgets":["b908233102f144eea231e82be55001b1","28392ec4f2e444d59fc3f36f65d301cc","77e26d042a23461096f3aeeba69a20c1","d75bf5733d8e4b198d197c524916990e","43c43a681de64febb13729c98636a8e2","8a0e0d1bac7b4438a0f794e34d6f635b","b3fcab80f104433a8c89babc3eb2a5ba","cf370d4a307e4d0e930e36be6e0318b6"]},"executionInfo":{"status":"ok","timestamp":1619705404585,"user_tz":-480,"elapsed":30270,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"af3a6578-cc7f-4c75-8bcb-d9fdef90d18d"},"source":["# checkpoint_last.pt : 最後一次檢驗的檔案\n","# checkpoint_best.pt : 檢驗 BLEU 最高的檔案\n","# avg_last_5_checkpoint.pt:　最5後個檔案平均\n","\n","try_load_checkpoint(model, name=\"avg_last_5_checkpoint.pt\")\n","validate(model, task, criterion, log_to_wandb=False)\n","None"],"execution_count":201,"outputs":[{"output_type":"stream","text":["2021-04-29 14:09:34 | INFO | hw5.seq2seq | loaded checkpoint /content/forward/avg_last_5_checkpoint.pt: step=unknown loss=2.9510977268218994 bleu=29.320080433504394\n","2021-04-29 14:09:34 | INFO | hw5.seq2seq | begin validation\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b908233102f144eea231e82be55001b1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='validation', max=23.0, style=ProgressStyle(description_wi…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["2021-04-29 14:10:03 | INFO | hw5.seq2seq | example source: that because the overdoses are happening so much to the white community .\n","2021-04-29 14:10:03 | INFO | hw5.seq2seq | example hypothesis: 因為吸食過量發生在白人族群中 。\n","2021-04-29 14:10:03 | INFO | hw5.seq2seq | example reference: 因為在白人社區發生這麼多用藥過量 。\n","2021-04-29 14:10:03 | INFO | hw5.seq2seq | validation loss:\t2.9247\n","2021-04-29 14:10:03 | INFO | hw5.seq2seq | BLEU = 29.63 60.5/36.6/23.4/15.7 (BP = 0.987 ratio = 0.987 hyp_len = 110359 ref_len = 111811)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q-VZILbUHE87","executionInfo":{"status":"ok","timestamp":1619705413123,"user_tz":-480,"elapsed":575,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}}},"source":["def generate_prediction(model, task, split=\"test\", outfile=\"/content/drive/MyDrive/Colab Notebooks/prediction1.txt\"):    \n","    task.load_dataset(split=split, epoch=1)\n","    itr = load_data_iterator(task, split, 1, config.max_tokens, config.num_workers).next_epoch_itr(shuffle=False)\n","    \n","    idxs = []\n","    hyps = []\n","\n","    model.eval()\n","    progress = tqdm.tqdm(itr, desc=f\"prediction\")\n","    with torch.no_grad():\n","        for i, sample in enumerate(progress):\n","            # validation loss\n","            sample = utils.move_to_cuda(sample, device=device)\n","\n","            # 進行推論\n","            s, h, r = inference_step(sample, model)\n","            \n","            hyps.extend(h)\n","            idxs.extend(list(sample['id']))\n","            \n","    # 根據 preprocess 時的順序排列\n","    hyps = [x for _,x in sorted(zip(idxs,hyps))]\n","    \n","    with open(outfile, \"w\") as f:\n","        for h in hyps:\n","            f.write(h+\"\\n\")"],"execution_count":202,"outputs":[]},{"cell_type":"code","metadata":{"id":"kkHJcfTHFhbI","colab":{"base_uri":"https://localhost:8080/","height":117,"referenced_widgets":["4cea1bc37a694a998a117dd24996edcb","ee4b53b80ce44f5faeadec7a852d3f8c","7f50ee76fd6341d0a8a09dd642ed337f","da7749d0e58e45ac80617f38c11139d0","0288b2c6045b436c83bd99ed634ec425","194dd4abbeac46fbb560909f34f76f53","62713f646bed4602adf7d5819490c9e6","6aab4866262f415dbada8cb549d59249"]},"executionInfo":{"status":"ok","timestamp":1619705438119,"user_tz":-480,"elapsed":24839,"user":{"displayName":"李祖福","photoUrl":"","userId":"06310313028867163536"}},"outputId":"74527bef-d7c9-43ff-9edd-421d18f40134"},"source":["generate_prediction(model, task)"],"execution_count":203,"outputs":[{"output_type":"stream","text":["2021-04-29 14:10:13 | INFO | fairseq.data.data_utils | loaded 4,000 examples from: ./DATA/data-bin/ted2020_with_mono/test.zh-en.en\n","2021-04-29 14:10:13 | INFO | fairseq.data.data_utils | loaded 4,000 examples from: ./DATA/data-bin/ted2020_with_mono/test.zh-en.zh\n","2021-04-29 14:10:13 | INFO | fairseq.tasks.translation | ./DATA/data-bin/ted2020_with_mono test en-zh 4000 examples\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4cea1bc37a694a998a117dd24996edcb","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='prediction', max=17.0, style=ProgressStyle(description_wi…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tSs8pQHuOn_K"},"source":["# References"]},{"cell_type":"markdown","metadata":{"id":"hXhyIxlXOn_K"},"source":["1. <a name=ott2019fairseq></a>Ott, M., Edunov, S., Baevski, A., Fan, A., Gross, S., Ng, N., ... & Auli, M. (2019, June). fairseq: A Fast, Extensible Toolkit for Sequence Modeling. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations) (pp. 48-53).\n","2. <a name=vaswani2017></a>Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017, December). Attention is all you need. In Proceedings of the 31st International Conference on Neural Information Processing Systems (pp. 6000-6010).\n","3. <a name=reimers-2020-multilingual-sentence-bert></a>Reimers, N., & Gurevych, I. (2020, November). Making Monolingual Sentence Embeddings Multilingual Using Knowledge Distillation. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) (pp. 4512-4525).\n","4. <a name=tiedemann2012parallel></a>Tiedemann, J. (2012, May). Parallel Data, Tools and Interfaces in OPUS. In Lrec (Vol. 2012, pp. 2214-2218).\n","5. <a name=kudo-richardson-2018-sentencepiece></a>Kudo, T., & Richardson, J. (2018, November). SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations (pp. 66-71).\n","6. <a name=sennrich-etal-2016-improving></a>Sennrich, R., Haddow, B., & Birch, A. (2016, August). Improving Neural Machine Translation Models with Monolingual Data. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (pp. 86-96).\n","7. <a name=edunov-etal-2018-understanding></a>Edunov, S., Ott, M., Auli, M., & Grangier, D. (2018). Understanding Back-Translation at Scale. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (pp. 489-500).\n","8. https://github.com/ajinkyakulkarni14/TED-Multilingual-Parallel-Corpus\n","9. https://ithelp.ithome.com.tw/articles/10233122\n","10. https://nlp.seas.harvard.edu/2018/04/03/attention.html"]},{"cell_type":"code","metadata":{"id":"IQOOFHkPOn_K"},"source":[""],"execution_count":null,"outputs":[]}]}